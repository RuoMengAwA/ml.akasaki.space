<!doctype html>
<html lang="zh-cn" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.9">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿ RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿ Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.css" crossorigin="anonymous"><title data-react-helmet="true">Feature Pyramid Networks for Object Detection | å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://ml.akasaki.space//blog/[09]Feature-Pyramid-Networks-for-Object-Detection"><meta data-react-helmet="true" name="docusaurus_locale" content="zh-cn"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><meta data-react-helmet="true" property="og:title" content="Feature Pyramid Networks for Object Detection | å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿"><meta data-react-helmet="true" name="description" content="è¿™ç¯‡ç¬”è®°çš„å†™ä½œè€…æ˜¯VisualDustã€‚"><meta data-react-helmet="true" property="og:description" content="è¿™ç¯‡ç¬”è®°çš„å†™ä½œè€…æ˜¯VisualDustã€‚"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="article:published_time" content="2022-11-05T07:47:19.660Z"><meta data-react-helmet="true" property="article:author" content="https://gong.host"><meta data-react-helmet="true" property="article:tag" content="detection,FPN,backbone,multi-scale-learning"><link data-react-helmet="true" rel="shortcut icon" href="/img/logo.svg"><link data-react-helmet="true" rel="canonical" href="https://ml.akasaki.space//blog/[09]Feature-Pyramid-Networks-for-Object-Detection"><link data-react-helmet="true" rel="alternate" href="https://ml.akasaki.space//blog/[09]Feature-Pyramid-Networks-for-Object-Detection" hreflang="zh-cn"><link data-react-helmet="true" rel="alternate" href="https://ml.akasaki.space//blog/[09]Feature-Pyramid-Networks-for-Object-Detection" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.2aa28e4b.css">
<link rel="preload" href="/assets/js/runtime~main.70701027.js" as="script">
<link rel="preload" href="/assets/js/main.e4cdc564.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Logo" class="themedImage_TMUO themedImage--light_4Vu1"><img src="/img/logo.svg" alt="Logo" class="themedImage_TMUO themedImage--dark_uzRr"></div><b class="navbar__title">å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">é­”æ³•éƒ¨æ—¥å¿—</a><a href="https://github.com/neet-cv/ml.akasaki.space" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/about">Authors &amp; About</a><a href="https://gong.host" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>YetAnotherAkasaki<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_iYfV toggle_2i4l toggleDisabled_xj38"><div class="toggleTrack_t-f2" role="button" tabindex="-1"><div class="toggleTrackCheck_mk7D"><span class="toggleIcon_pHJ9">ğŸŒœ</span></div><div class="toggleTrackX_dm8H"><span class="toggleIcon_pHJ9">ğŸŒ</span></div><div class="toggleTrackThumb_W6To"></div></div><input type="checkbox" class="toggleScreenReader_h9qa" aria-label="Switch between dark and light mode"></div><div class="navbar__search searchBarContainer_I7kZ"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_Zg7X searchBarLoadingRing_J5Ez"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_CDc6"><kbd class="searchHint_2RRg">ctrl</kbd><kbd class="searchHint_2RRg">K</kbd></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-post-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_q+wC thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_9G5K margin-bottom--md">All posts</div><ul class="sidebarItemList_6T4b"><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[42]CCNet-Criss-Cross-Attention-for-Semantic-Segmentation">CCNet - Criss-Cross Attention for Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[43]RepVGG-Making-VGG-style-ConvNets-Great-Again">RepVGG - Making VGG-style ConvNets Great Again</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[44]PP-LCNet-A-Lightweight-CPU-Convolutional-Neural-Network">PP-LCNet - A Lightweight CPU Convolutional Neural Network</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[45]Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows">Swin Transformer - Hierarchical Vision Transformer using Shifted Windows</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[46]Demystifying-Local-Vision-Transformer">Demystifying Local Vision Transformer</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[47]Discrete-Cosine-Transform-Mask-Representation-for-Instance-Segmentation">DCT-Mask - Discrete Cosine Transform Mask Representation for Instance Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[48]Deep-Retinex-Decomposition-for-Low-Light-Enhancement">Deep Retinex Decomposition for Low-Light Enhancement</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[49]GhostNet-More-Features-from-Cheap-Operations">GhostNet - More Features from Cheap Operations</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[50]Kindling-the-Darkness-A-Practical-Low-light-Image-Enhancer">Kindling the Darkness - A Practical Low-light Image Enhancer</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[51]How-much-Position-Information-Do-Convolutional-Neural-Networks-Encode">How much Position Information Do Convolutional Neural Networks Encode?</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[52]Axiomatic-Attribution-for-Deep-Networks">Axiomatic Attribution for Deep Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[00]unlimited-paper-works">æ¬¢è¿æ¥åˆ°é­”æ³•éƒ¨æ—¥å¿—</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[01]The-Devil-is-in-the-Decoder-Classification-Regression-and-GANs">The Devil is in the Decoder - Classification, Regression and GANs</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[02]Threat-of-Adversarial-Attacks-on-Deep-Learning-in-Computer-Vision-A-Survey">Threat of Adversarial Attacks on Deep Learning in Computer Vision - A Survey</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[03]Progressive-Semantic-Segmentation">Progressive Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[04]Decoders-Matter-for-Semantic-Segmentation-Data-Dependent-Decoding-Enables-Flexible-Feature-Aggregation">Decoders Matter for Semantic Segmentation - Data-Dependent Decoding Enables Flexible Feature Aggregation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[05]HLA-Face-Joint-High-Low-Adaptation-for-Low-Light-Face-Detection">HLA-Face Joint High-Low Adaptation for Low Light Face Detection</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[06]DeepLab-Series">DeepLab Series</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[07]Cross-Dataset-Collaborative-Learning-for-Semantic-Segmentation">Cross-Dataset Collaborative Learning for Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[08]Dynamic-Neural-Networks-A-Survey">Dynamic Neural Networks - A Survey</a></li><li class="sidebarItem_cjdF"><a aria-current="page" class="sidebarItemLink_zyXk sidebarItemLinkActive_wcJs" href="/blog/[09]Feature-Pyramid-Networks-for-Object-Detection">Feature Pyramid Networks for Object Detection</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[10]Overview-Of-Semantic-Segmentation">A Review on Deep Learning Techniques Applied to Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[12]MobileNetV2-Inverted-Residuals-and-Linear-bottleneck">MobileNetV2 - Inverted Residuals and Linear Bottlenecks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[13]Fast-SCNN-Fast-Semantic-Segmentation-Network">Fast-SCNN - Fast Semantic Segmentation Network</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[14]MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications">MobileNets - Efficient Convolutional Neural Networks for Mobile Vision Applications</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[15]Gated-Channel-Transformation-for-Visual-Recognition">Gated Channel Transformation for Visual Recognition</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[16]Convolutional-Block-Attention-Module">Convolutional Block Attention Module</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[17]Boundary-IoU-Improving-Object-Centri-Image-Segmentation-Evaluation">Boundary IoU - Improving Object-Centric Image Segmentation Evaluation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[18]Involution-Inverting-the-Inherence-of-Convolution-for-Visual-Recognition">Involution - Inverting the Inherence of Convolution for Visual Recognition</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[19]PointRend-Image-Segmentation-as-Rendering">PointRend - Image Segmentation as Rendering</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[20]Transformer-Attention-is-all-you-need">Transformer - Attention is all you need</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[21]RefineMask-Towards-High-Quality-Instance-Segmentationwith-Fine-Grained_Features">RefineMask - Towards High-Quality Instance Segmentationwith Fine-Grained Features</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[22]GLADNet-Low-Light-Enhancement-Network-with-Global-Awareness">GLADNet - Low-Light Enhancement Network with Global Awareness</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[23]Squeeze-and-Excitation-Networks">Squeeze-and-Excitation Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation">BiSeNet - Bilateral Segmentation Network for Real-time Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[25]Rethinking-BiSeNet-For-Real-time-Semantic-Segmentation">Rethinking BiSeNet For Real-time Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[26]CBAM-Convolutional-Block-Attention-Module">CBAM - Convolutional Block Attention Module</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[27]Non-local-Neural-Networks">Non-local Neural Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[28]GCNet-Non-local-Networks-Meet-Squeeze-Excitation-Networks-and-Beyond">Non-local Networks Meet Squeeze-Excitation Networks and Beyond</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[29]Disentangled-Non-Local-Neural-Networks">Disentangled Non-Local Neural Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[30]RetinexNet-for-Low-Light-Enhancement">Deep Retinex Decomposition for Low-Light Enhancement</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[31]MSR-netLow-light-Image-Enhancement-Using-Deep-Convolutional-Network">MSR-net - Low-light Image Enhancement Using Deep Convolutional Network</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[32]LLCNN-A-Convolutional-Neural-Network-for-Low-light-Image-Enhancement">LLCNN - A convolutional neural network for low-light image enhancement</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[33]VOLO-Vision-Outlooker-for-Visual-Recognition">VOLO - Vision Outlooker for Visual Recognition</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[34]Polarized-Self-Attention-Towards-High-quality-Pixel-wise-Regression">Polarized Self-Attention - Towards High-quality Pixel-wise Regression</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[35]SimAM-A-Simple-Parameter-Free-Attention-Module-for-Convolutional-Neural-Networks">SimAM - A Simple, Parameter-Free Attention Module for Convolutional Neural Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[36]SOLO-Segmenting-Objects-by-Locations">SOLO - Segmenting Objects by Locations</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[37]YOLACT-Real-time-Instance-Segmentation">YOLACT - Real-time Instance Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[38]You-Only-Look-One-level-Feature">You Only Look One-level Feature</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[39]Instance-sensitive-Fully-Convolutional-Networks">Instance-sensitive Fully Convolutional Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[40]Learning-in-the-Frequency-Domain">Learning in the Frequency Domain</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_d4p0" itemprop="headline">Feature Pyramid Networks for Object Detection</h1><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/visualDust.png" alt="Gavin Gong"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Gavin Gong</span></a></div><small class="avatar__subtitle" itemprop="description">Rubbish CVer | Poor LaTex speaker | Half stack developer | é”®åœˆèººå°¸ç –å®¶</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><h3 class="anchor anchorWithStickyNavbar_y2LR" id="è¿™ç¯‡ç¬”è®°çš„å†™ä½œè€…æ˜¯visualdust">è¿™ç¯‡ç¬”è®°çš„å†™ä½œè€…æ˜¯<a href="https://github.com/visualDust" target="_blank" rel="noopener noreferrer">VisualDust</a>ã€‚<a aria-hidden="true" class="hash-link" href="#è¿™ç¯‡ç¬”è®°çš„å†™ä½œè€…æ˜¯visualdust" title="Direct link to heading">â€‹</a></h3><p>åŸè®ºæ–‡<a href="https://arxiv.org/abs/1612.03144" target="_blank" rel="noopener noreferrer">Feature Pyramid Networks for Object Detection</a>ã€‚</p><p>è¿™ç¯‡è®ºæ–‡å°±æ˜¯å¤§å®¶ç†ŸçŸ¥çš„FPNäº†ã€‚FPNæ˜¯<strong>æ¯”è¾ƒæ—©æœŸçš„ä¸€ä»½å·¥ä½œ</strong>ï¼ˆè¯·æ³¨æ„ï¼Œè¿™ç¯‡è®ºæ–‡åªæ˜¯å¤šå°ºåº¦ç‰¹å¾èåˆçš„ä¸€ç§æ–¹å¼ã€‚ä¸è¿‡è¿™ç¯‡è®ºæ–‡æå‡ºçš„æ¯”è¾ƒæ—©ï¼ˆCVPR2017ï¼‰ï¼Œåœ¨å½“æ—¶çœ‹æ¥æ˜¯éå¸¸å…ˆè¿›çš„ï¼‰ï¼Œåœ¨å½“æ—¶å…·æœ‰å¾ˆå¤šäº®ç‚¹ï¼šFPNä¸»è¦è§£å†³çš„æ˜¯ç‰©ä½“æ£€æµ‹ä¸­çš„å¤šå°ºåº¦é—®é¢˜ï¼Œé€šè¿‡ç®€å•çš„ç½‘ç»œè¿æ¥æ”¹å˜ï¼Œåœ¨åŸºæœ¬ä¸å¢åŠ åŸæœ‰æ¨¡å‹è®¡ç®—é‡æƒ…å†µä¸‹ï¼Œå¤§å¹…åº¦æå‡äº†å°ç‰©ä½“æ£€æµ‹çš„æ€§èƒ½ã€‚</p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="abstractæ‘˜è¦">Abstractï¼ˆæ‘˜è¦ï¼‰<a aria-hidden="true" class="hash-link" href="#abstractæ‘˜è¦" title="Direct link to heading">â€‹</a></h2><blockquote><p>Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But recent deep learning object detectors have avoided pyramid representations, in part because they are compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. A top-down architecture with lateral connections is developed for building high-level semantic feature maps at all scales. This architecture, called a Feature Pyramid Network (FPN), shows significant improvement as a generic feature extractor in several applications. Using FPN in a basic Faster R-CNN system, our method achieves state-of-the-art single-model results on the COCO detection benchmark without bells and whistles, surpassing all existing single-model entries including those from the COCO 2016 challenge winners. In addition, our method can run at 5 FPS on a GPU and thus is a practical and accurate solution to multi-scale object detection. Code will be made publicly available.</p></blockquote><p>è¿™ç¯‡è®ºæ–‡å¯¹ä»¥åçš„è®¸å¤šç½‘ç»œè®¾è®¡äº§ç”Ÿäº†è¾ƒå¤§çš„å½±å“ï¼Œæ¨èä½ é˜…è¯»<a href="https://arxiv.org/abs/1612.03144" target="_blank" rel="noopener noreferrer">åŸæ–‡</a>ã€‚è¿™é‡Œåªæ˜¯å¯¹è¿™ç¯‡è®ºæ–‡çš„ç²—æµ…é˜…è¯»ç¬”è®°ã€‚</p><hr><h2 class="anchor anchorWithStickyNavbar_y2LR" id="ä»‹ç»introduction">ä»‹ç»ï¼ˆIntroductionï¼‰<a aria-hidden="true" class="hash-link" href="#ä»‹ç»introduction" title="Direct link to heading">â€‹</a></h2><p>è¯¥è®ºæ–‡æå‡ºï¼Œç‰¹å¾é‡‘å­—å¡”æ˜¯è¯†åˆ«ç³»ç»Ÿä¸­ç”¨äºæ£€æµ‹ä¸åŒæ¯”ä¾‹ç‰©ä½“çš„åŸºæœ¬ç»„ä»¶ï¼Œç”šè‡³å·ç§°æ‰‹å·¥ç‰¹å¾è®¾è®¡æ—¶ä»£çš„ä¸‡é‡‘æ²¹ï¼šæ¯”å¦‚åœ¨OpenCVåº“çš„ç‰¹å¾åŒ¹é…Cascadeåˆ†ç±»å™¨ç”¨äºäººè„¸è¯†åˆ«ä¸­ä½¿ç”¨ç‰¹å¾é‡‘å­—å¡”æ¨¡å‹+AdaBoostæå–ä¸åŒå°ºåº¦ç‰¹å¾ç»è¡Œåˆ†ç±»ç­‰ã€‚</p><p>åŸè®ºæ–‡è¿™æ ·å½¢å®¹å¤šå°ºåº¦çš„å¥½å¤„ï¼š</p><blockquote><p>The principle advantage of featurizing each level of an image pyramid is that it produces a multi-scale feature representation in which all levels are semantically strong, including the high-resolution levels.</p></blockquote><p>åœ¨è¿›å…¥æ·±åº¦å·ç§¯ç½‘ç»œä¹‹åï¼Œå¦‚ä½•åœ¨å·ç§¯ç¥ç»ç½‘ç»œä¸­æ›´å¥½åœ°åˆ©ç”¨å¤šå°ºåº¦ç§°ä¸ºäº†ä¸€é¡¹æŒ‘æˆ˜ã€‚ä¸€æ–¹é¢ï¼Œä»…ä½¿ç”¨æ·±åº¦å·ç§¯ç½‘ç»œè¿›è¡Œæ£€æµ‹ä¼šå¯¼è‡´å°ç›®æ ‡çš„æ¼æ£€ï¼›å¦ä¸€æ–¹é¢ï¼Œåœ¨æ¯å±‚ä¸åŒçº§åˆ«çš„ç‰¹å¾å›¾ä¸Šè¿›è¡Œé¢„æµ‹äº§ç”Ÿäº†å¤šä½™çš„æ€§èƒ½æ¶ˆè€—ï¼Œå¹¶ä¸”æ•ˆæœå¹¶æ²¡æœ‰æƒ³è±¡çš„é‚£ä¹ˆå¥½ã€‚è¿™ç¯‡è®ºæ–‡å°±æ˜¯ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜çš„ã€‚</p><hr><h2 class="anchor anchorWithStickyNavbar_y2LR" id="ç›¸å…³å·¥ä½œrelated-works">ç›¸å…³å·¥ä½œï¼ˆRelated worksï¼‰<a aria-hidden="true" class="hash-link" href="#ç›¸å…³å·¥ä½œrelated-works" title="Direct link to heading">â€‹</a></h2><ul><li>æ‰‹å·¥è®¾è®¡çš„ç‰¹å¾å’Œæ—©æœŸç¥ç»ç½‘ç»œï¼ˆHand-engineered features and early neural networksï¼‰</li><li>æ™®é€šçš„æ·±åº¦å·ç§¯ç›®æ ‡æ£€æµ‹ç½‘ç»œï¼ˆDeep ConvNet object detectorsï¼‰</li><li>èåˆäº†æ·±åº¦å·ç§¯ç½‘ç»œçš„ç‰¹å¾é‡‘å­—å¡”æ¨¡å‹ï¼ˆMethods using multiple layersï¼‰</li></ul><p><img alt="image-20210512231141905" src="/assets/images/image-20210512231141905-b65472fe00bc89cbbae7520f4333ccf7.png"></p><p>ä¸Šå›¾ä¸ºåŸè®ºæ–‡ä¸­å‡ºç°çš„ç¤ºæ„å›¾ã€‚å…¶ä¸­ï¼š</p><ul><li><p>(a)æ˜¯æ‰‹å·¥è®¾è®¡ç‰¹å¾æè¿°æ—¶ä»£çš„å¸¸è§æ¨¡å‹ï¼Œå³å¯¹ä¸åŒå°ºå¯¸çš„å›¾ç‰‡æå–ç‰¹å¾ï¼Œä»¥æ»¡è¶³ä¸åŒå°ºåº¦ç›®æ ‡çš„æ£€æµ‹è¦æ±‚ï¼Œæé«˜æ¨¡å‹æ€§èƒ½ã€‚</p></li><li><p>(b)æ˜¯æ™®é€šçš„æ·±åº¦å·ç§¯ç½‘ç»œæ¨¡å¼ï¼Œé€šè¿‡ä¸‹é‡‡æ ·æ‰©å¤§æ„Ÿå—é‡ï¼Œæå–è¯­ä¹‰ä¿¡æ¯ã€‚</p></li><li><p>(c)æ˜¯èåˆäº†æ·±åº¦å·ç§¯ç½‘ç»œçš„ç‰¹å¾é‡‘å­—å¡”æ¨¡å‹ã€‚æ·±åº¦å·ç§¯ç½‘ç»œåœ¨å·ç§¯è¿‡ç¨‹ä¸­æ¯å±‚éƒ½ä¼šäº§ç”Ÿä¸åŒå°ºåº¦çš„ç‰¹å¾å›¾ï¼Œæ‰€ä»¥å…¶æœ¬èº«å°±å¤©ç„¶å…·æœ‰é‡‘å­—å¡”ç»“æ„ã€‚æˆªæ­¢åˆ°è¿™ç¯‡è®ºæ–‡çš„å†™ä½œæ—¶é—´ä¸ºæ­¢ï¼Œæœ‰å¾ˆå¤šåœ¨COCOå’ŒImageNetä¸Šè¡¨ç°ä¼˜ç§€çš„ç½‘ç»œéƒ½æ˜¯pyramid representationsçš„ï¼Œå³è®©ä¸åŒå±‚é¢„æµ‹ä¸åŒå°ºåº¦çš„ç‰©ä½“ã€‚ä½†æ˜¯å…¶å¯¹å°ç›®æ ‡çš„æ£€æµ‹æ•ˆæœä»ç„¶ä¸å¤Ÿå¥½ï¼ŒåŸå› åœ¨äºä½å°ºåº¦çš„ç‰¹å¾å›¾åŒ…å«çš„è¯­ä¹‰ä¿¡æ¯è¿˜ä¸å¤Ÿæ·±åˆ»ï¼ˆè¯´ä¿—è¯å°±æ˜¯æ¬ å·äº†ï¼‰ï¼ŒåŸæ–‡æ˜¯è¿™æ ·è¯´çš„ï¼š</p><blockquote><p>This in-network feature hierarchy produces feature maps of different spatial resolutions, but introduces large semantic gaps caused by different depths. The high-resolution maps have low-level features that harm their representational capacity for object recognition.</p></blockquote><p>SSDå°±æ˜¯ç¬¬ä¸€æ‰¹é‡‡ç”¨è¿™ç§æ–¹æ³•çš„æ·±åº¦å·ç§¯ç½‘ç»œä¹‹ä¸€ã€‚ä¸è¿‡SSDä¸ºäº†é¿å…ä½¿ç”¨è¯­ä¹‰ä¿¡æ¯ä¸è¶³çš„ç‰¹å¾å›¾ï¼ŒSSDå¹¶æ²¡èƒ½å¾ˆå¥½åœ°å¤ç”¨å·²æœ‰çš„ç‰¹å¾å›¾ï¼Œè¿™è®©å®ƒå¯¹å°ç›®æ ‡çš„æ£€æµ‹æ•ˆæœä»ç„¶ä¸å¤Ÿå¥½ã€‚å·ç§¯ç¥ç»ç½‘ç»œçš„æ·±åº¦å¾€å¾€å’Œæ¯ä¸€æ­¥çš„å·ç§¯çš„æ­¥é•¿å‚æ•°æ˜¯ä¸€ä¸ªå¾ˆçŸ›ç›¾çš„ä¸œè¥¿ã€‚å±•å¼€æ¥è¯´ï¼Œç½‘ç»œæ›´æ·±çš„æ—¶å€™ï¼Œå°±ä¸å¾—ä¸é€šè¿‡å°†æ­¥é•¿æ”¹å¤§ä»¥å¹³è¡¡æ›´æ·±çš„ç½‘ç»œå¸¦æ¥çš„å‚æ•°é‡ä¸Šæ¶¨é—®é¢˜ã€‚ä½†åŒæ—¶è¿™å¯¼è‡´äº†å¦å¤–ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯æ­¥é•¿å¾ˆå¤§çš„æ—¶å€™ï¼Œç”šè‡³å¯ä»¥å¤§è¿‡è¾“å…¥å›¾åƒä¸­ä¸€äº›ç‰©ä½“çš„å¤§å°ï¼Œä½¿å¾—ä¸€äº›ç›®æ ‡ä¸¢å¤±ã€‚</p></li><li><p>(d)æ˜¯è¿™ç¯‡è®ºæ–‡è¦æå‡ºçš„FPNç½‘ç»œç»“æ„ã€‚è¯¥ç½‘ç»œåœ¨è®¾è®¡æ—¶çš„ä¸€ä¸ªç›®æ ‡å°±æ˜¯é¿å…(c)ä¸­å‡ºç°çš„é—®é¢˜ï¼Œè®©æ¯ä¸€ä¸ªå°ºåº¦çš„ç‰¹å¾å›¾éƒ½ä¼šåŒ…å«è¶³å¤Ÿä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ã€‚</p></li></ul><hr><h2 class="anchor anchorWithStickyNavbar_y2LR" id="ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œfeature-pyramid-networks">ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œï¼ˆFeature Pyramid Networksï¼‰<a aria-hidden="true" class="hash-link" href="#ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œfeature-pyramid-networks" title="Direct link to heading">â€‹</a></h2><p>åŸè®ºæ–‡è¿™æ ·æè¿°è¿™ç¯‡è®ºæ–‡çš„ç›®çš„ï¼š</p><blockquote><p>Our goal is to leverage a ConvNetâ€™s pyramidal feature hierarchy, which has semantics from low to high levels, and build a feature pyramid with high-level semantics throughout.</p></blockquote><p>ä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™ç¯‡è®ºæ–‡çš„ç›®çš„å°±æ˜¯åˆ©ç”¨æ·±åº¦å·ç§¯ç½‘ç»œå¤©ç„¶å­˜åœ¨çš„é‡‘å­—å¡”ç‰¹å¾å±‚æ¬¡ç»“æ„ï¼šè¯¥å±‚æ¬¡ç»“æ„åˆ©ç”¨è‡ªåº•å‘ä¸Šçš„é€å±‚çš„å·ç§¯è·å¾—ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­æ„å»ºå…·æœ‰é«˜å±‚è¯­ä¹‰çš„ç‰¹å¾é‡‘å­—å¡”ã€‚</p><p>è¿™ç¯‡è®ºæ–‡çš„ç½‘ç»œç»“æ„è®¾è®¡ä¸»è¦åŒ…å«äº†ä¸¤ä¸ªéƒ¨åˆ†ï¼š</p><ul><li>è‡ªåº•å‘ä¸Šï¼ˆBottom-up pathwayï¼‰</li><li>è‡ªé¡¶å‘ä¸‹ï¼ˆTop-down pathway and lateral connectionsï¼‰</li></ul><p>åœ¨æ¥ä¸‹æ¥çš„è¯´æ˜ä¸­ï¼Œä¼šç»å¸¸ä½¿ç”¨<code>stage</code>çš„æ¦‚å¿µã€‚åœ¨è¿™é‡Œè¿›è¡Œæå‰å®šä¹‰è¯´æ˜ï¼šåœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œç½‘ç»œä¸­è¾“å‡ºçš„feature mapå¤§å°ç›¸åŒçš„å±‚è¢«ç§°ä¸ºæ˜¯åŒä¸ªstageçš„ã€‚ä¸åŒstageä¼šäº§ç”Ÿä¸åŒå¤§å°çš„ç‰¹å¾å›¾ï¼Œè¿™ç¯‡è®ºæ–‡ä¸ºæ¯ä¸ªstageå®šä¹‰ä¸€ä¸ªé‡‘å­—å¡”å±‚çº§ï¼ˆpyramid levelï¼‰ã€‚</p><p><img alt="image-20210513105442041" src="/assets/images/image-20210513105442041-bf83a73de8877a088888077f30e8e37f.png"></p><p>ä¾‹å¦‚ä¸Šå›¾æ˜¯VGG-16çš„ç½‘ç»œç»“æ„å›¾ï¼Œå›¾ä¸­ç”¨ç´«è‰²çš„æ–‡å­—æ ‡å‡ºäº†5ä¸ªä¸åŒçš„stageã€‚å½“ç„¶ï¼Œä¸æŒ¨åœ¨ä¸€èµ·ä½†æ˜¯è¾“å‡ºç‰¹å¾å›¾å¤§å°ç›¸åŒçš„å±‚ä¹Ÿæ˜¯å±äºåŒä¸€ä¸ªstageçš„ã€‚</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="è‡ªåº•å‘ä¸Šbottom-up-pathway">è‡ªåº•å‘ä¸Šï¼ˆBottom-up pathwayï¼‰<a aria-hidden="true" class="hash-link" href="#è‡ªåº•å‘ä¸Šbottom-up-pathway" title="Direct link to heading">â€‹</a></h3><p>è‡ªåº•å‘ä¸Šå°±æ˜¯æ™®é€šæ·±åº¦å·ç§¯ç½‘ç»œå‰å‘ä¼ æ’­çš„è¿‡ç¨‹ã€‚å¯¹äºæåŠçš„é‡‘å­—å¡”ï¼ˆpyramidï¼‰ç‰¹å¾ï¼Œè¿™ç¯‡è®ºæ–‡é€‰æ‹©æ¯ä¸ªstageæœ€åä¸€å±‚çš„è¾“å‡ºä½œä¸ºä¸€ä¸ªç‰¹å¾å›¾ï¼Œè¿™ä¸ªé€‰æ‹©å¬ä¸Šå»å¾ˆåˆç†ï¼Œå› ä¸ºè¶Šä¸Šå±‚ï¼ˆæ¯ä¸ªstageçš„æœ€åä¸€ä¸ªå±‚ï¼‰çš„ç‰¹å¾å°±åŒ…å«æ›´å¤šçš„è¯­ä¹‰ä¿¡æ¯ã€‚</p><p><img alt="image-20210513105825996" src="/assets/images/image-20210513105825996-5e0eb11494ad89300caf9a419b3dba24.png"></p><p>ä¾‹å¦‚ï¼Œåœ¨ä¸Šå›¾ä¸­ï¼Œè¿™ç¯‡è®ºæ–‡çš„æ–¹æ³•é€‰æ‹©å³ä¾§çš„ç‰¹å¾å›¾è¾“å‡ºä½œä¸ºä¸€ä¸ªstageçš„ç‰¹å¾å›¾è¾“å‡ºè€Œä¸æ˜¯å·¦ä¾§çš„ã€‚</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="è‡ªé¡¶å‘ä¸‹top-down-pathway-and-lateral-connections">è‡ªé¡¶å‘ä¸‹ï¼ˆTop-down pathway and lateral connectionsï¼‰<a aria-hidden="true" class="hash-link" href="#è‡ªé¡¶å‘ä¸‹top-down-pathway-and-lateral-connections" title="Direct link to heading">â€‹</a></h3><p>è‡ªé¡¶å‘ä¸‹çš„ç»“æ„åœ¨ç›´è§‚æ„Ÿå—ä¸Šæ˜¯å’Œæ·±åº¦å·ç§¯ç½‘ç»œä¸‹é‡‡æ ·çš„è¿‡ç¨‹ç›¸åçš„ï¼šå®ƒå°†é«˜å±‚stageè¾“å‡ºçš„ç©ºé—´ä¿¡æ¯å¾ˆç²—åŠ£ï¼ˆæ¯•ç«Ÿä¹‹å‰ä¸€ç›´åœ¨ä¸‹é‡‡æ ·...ï¼‰ä½†æ˜¯è¯­ä¹‰ä¿¡æ¯å¾ˆä¸°å¯Œçš„ç‰¹å¾å›¾è¿›è¡Œä¸æ–­ä¸Šé‡‡æ ·ï¼Œä¸Šé‡‡æ ·åˆ°å’Œå…¶å¯¹åº”çš„stageçš„ä¸Šä¸€ä¸ªstageçš„ç‰¹å¾å›¾å¤§å°ï¼Œå†é€šè¿‡å›¾ä¸­è¿™ç§ä¾§è¾¹çš„è¿æ¥ï¼ˆlateral connectionsï¼‰ï¼Œä½¿ç”¨ä½ä¸€çº§stageçš„ç‰¹å¾å›¾æ¥å¢å¼ºå®ƒã€‚</p><p><img alt="image-20210513110511093" src="/assets/images/image-20210513110511093-4117637496c0968d7839c6776dd6b66e.png"></p><p>ä¸Šå›¾æ˜¯è®ºæ–‡ä¸­ä¾§è¾¹è¿æ¥ï¼ˆlateral connectionsï¼‰çš„æ–¹å¼ã€‚æ¯ä¸ªä¾§è¾¹è¿æ¥å°†åŒä¸ªstageçš„è‡ªåº•å‘ä¸Šçš„ç‰¹å¾å›¾å’Œè‡ªé¡¶å‘ä¸‹çš„ç‰¹å¾å›¾ç›¸åŠ ã€‚æ³¨æ„ï¼Œè¯¥è®ºæ–‡ä¸­ç‰¹æŒ‡äº†æ¯ä¸¤ä¸ªstageä¹‹é—´çš„ç©ºé—´åˆ†è¾¨ç‡ä¹‹å·®æ˜¯2å€ï¼Œä¹Ÿå°±æ˜¯ä¸‹é‡‡æ ·ç‡æ˜¯2å€ã€‚æ‰€ä»¥ä¸Šå›¾çš„ç¤ºæ„ä¸­é è¿‘é¡¶å±‚çš„ç‰¹å¾å›¾ç»è¿‡2å€ä¸Šé‡‡æ ·åä½¿ç”¨ä¾§è¾¹è¿æ¥å’Œä¸Šä¸€çº§ç‰¹å¾å›¾ç›¸åŠ ç»„æˆå¢å¼ºåçš„æ–°ç‰¹å¾ï¼›æŠ€æœ¯ä¸Šï¼Œåœ¨ä¾§è¾¹è¿æ¥çš„è¿‡ç¨‹ä¸­ï¼Œè¿™ç¯‡è®ºæ–‡çš„æ–¹æ³•ä½¿ç”¨<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>Ã—</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1\times 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">Ã—</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></span>å·ç§¯çš„æ–¹å¼ä½¿éœ€è¦ç›¸åŠ çš„ç‰¹å¾å›¾é€šé“æ•°ä¿æŒä¸€è‡´ã€‚</p><hr><h2 class="anchor anchorWithStickyNavbar_y2LR" id="åº”ç”¨applications">åº”ç”¨ï¼ˆApplicationsï¼‰<a aria-hidden="true" class="hash-link" href="#åº”ç”¨applications" title="Direct link to heading">â€‹</a></h2><p>æœ‰ç©ºå°±å†™ã€‚</p></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_xD8n"><div class="col"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/detection">detection</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/fpn">FPN</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/backbone">backbone</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/multi-scale-learning">multi-scale-learning</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.dev/neet-cv/ml.akasaki.space/blob/master/blog/[09]Feature-Pyramid-Networks-for-Object-Detection.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_mS5F" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/[08]Dynamic-Neural-Networks-A-Survey"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Â« <!-- -->Dynamic Neural Networks - A Survey</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/[10]Overview-Of-Semantic-Segmentation"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">A Review on Deep Learning Techniques Applied to Semantic Segmentation<!-- --> Â»</div></a></div></nav></main><div class="col col--2"><div class="tableOfContents_vrFS thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#è¿™ç¯‡ç¬”è®°çš„å†™ä½œè€…æ˜¯visualdust" class="table-of-contents__link toc-highlight">è¿™ç¯‡ç¬”è®°çš„å†™ä½œè€…æ˜¯VisualDustã€‚</a></li><li><a href="#abstractæ‘˜è¦" class="table-of-contents__link toc-highlight">Abstractï¼ˆæ‘˜è¦ï¼‰</a></li><li><a href="#ä»‹ç»introduction" class="table-of-contents__link toc-highlight">ä»‹ç»ï¼ˆIntroductionï¼‰</a></li><li><a href="#ç›¸å…³å·¥ä½œrelated-works" class="table-of-contents__link toc-highlight">ç›¸å…³å·¥ä½œï¼ˆRelated worksï¼‰</a></li><li><a href="#ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œfeature-pyramid-networks" class="table-of-contents__link toc-highlight">ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œï¼ˆFeature Pyramid Networksï¼‰</a><ul><li><a href="#è‡ªåº•å‘ä¸Šbottom-up-pathway" class="table-of-contents__link toc-highlight">è‡ªåº•å‘ä¸Šï¼ˆBottom-up pathwayï¼‰</a></li><li><a href="#è‡ªé¡¶å‘ä¸‹top-down-pathway-and-lateral-connections" class="table-of-contents__link toc-highlight">è‡ªé¡¶å‘ä¸‹ï¼ˆTop-down pathway and lateral connectionsï¼‰</a></li></ul></li><li><a href="#åº”ç”¨applications" class="table-of-contents__link toc-highlight">åº”ç”¨ï¼ˆApplicationsï¼‰</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2022 neet-cv. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.70701027.js"></script>
<script src="/assets/js/main.e4cdc564.js"></script>
</body>
</html>