<!doctype html>
<html lang="zh-cn" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.9">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿ RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿ Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.css" crossorigin="anonymous"><title data-react-helmet="true">BiSeNet - Bilateral Segmentation Network for Real-time Semantic Segmentation | å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://ml.akasaki.space//blog/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation"><meta data-react-helmet="true" name="docusaurus_locale" content="zh-cn"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><meta data-react-helmet="true" property="og:title" content="BiSeNet - Bilateral Segmentation Network for Real-time Semantic Segmentation | å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿"><meta data-react-helmet="true" name="description" content="BiSeNetçš„ç›®æ ‡æ˜¯æ›´å¿«é€Ÿçš„å®æ—¶è¯­ä¹‰åˆ†å‰²ã€‚åœ¨è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸­ï¼Œç©ºé—´åˆ†è¾¨ç‡å’Œæ„Ÿå—é‡å¾ˆéš¾ä¸¤å…¨ï¼Œå°¤å…¶æ˜¯åœ¨å®æ—¶è¯­ä¹‰åˆ†å‰²çš„æƒ…å†µä¸‹ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸æ˜¯åˆ©ç”¨å°çš„è¾“å…¥å›¾åƒæˆ–è€…è½»é‡ä¸»å¹²æ¨¡å‹å®ç°åŠ é€Ÿã€‚ä½†æ˜¯å°å›¾åƒç›¸è¾ƒäºåŸå›¾åƒç¼ºå¤±äº†å¾ˆå¤šç©ºé—´ä¿¡æ¯ï¼Œè€Œè½»é‡çº§æ¨¡å‹åˆ™ç”±äºè£å‰ªé€šé“è€ŒæŸå®³äº†ç©ºé—´ä¿¡æ¯ã€‚BiSegNetæ•´åˆäº†Spatial Path (SP) å’Œ Context Path (CP)åˆ†åˆ«ç”¨æ¥è§£å†³ç©ºé—´ä¿¡æ¯ç¼ºå¤±å’Œæ„Ÿå—é‡ç¼©å°çš„é—®é¢˜ã€‚"><meta data-react-helmet="true" property="og:description" content="BiSeNetçš„ç›®æ ‡æ˜¯æ›´å¿«é€Ÿçš„å®æ—¶è¯­ä¹‰åˆ†å‰²ã€‚åœ¨è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸­ï¼Œç©ºé—´åˆ†è¾¨ç‡å’Œæ„Ÿå—é‡å¾ˆéš¾ä¸¤å…¨ï¼Œå°¤å…¶æ˜¯åœ¨å®æ—¶è¯­ä¹‰åˆ†å‰²çš„æƒ…å†µä¸‹ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸æ˜¯åˆ©ç”¨å°çš„è¾“å…¥å›¾åƒæˆ–è€…è½»é‡ä¸»å¹²æ¨¡å‹å®ç°åŠ é€Ÿã€‚ä½†æ˜¯å°å›¾åƒç›¸è¾ƒäºåŸå›¾åƒç¼ºå¤±äº†å¾ˆå¤šç©ºé—´ä¿¡æ¯ï¼Œè€Œè½»é‡çº§æ¨¡å‹åˆ™ç”±äºè£å‰ªé€šé“è€ŒæŸå®³äº†ç©ºé—´ä¿¡æ¯ã€‚BiSegNetæ•´åˆäº†Spatial Path (SP) å’Œ Context Path (CP)åˆ†åˆ«ç”¨æ¥è§£å†³ç©ºé—´ä¿¡æ¯ç¼ºå¤±å’Œæ„Ÿå—é‡ç¼©å°çš„é—®é¢˜ã€‚"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="article:published_time" content="2022-11-05T07:47:19.660Z"><meta data-react-helmet="true" property="article:author" content="https://gong.host"><meta data-react-helmet="true" property="article:tag" content="segmentation,light-weight"><link data-react-helmet="true" rel="shortcut icon" href="/img/logo.svg"><link data-react-helmet="true" rel="canonical" href="https://ml.akasaki.space//blog/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation"><link data-react-helmet="true" rel="alternate" href="https://ml.akasaki.space//blog/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation" hreflang="zh-cn"><link data-react-helmet="true" rel="alternate" href="https://ml.akasaki.space//blog/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.2aa28e4b.css">
<link rel="preload" href="/assets/js/runtime~main.70701027.js" as="script">
<link rel="preload" href="/assets/js/main.e4cdc564.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Logo" class="themedImage_TMUO themedImage--light_4Vu1"><img src="/img/logo.svg" alt="Logo" class="themedImage_TMUO themedImage--dark_uzRr"></div><b class="navbar__title">å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">é­”æ³•éƒ¨æ—¥å¿—</a><a href="https://github.com/neet-cv/ml.akasaki.space" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/about">Authors &amp; About</a><a href="https://gong.host" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>YetAnotherAkasaki<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_iYfV toggle_2i4l toggleDisabled_xj38"><div class="toggleTrack_t-f2" role="button" tabindex="-1"><div class="toggleTrackCheck_mk7D"><span class="toggleIcon_pHJ9">ğŸŒœ</span></div><div class="toggleTrackX_dm8H"><span class="toggleIcon_pHJ9">ğŸŒ</span></div><div class="toggleTrackThumb_W6To"></div></div><input type="checkbox" class="toggleScreenReader_h9qa" aria-label="Switch between dark and light mode"></div><div class="navbar__search searchBarContainer_I7kZ"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_Zg7X searchBarLoadingRing_J5Ez"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_CDc6"><kbd class="searchHint_2RRg">ctrl</kbd><kbd class="searchHint_2RRg">K</kbd></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-post-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_q+wC thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_9G5K margin-bottom--md">All posts</div><ul class="sidebarItemList_6T4b"><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[42]CCNet-Criss-Cross-Attention-for-Semantic-Segmentation">CCNet - Criss-Cross Attention for Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[43]RepVGG-Making-VGG-style-ConvNets-Great-Again">RepVGG - Making VGG-style ConvNets Great Again</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[44]PP-LCNet-A-Lightweight-CPU-Convolutional-Neural-Network">PP-LCNet - A Lightweight CPU Convolutional Neural Network</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[45]Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows">Swin Transformer - Hierarchical Vision Transformer using Shifted Windows</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[46]Demystifying-Local-Vision-Transformer">Demystifying Local Vision Transformer</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[47]Discrete-Cosine-Transform-Mask-Representation-for-Instance-Segmentation">DCT-Mask - Discrete Cosine Transform Mask Representation for Instance Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[48]Deep-Retinex-Decomposition-for-Low-Light-Enhancement">Deep Retinex Decomposition for Low-Light Enhancement</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[49]GhostNet-More-Features-from-Cheap-Operations">GhostNet - More Features from Cheap Operations</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[50]Kindling-the-Darkness-A-Practical-Low-light-Image-Enhancer">Kindling the Darkness - A Practical Low-light Image Enhancer</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[51]How-much-Position-Information-Do-Convolutional-Neural-Networks-Encode">How much Position Information Do Convolutional Neural Networks Encode?</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[52]Axiomatic-Attribution-for-Deep-Networks">Axiomatic Attribution for Deep Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[00]unlimited-paper-works">æ¬¢è¿æ¥åˆ°é­”æ³•éƒ¨æ—¥å¿—</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[01]The-Devil-is-in-the-Decoder-Classification-Regression-and-GANs">The Devil is in the Decoder - Classification, Regression and GANs</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[02]Threat-of-Adversarial-Attacks-on-Deep-Learning-in-Computer-Vision-A-Survey">Threat of Adversarial Attacks on Deep Learning in Computer Vision - A Survey</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[03]Progressive-Semantic-Segmentation">Progressive Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[04]Decoders-Matter-for-Semantic-Segmentation-Data-Dependent-Decoding-Enables-Flexible-Feature-Aggregation">Decoders Matter for Semantic Segmentation - Data-Dependent Decoding Enables Flexible Feature Aggregation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[05]HLA-Face-Joint-High-Low-Adaptation-for-Low-Light-Face-Detection">HLA-Face Joint High-Low Adaptation for Low Light Face Detection</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[06]DeepLab-Series">DeepLab Series</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[07]Cross-Dataset-Collaborative-Learning-for-Semantic-Segmentation">Cross-Dataset Collaborative Learning for Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[08]Dynamic-Neural-Networks-A-Survey">Dynamic Neural Networks - A Survey</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[09]Feature-Pyramid-Networks-for-Object-Detection">Feature Pyramid Networks for Object Detection</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[10]Overview-Of-Semantic-Segmentation">A Review on Deep Learning Techniques Applied to Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[12]MobileNetV2-Inverted-Residuals-and-Linear-bottleneck">MobileNetV2 - Inverted Residuals and Linear Bottlenecks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[13]Fast-SCNN-Fast-Semantic-Segmentation-Network">Fast-SCNN - Fast Semantic Segmentation Network</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[14]MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications">MobileNets - Efficient Convolutional Neural Networks for Mobile Vision Applications</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[15]Gated-Channel-Transformation-for-Visual-Recognition">Gated Channel Transformation for Visual Recognition</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[16]Convolutional-Block-Attention-Module">Convolutional Block Attention Module</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[17]Boundary-IoU-Improving-Object-Centri-Image-Segmentation-Evaluation">Boundary IoU - Improving Object-Centric Image Segmentation Evaluation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[18]Involution-Inverting-the-Inherence-of-Convolution-for-Visual-Recognition">Involution - Inverting the Inherence of Convolution for Visual Recognition</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[19]PointRend-Image-Segmentation-as-Rendering">PointRend - Image Segmentation as Rendering</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[20]Transformer-Attention-is-all-you-need">Transformer - Attention is all you need</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[21]RefineMask-Towards-High-Quality-Instance-Segmentationwith-Fine-Grained_Features">RefineMask - Towards High-Quality Instance Segmentationwith Fine-Grained Features</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[22]GLADNet-Low-Light-Enhancement-Network-with-Global-Awareness">GLADNet - Low-Light Enhancement Network with Global Awareness</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[23]Squeeze-and-Excitation-Networks">Squeeze-and-Excitation Networks</a></li><li class="sidebarItem_cjdF"><a aria-current="page" class="sidebarItemLink_zyXk sidebarItemLinkActive_wcJs" href="/blog/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation">BiSeNet - Bilateral Segmentation Network for Real-time Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[25]Rethinking-BiSeNet-For-Real-time-Semantic-Segmentation">Rethinking BiSeNet For Real-time Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[26]CBAM-Convolutional-Block-Attention-Module">CBAM - Convolutional Block Attention Module</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[27]Non-local-Neural-Networks">Non-local Neural Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[28]GCNet-Non-local-Networks-Meet-Squeeze-Excitation-Networks-and-Beyond">Non-local Networks Meet Squeeze-Excitation Networks and Beyond</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[29]Disentangled-Non-Local-Neural-Networks">Disentangled Non-Local Neural Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[30]RetinexNet-for-Low-Light-Enhancement">Deep Retinex Decomposition for Low-Light Enhancement</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[31]MSR-netLow-light-Image-Enhancement-Using-Deep-Convolutional-Network">MSR-net - Low-light Image Enhancement Using Deep Convolutional Network</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[32]LLCNN-A-Convolutional-Neural-Network-for-Low-light-Image-Enhancement">LLCNN - A convolutional neural network for low-light image enhancement</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[33]VOLO-Vision-Outlooker-for-Visual-Recognition">VOLO - Vision Outlooker for Visual Recognition</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[34]Polarized-Self-Attention-Towards-High-quality-Pixel-wise-Regression">Polarized Self-Attention - Towards High-quality Pixel-wise Regression</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[35]SimAM-A-Simple-Parameter-Free-Attention-Module-for-Convolutional-Neural-Networks">SimAM - A Simple, Parameter-Free Attention Module for Convolutional Neural Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[36]SOLO-Segmenting-Objects-by-Locations">SOLO - Segmenting Objects by Locations</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[37]YOLACT-Real-time-Instance-Segmentation">YOLACT - Real-time Instance Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[38]You-Only-Look-One-level-Feature">You Only Look One-level Feature</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[39]Instance-sensitive-Fully-Convolutional-Networks">Instance-sensitive Fully Convolutional Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[40]Learning-in-the-Frequency-Domain">Learning in the Frequency Domain</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_d4p0" itemprop="headline">BiSeNet - Bilateral Segmentation Network for Real-time Semantic Segmentation</h1><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/visualDust.png" alt="Gavin Gong"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Gavin Gong</span></a></div><small class="avatar__subtitle" itemprop="description">Rubbish CVer | Poor LaTex speaker | Half stack developer | é”®åœˆèººå°¸ç –å®¶</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>BiSeNetçš„ç›®æ ‡æ˜¯æ›´å¿«é€Ÿçš„å®æ—¶è¯­ä¹‰åˆ†å‰²ã€‚åœ¨è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸­ï¼Œç©ºé—´åˆ†è¾¨ç‡å’Œæ„Ÿå—é‡å¾ˆéš¾ä¸¤å…¨ï¼Œå°¤å…¶æ˜¯åœ¨å®æ—¶è¯­ä¹‰åˆ†å‰²çš„æƒ…å†µä¸‹ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸æ˜¯åˆ©ç”¨å°çš„è¾“å…¥å›¾åƒæˆ–è€…è½»é‡ä¸»å¹²æ¨¡å‹å®ç°åŠ é€Ÿã€‚ä½†æ˜¯å°å›¾åƒç›¸è¾ƒäºåŸå›¾åƒç¼ºå¤±äº†å¾ˆå¤šç©ºé—´ä¿¡æ¯ï¼Œè€Œè½»é‡çº§æ¨¡å‹åˆ™ç”±äºè£å‰ªé€šé“è€ŒæŸå®³äº†ç©ºé—´ä¿¡æ¯ã€‚BiSegNetæ•´åˆäº†Spatial Path (SP) å’Œ Context Path (CP)åˆ†åˆ«ç”¨æ¥è§£å†³ç©ºé—´ä¿¡æ¯ç¼ºå¤±å’Œæ„Ÿå—é‡ç¼©å°çš„é—®é¢˜ã€‚</p><blockquote><p>Semantic segmentation requires both rich spatial information and sizeable receptive field. However, modern approaches usually compromise spatial resolution to achieve real-time inference speed, which leads to poor performance. In this paper, we address this dilemma with a novel Bilateral Segmentation Network (BiSeNet). We first design a Spatial Path with a small stride to preserve the spatial information and generate high-resolution features. Meanwhile, a Context Path with a fast downsampling strategy is employed to obtain sufficient receptive field. On top of the two paths, we introduce a new Feature Fusion Module to combine features efficiently. The proposed architecture makes a right balance between the speed and segmentation performance on Cityscapes, CamVid, and COCO-Stuff datasets. Specifically, for a 2048x1024 input, we achieve 68.4% Mean IOU on the Cityscapes test dataset with speed of 105 FPS on one NVIDIA Titan XP card, which is significantly faster than the existing methods with comparable performance.</p></blockquote><p>è®ºæ–‡åŸæ–‡ï¼š<a href="https://arxiv.org/abs/1808.00897" target="_blank" rel="noopener noreferrer">BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation</a>ã€‚é˜…è¯»åä½ ä¼šå‘ç°ï¼Œè¿™ç¯‡è®ºæ–‡æœ‰å¾ˆå¤šæ€è·¯å—åˆ°<a href="/blog/[23]Squeeze-and-Excitation-Networks">SENetï¼ˆSqueeze-and-Excitation Networksï¼‰</a>çš„å¯å‘ã€‚</p><hr><h2 class="anchor anchorWithStickyNavbar_y2LR" id="è®¾è®¡ç›®çš„å’Œæ€è·¯">è®¾è®¡ç›®çš„å’Œæ€è·¯<a aria-hidden="true" class="hash-link" href="#è®¾è®¡ç›®çš„å’Œæ€è·¯" title="Direct link to heading">â€‹</a></h2><p>åœ¨ä»¥å¾€çš„å·¥ä½œä¸­ï¼Œä¸ºäº†å¯¹ç½‘ç»œè¿›è¡ŒåŠ é€Ÿä»¥è¾¾åˆ°å®æ—¶çš„ç›®çš„ï¼Œç ”ç©¶è€…ä»¬å¾€å¾€ä¼šé€‰æ‹©æŠ˜ä¸­ç²¾åº¦ä»¥æ±‚é€Ÿåº¦ï¼š</p><ol><li>é€šè¿‡å‰ªè£æˆ– resize æ¥é™å®šè¾“å…¥å¤§å°ï¼Œä»¥é™ä½è®¡ç®—å¤æ‚åº¦ã€‚å°½ç®¡è¿™ç§æ–¹æ³•ç®€å•è€Œæœ‰æ•ˆï¼Œç©ºé—´ç»†èŠ‚çš„æŸå¤±è¿˜æ˜¯è®©é¢„æµ‹æ‰“äº†æŠ˜æ‰£ï¼Œå°¤å…¶æ˜¯è¾¹ç•Œéƒ¨åˆ†ï¼Œå¯¼è‡´åº¦é‡å’Œå¯è§†åŒ–çš„ç²¾åº¦ä¸‹é™ï¼›</li><li>é€šè¿‡å‡å°‘ç½‘ç»œé€šé“æ•°é‡åŠ å¿«å¤„ç†é€Ÿåº¦ï¼Œå°¤å…¶æ˜¯åœ¨éª¨å¹²æ¨¡å‹çš„æ—©æœŸé˜¶æ®µï¼Œä½†æ˜¯è¿™ä¼šå¼±åŒ–ç©ºé—´ä¿¡æ¯ã€‚</li><li>ä¸ºè¿½æ±‚æå…¶ç´§å‡‘çš„æ¡†æ¶è€Œä¸¢å¼ƒæ¨¡å‹çš„æœ€åé˜¶æ®µï¼ˆæ¯”å¦‚ENetï¼‰ã€‚è¯¥æ–¹æ³•çš„ç¼ºç‚¹ä¹Ÿå¾ˆæ˜æ˜¾ï¼šç”±äº ENet æŠ›å¼ƒäº†æœ€åé˜¶æ®µçš„ä¸‹é‡‡æ ·ï¼Œæ¨¡å‹çš„æ„Ÿå—é‡ä¸è¶³ä»¥æ¶µç›–å¤§ç‰©ä½“ï¼Œå¯¼è‡´åˆ¤åˆ«èƒ½åŠ›è¾ƒå·®ã€‚</li></ol><p><img alt="image-20210704101433666" src="/assets/images/image-20210704101433666-123c7f576017c475fb4fa8e3a507b61e.png"></p><p>ä¸Šå›¾ä¸­å·¦ä¾§æ˜¯å‰ªè£å’Œresizeæ–¹æ³•çš„ç¤ºæ„ï¼Œå³ä¾§æ˜¯è·‘å»éƒ¨åˆ†ç»“æ„æˆ–å‡å°‘é€šé“çš„ç¤ºæ„ã€‚ä¸ºè§£å†³ä¸Šè¿°ç©ºé—´ä¿¡æ¯ç¼ºå¤±é—®é¢˜ï¼Œç ”ç©¶è€…æ™®éé‡‡ç”¨ U å½¢ç»“æ„ã€‚é€šè¿‡èåˆ backbone ç½‘ç»œä¸åŒå±‚çº§çš„ç‰¹å¾ï¼ŒU å½¢ç»“æ„é€æ¸å¢åŠ äº†ç©ºé—´åˆ†è¾¨ç‡ï¼Œå¹¶å¡«è¡¥äº†ä¸€äº›é—å¤±çš„ç»†èŠ‚ã€‚</p><p><img alt="image-20210704102757859" src="/assets/images/image-20210704102757859-98a380bdd1662da7f682da3048fd1a5e.png"></p><p>ä¸Šå›¾æ˜¯ä¸€ç§å…¸å‹çš„Uå‹ç»“æ„ã€‚ä½†æ˜¯ï¼Œè¿™ä¸€æŠ€æœ¯æœ‰ä¸¤ä¸ªå¼±ç‚¹ï¼š</p><ol><li>ç”±äºé«˜åˆ†è¾¨ç‡ç‰¹å¾å›¾ä¸Šé¢å¤–è®¡ç®—é‡çš„å¼•å…¥ï¼Œå®Œæ•´çš„ U å½¢ç»“æ„æ‹–æ…¢äº†æ¨¡å‹çš„é€Ÿåº¦ã€‚</li><li>ç»å¤§å¤šæ•°ç”±äºè£å‰ªè¾“å…¥æˆ–è€…å‡å°‘ç½‘ç»œé€šé“è€Œä¸¢å¤±çš„ç©ºé—´ä¿¡æ¯æ— æ³•é€šè¿‡å¼•å…¥æµ…å±‚è€Œè½»æ˜“å¤åŸã€‚æ¢è¨€ä¹‹ï¼ŒU å½¢ç»“æ„é¡¶å¤šæ˜¯ä¸€ä¸ªå¤‡é€‰æ–¹æ³•ï¼Œè€Œä¸æ˜¯æœ€ç»ˆçš„è§£å†³æ–¹æ¡ˆã€‚</li></ol><p>åŸºäºä¸Šè¿°è§‚å¯Ÿï¼Œæœ¬æ–‡æå‡ºäº†åŒå‘åˆ†å‰²ç½‘ç»œBiSeNetï¼ˆBilateral Segmentation Networkï¼‰ï¼Œå…¶ä¸»è¦çš„æ”¹è¿›æœ‰ï¼š</p><ul><li>åŒæ—¶ä½¿ç”¨Spatial Path (SP) å’Œ Context Path (CP)ï¼Œå…¼é¡¾ç©ºé—´å±æ€§å’Œæ„Ÿå—é‡</li><li>æå‡ºç‰¹å¾èåˆæ¨¡å—ï¼ˆFeature Fusion Module/FFMï¼‰ç”¨äºæ›´å¥½åœ°èåˆSPå’ŒCPçš„ç‰¹å¾</li><li>æå‡ºæ³¨æ„åŠ›ä¼˜åŒ–æ¨¡å—ï¼ˆAttention Refinement Module/ARMï¼‰</li></ul><p>ä¸‹å›¾ä¸ºBiSeNetçš„ç»“æ„ç¤ºæ„å›¾ï¼š</p><p><img alt="image-20210704102830425" src="/assets/images/image-20210704102830425-4704ba1016a5406ad789ef27aed50af9.png"></p><p>å®ƒåŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼šSpatial Path (SP) å’Œ Context Path (CP)ã€‚é¡¾åæ€ä¹‰ï¼Œè¿™ä¸¤ä¸ªç»„ä»¶åˆ†åˆ«ç”¨æ¥è§£å†³ç©ºé—´ä¿¡æ¯ç¼ºå¤±å’Œæ„Ÿå—é‡ç¼©å°çš„é—®é¢˜ã€‚å¯¹äº Spatial Pathï¼Œè®ºæ–‡ä¸­åªå åŠ ä¸‰ä¸ªå·ç§¯å±‚ä»¥è·å¾— 1/8 ç‰¹å¾å›¾ï¼Œå…¶ä¿ç•™ç€ä¸°å¯Œçš„ç©ºé—´ç»†èŠ‚ã€‚å¯¹äº Context Pathï¼Œæœ¬æ–‡åœ¨<a href="//todo" target="_blank" rel="noopener noreferrer">Xception</a>å°¾éƒ¨é™„åŠ ä¸€ä¸ªå…¨å±€å¹³å‡æ± åŒ–å±‚ï¼Œå…¶ä¸­æ„Ÿå—é‡æ˜¯ backbone ç½‘ç»œçš„æœ€å¤§å€¼ã€‚</p><p><img alt="image-20210704103510162" src="/assets/images/image-20210704103510162-b07bae6fce147f59d2928542cb6b59b2.png"></p><p>ä¸Šå›¾æ˜¯ä»¥ä¸Šä¸‰ç§æ€è·¯æ”¾åœ¨ä¸€èµ·çš„å¯¹æ¯”å›¾ã€‚åœ¨è¿½æ±‚æ›´å¿«ã€æ›´å¥½æ¨¡å‹çš„è¿‡ç¨‹ä¸­ï¼Œè®ºæ–‡ä¹Ÿç ”ç©¶äº†ä¸¤ä¸ªç»„ä»¶çš„èåˆï¼Œä»¥åŠæœ€åé¢„æµ‹çš„ä¼˜åŒ–ï¼Œå¹¶åˆ†åˆ«æå‡ºç‰¹å¾èåˆæ¨¡å—FFMï¼ˆFeature Fusion Moduleï¼‰å’Œæ³¨æ„åŠ›ä¼˜åŒ–æ¨¡å—ARMï¼ˆAttention Refinement Moduleï¼‰ï¼Œè¿™ä¸¤ä¸ªæ¨¡å—è¿›ä¸€æ­¥ä»æ•´ä½“ä¸Šæå‡äº†è¯­ä¹‰åˆ†å‰²çš„ç²¾åº¦ã€‚</p><hr><h2 class="anchor anchorWithStickyNavbar_y2LR" id="ç½‘ç»œç»“æ„è®¾è®¡">ç½‘ç»œç»“æ„è®¾è®¡<a aria-hidden="true" class="hash-link" href="#ç½‘ç»œç»“æ„è®¾è®¡" title="Direct link to heading">â€‹</a></h2><p><img alt="image-20210704141854108" src="/assets/images/image-20210704141854108-1028f8624ca37778cd9f846bebfdd718.png"></p><p>ä¸Šå›¾æ˜¯BiSeNetçš„ç½‘ç»œç»“æ„ã€‚å¯ä»¥çœ‹åˆ°å…¶é‡è¦ç»„æˆéƒ¨åˆ†Spatial Pathã€Context Pathä»¥åŠä¸¤ä¸ªä¼˜åŒ–æ¨¡å—Attention Refinementï¼ˆåŸå›¾ä¸­æ‰“é”™äº†å•è¯ï¼‰ã€Feature Fusion Moduleã€‚</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="spatial-path">Spatial Path<a aria-hidden="true" class="hash-link" href="#spatial-path" title="Direct link to heading">â€‹</a></h3><p>åœ¨è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸­ï¼Œç©ºé—´åˆ†è¾¨ç‡å’Œæ„Ÿå—é‡å¾ˆéš¾ä¸¤å…¨ï¼Œå°¤å…¶æ˜¯åœ¨å®æ—¶è¯­ä¹‰åˆ†å‰²çš„æƒ…å†µä¸‹ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸æ˜¯åˆ©ç”¨å°çš„è¾“å…¥å›¾åƒæˆ–è€…è½»é‡ä¸»å¹²æ¨¡å‹å®ç°åŠ é€Ÿã€‚ä½†æ˜¯å°å›¾åƒç›¸è¾ƒäºåŸå›¾åƒç¼ºå¤±äº†å¾ˆå¤šç©ºé—´ä¿¡æ¯ï¼Œè€Œè½»é‡çº§æ¨¡å‹åˆ™ç”±äºè£å‰ªé€šé“è€ŒæŸå®³äº†ç©ºé—´ä¿¡æ¯ã€‚</p><p><img alt="image-20210704144527369" src="/assets/images/image-20210704144527369-7907d3f07d3299bf8f8518bdbb813225.png"></p><p>åœ¨åŸè®ºæ–‡ä¸­ï¼Œä¸ºäº†ä¿æŒå……è¶³çš„ç©ºé—´ä¿¡æ¯ï¼ŒSpatial PathåŒ…å«ä¸‰ä¸ªå±‚ï¼Œæ¯ä¸ªå±‚ç”±ä¸€ä¸ªæ­¥é•¿ä¸º2çš„å·ç§¯å’Œä¸€ä¸ªBNå±‚ä»¥åŠä¸€ä¸ªéçº¿æ€§çš„ReLUæ¿€æ´»å±‚æ„æˆã€‚è¿™æ ·åšä½¿å¾—Spatial Pathä»…å¯¹åŸå›¾è¿›è¡Œ1/8ä¸‹é‡‡æ ·ï¼Œä¿ç•™äº†ä¸°å¯Œçš„ç©ºé—´ä¿¡æ¯ã€‚</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="context-path">Context Path<a aria-hidden="true" class="hash-link" href="#context-path" title="Direct link to heading">â€‹</a></h3><p>åœ¨è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸­ï¼Œæ„Ÿå—é‡å¯¹äºæ€§èƒ½è¡¨ç°è‡³å…³é‡è¦ã€‚ä¸ºå¢å¤§æ„Ÿå—é‡ï¼Œä¸€äº›æ–¹æ³•åˆ©ç”¨é‡‘å­—å¡”æ± åŒ–æ¨¡å—ï¼Œé‡‘å­—å¡”å‹ç©ºæ´æ± åŒ–ï¼ˆASPPï¼‰æˆ–ä½¿ç”¨&quot;large kernel&quot;ï¼Œä½†æ˜¯è¿™äº›æ“ä½œæ¯”è¾ƒè€—è´¹è®¡ç®—å’Œå†…å­˜ï¼Œå¯¼è‡´é€Ÿåº¦æ…¢ï¼Œè¿™äº›ç¼ºç‚¹åœ¨å®æ—¶çš„ä»»åŠ¡ä¸Šå°¤ä¸ºçªå‡ºã€‚å‡ºäºè¾ƒå¤§æ„Ÿå—é‡å’Œè¾ƒé«˜è®¡ç®—æ•ˆç‡å…¼å¾—çš„è€ƒé‡ï¼Œæœ¬æ–‡æå‡º Context Pathï¼Œå®ƒå……åˆ†åˆ©ç”¨è½»é‡çº§æ¨¡å‹ä¸å…¨å±€å¹³å‡æ± åŒ–ä»¥æä¾›å¤§æ„Ÿå—é‡ã€‚</p><p><img alt="image-20210704145307009" src="/assets/images/image-20210704145307009-8cb05d3ce02ee8a6480ac21105f7d9ec.png"></p><p>åœ¨æœ¬å·¥ä½œä¸­ï¼Œè½»é‡çº§æ¨¡å‹ï¼Œæ¯”å¦‚ Xceptionï¼Œå¯ä»¥å¿«é€Ÿä¸‹é‡‡æ ·ç‰¹å¾å›¾ä»¥è·å¾—å¤§æ„Ÿå—é‡ï¼Œç¼–ç é«˜å±‚è¯­ä¹‰è¯­å¢ƒä¿¡æ¯ã€‚æ¥ç€ï¼Œæœ¬æ–‡åœ¨è½»é‡çº§æ¨¡å‹æœ«ç«¯æ·»åŠ ä¸€ä¸ªå…¨å±€å¹³å‡æ± åŒ–ï¼Œé€šè¿‡å…¨å±€è¯­å¢ƒä¿¡æ¯æä¾›ä¸€ä¸ªæœ€å¤§æ„Ÿå—é‡ã€‚åœ¨è½»é‡çº§æ¨¡å‹ä¸­ï¼Œæœ¬æ–‡å€ŸåŠ© U å½¢ç»“æ„èåˆæœ€åä¸¤ä¸ªé˜¶æ®µçš„ç‰¹å¾ï¼Œä½†è¿™ä¸æ˜¯ä¸€ä¸ªå®Œæ•´çš„ U å½¢ç»“æ„ã€‚å›¾ 2(c) å…¨é¢å±•ç¤ºäº† Context Pathã€‚</p><h4 class="anchor anchorWithStickyNavbar_y2LR" id="attention-refinement-module-arm">Attention Refinement Module (ARM)<a aria-hidden="true" class="hash-link" href="#attention-refinement-module-arm" title="Direct link to heading">â€‹</a></h4><p>åœ¨ Context Path ä¸­ï¼Œæœ¬æ–‡æå‡ºä¸€ä¸ªç‹¬ç‰¹çš„æ³¨æ„åŠ›ä¼˜åŒ–æ¨¡å—ï¼Œä»¥ä¼˜åŒ–æ¯ä¸€é˜¶æ®µçš„ç‰¹å¾ï¼š</p><p><img alt="image-20210704145528506" src="/assets/images/image-20210704145528506-6968338cc8150c82afd8ea1bd38cb0e2.png"></p><p>å¦‚ä¸Šå›¾æ‰€ç¤ºï¼ŒARM å€ŸåŠ©å…¨å±€å¹³å‡æ± åŒ–æ•è·å…¨å±€è¯­å¢ƒå¹¶è®¡ç®—æ³¨æ„åŠ›å‘é‡ä»¥æŒ‡å¯¼ç‰¹å¾å­¦ä¹ ã€‚è¿™ä¸€è®¾è®¡å¯ä»¥ä¼˜åŒ– Context Path ä¸­æ¯ä¸€é˜¶æ®µçš„è¾“å‡ºç‰¹å¾ï¼Œæ— éœ€ä»»ä½•ä¸Šé‡‡æ ·æ“ä½œå³å¯è½»æ˜“æ•´åˆå…¨å±€è¯­å¢ƒä¿¡æ¯ï¼Œå› æ­¤ï¼Œå…¶è®¡ç®—æˆæœ¬å‡ ä¹å¯å¿½ç•¥ã€‚</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="feature-fusion-module-ffm">Feature Fusion Module (FFM)<a aria-hidden="true" class="hash-link" href="#feature-fusion-module-ffm" title="Direct link to heading">â€‹</a></h3><p>åœ¨ç‰¹å¾è¡¨ç¤ºçš„å±‚é¢ä¸Šï¼Œä¸¤è·¯ç½‘ç»œçš„ç‰¹å¾å¹¶ä¸ç›¸åŒã€‚å› æ­¤ä¸èƒ½ç®€å•åœ°åŠ æƒè¿™äº›ç‰¹å¾ã€‚ç”± Spatial Pathæ•è·çš„ç©ºé—´ä¿¡æ¯ç¼–ç äº†ç»å¤§å¤šæ•°çš„ä¸°å¯Œç»†èŠ‚ä¿¡æ¯ã€‚è€Œ Context Path çš„è¾“å‡ºç‰¹å¾ä¸»è¦ç¼–ç è¯­å¢ƒä¿¡æ¯ã€‚æ¢è¨€ä¹‹ï¼ŒSpatial Path çš„è¾“å‡ºç‰¹å¾æ˜¯ä½å±‚çº§çš„ï¼ŒContext Path çš„è¾“å‡ºç‰¹å¾æ˜¯é«˜å±‚çº§çš„ã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºä¸€ä¸ªç‹¬ç‰¹çš„ç‰¹å¾èåˆæ¨¡å—ä»¥èåˆè¿™äº›ç‰¹å¾ã€‚</p><p><img alt="image-20210704150819590" src="/assets/images/image-20210704150819590-0779d2c320de89a502426a3240645cfb.png"></p><p>åœ¨ç‰¹å¾çš„ä¸åŒå±‚çº§ç»™å®šçš„æƒ…å†µä¸‹ï¼Œæœ¬æ–‡é¦–å…ˆè¿æ¥ Spatial Path å’Œ Context Path çš„è¾“å‡ºç‰¹å¾ï¼›æ¥ç€ï¼Œé€šè¿‡æ‰¹å½’ä¸€åŒ–å¹³è¡¡ç‰¹å¾çš„å°ºåº¦ã€‚ä¸‹ä¸€æ­¥ï¼Œåƒ<a href="/blog/[23]Squeeze-and-Excitation-Networks">SENet</a>ä¸€æ ·ï¼ŒæŠŠç›¸è¿æ¥çš„ç‰¹å¾æ± åŒ–ä¸ºä¸€ä¸ªç‰¹å¾å‘é‡ï¼Œå¹¶è®¡ç®—ä¸€ä¸ªæƒé‡å‘é‡ã€‚è¿™ä¸€æƒé‡å‘é‡å¯ä»¥é‡æ–°åŠ æƒç‰¹å¾ï¼Œèµ·åˆ°ç‰¹å¾é€‰æ‹©å’Œç»“åˆçš„ä½œç”¨ã€‚ä¸Šå›¾å±•ç¤ºäº†è¿™ä¸€è®¾è®¡çš„ç»†èŠ‚ã€‚</p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="å®éªŒ">å®éªŒ<a aria-hidden="true" class="hash-link" href="#å®éªŒ" title="Direct link to heading">â€‹</a></h2><p>å®éªŒéƒ¨åˆ†è¯·è‡ªè¡Œé˜…è¯»åŸè®ºæ–‡ã€‚</p></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_xD8n"><div class="col"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/segmentation">segmentation</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/light-weight">light-weight</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.dev/neet-cv/ml.akasaki.space/blob/master/blog/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_mS5F" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/[23]Squeeze-and-Excitation-Networks"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Â« <!-- -->Squeeze-and-Excitation Networks</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/[25]Rethinking-BiSeNet-For-Real-time-Semantic-Segmentation"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Rethinking BiSeNet For Real-time Semantic Segmentation<!-- --> Â»</div></a></div></nav></main><div class="col col--2"><div class="tableOfContents_vrFS thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#è®¾è®¡ç›®çš„å’Œæ€è·¯" class="table-of-contents__link toc-highlight">è®¾è®¡ç›®çš„å’Œæ€è·¯</a></li><li><a href="#ç½‘ç»œç»“æ„è®¾è®¡" class="table-of-contents__link toc-highlight">ç½‘ç»œç»“æ„è®¾è®¡</a><ul><li><a href="#spatial-path" class="table-of-contents__link toc-highlight">Spatial Path</a></li><li><a href="#context-path" class="table-of-contents__link toc-highlight">Context Path</a></li><li><a href="#feature-fusion-module-ffm" class="table-of-contents__link toc-highlight">Feature Fusion Module (FFM)</a></li></ul></li><li><a href="#å®éªŒ" class="table-of-contents__link toc-highlight">å®éªŒ</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2022 neet-cv. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.70701027.js"></script>
<script src="/assets/js/main.e4cdc564.js"></script>
</body>
</html>