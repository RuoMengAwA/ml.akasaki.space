<!doctype html>
<html lang="zh-cn" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.9">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿ RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿ Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.css" crossorigin="anonymous"><title data-react-helmet="true">One post tagged with &quot;transformer&quot; | å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿</title><meta data-react-helmet="true" property="og:title" content="One post tagged with &quot;transformer&quot; | å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://ml.akasaki.space//blog/tags/transformer"><meta data-react-helmet="true" name="docusaurus_locale" content="zh-cn"><meta data-react-helmet="true" name="docusaurus_tag" content="blog_tags_posts"><link data-react-helmet="true" rel="shortcut icon" href="/img/logo.svg"><link data-react-helmet="true" rel="canonical" href="https://ml.akasaki.space//blog/tags/transformer"><link data-react-helmet="true" rel="alternate" href="https://ml.akasaki.space//blog/tags/transformer" hreflang="zh-cn"><link data-react-helmet="true" rel="alternate" href="https://ml.akasaki.space//blog/tags/transformer" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.2aa28e4b.css">
<link rel="preload" href="/assets/js/runtime~main.70701027.js" as="script">
<link rel="preload" href="/assets/js/main.e4cdc564.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Logo" class="themedImage_TMUO themedImage--light_4Vu1"><img src="/img/logo.svg" alt="Logo" class="themedImage_TMUO themedImage--dark_uzRr"></div><b class="navbar__title">å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">é­”æ³•éƒ¨æ—¥å¿—</a><a href="https://github.com/neet-cv/ml.akasaki.space" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/about">Authors &amp; About</a><a href="https://gong.host" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>YetAnotherAkasaki<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_iYfV toggle_2i4l toggleDisabled_xj38"><div class="toggleTrack_t-f2" role="button" tabindex="-1"><div class="toggleTrackCheck_mk7D"><span class="toggleIcon_pHJ9">ğŸŒœ</span></div><div class="toggleTrackX_dm8H"><span class="toggleIcon_pHJ9">ğŸŒ</span></div><div class="toggleTrackThumb_W6To"></div></div><input type="checkbox" class="toggleScreenReader_h9qa" aria-label="Switch between dark and light mode"></div><div class="navbar__search searchBarContainer_I7kZ"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_Zg7X searchBarLoadingRing_J5Ez"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_CDc6"><kbd class="searchHint_2RRg">ctrl</kbd><kbd class="searchHint_2RRg">K</kbd></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-tags-post-list-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_q+wC thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_9G5K margin-bottom--md">All posts</div><ul class="sidebarItemList_6T4b"><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[42]CCNet-Criss-Cross-Attention-for-Semantic-Segmentation">CCNet - Criss-Cross Attention for Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[43]RepVGG-Making-VGG-style-ConvNets-Great-Again">RepVGG - Making VGG-style ConvNets Great Again</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[44]PP-LCNet-A-Lightweight-CPU-Convolutional-Neural-Network">PP-LCNet - A Lightweight CPU Convolutional Neural Network</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[45]Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows">Swin Transformer - Hierarchical Vision Transformer using Shifted Windows</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[46]Demystifying-Local-Vision-Transformer">Demystifying Local Vision Transformer</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[47]Discrete-Cosine-Transform-Mask-Representation-for-Instance-Segmentation">DCT-Mask - Discrete Cosine Transform Mask Representation for Instance Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[48]Deep-Retinex-Decomposition-for-Low-Light-Enhancement">Deep Retinex Decomposition for Low-Light Enhancement</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[49]GhostNet-More-Features-from-Cheap-Operations">GhostNet - More Features from Cheap Operations</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[50]Kindling-the-Darkness-A-Practical-Low-light-Image-Enhancer">Kindling the Darkness - A Practical Low-light Image Enhancer</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[51]How-much-Position-Information-Do-Convolutional-Neural-Networks-Encode">How much Position Information Do Convolutional Neural Networks Encode?</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[52]Axiomatic-Attribution-for-Deep-Networks">Axiomatic Attribution for Deep Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[00]unlimited-paper-works">æ¬¢è¿æ¥åˆ°é­”æ³•éƒ¨æ—¥å¿—</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[01]The-Devil-is-in-the-Decoder-Classification-Regression-and-GANs">The Devil is in the Decoder - Classification, Regression and GANs</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[02]Threat-of-Adversarial-Attacks-on-Deep-Learning-in-Computer-Vision-A-Survey">Threat of Adversarial Attacks on Deep Learning in Computer Vision - A Survey</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[03]Progressive-Semantic-Segmentation">Progressive Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[04]Decoders-Matter-for-Semantic-Segmentation-Data-Dependent-Decoding-Enables-Flexible-Feature-Aggregation">Decoders Matter for Semantic Segmentation - Data-Dependent Decoding Enables Flexible Feature Aggregation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[05]HLA-Face-Joint-High-Low-Adaptation-for-Low-Light-Face-Detection">HLA-Face Joint High-Low Adaptation for Low Light Face Detection</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[06]DeepLab-Series">DeepLab Series</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[07]Cross-Dataset-Collaborative-Learning-for-Semantic-Segmentation">Cross-Dataset Collaborative Learning for Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[08]Dynamic-Neural-Networks-A-Survey">Dynamic Neural Networks - A Survey</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[09]Feature-Pyramid-Networks-for-Object-Detection">Feature Pyramid Networks for Object Detection</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[10]Overview-Of-Semantic-Segmentation">A Review on Deep Learning Techniques Applied to Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[12]MobileNetV2-Inverted-Residuals-and-Linear-bottleneck">MobileNetV2 - Inverted Residuals and Linear Bottlenecks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[13]Fast-SCNN-Fast-Semantic-Segmentation-Network">Fast-SCNN - Fast Semantic Segmentation Network</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[14]MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications">MobileNets - Efficient Convolutional Neural Networks for Mobile Vision Applications</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[15]Gated-Channel-Transformation-for-Visual-Recognition">Gated Channel Transformation for Visual Recognition</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[16]Convolutional-Block-Attention-Module">Convolutional Block Attention Module</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[17]Boundary-IoU-Improving-Object-Centri-Image-Segmentation-Evaluation">Boundary IoU - Improving Object-Centric Image Segmentation Evaluation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[18]Involution-Inverting-the-Inherence-of-Convolution-for-Visual-Recognition">Involution - Inverting the Inherence of Convolution for Visual Recognition</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[19]PointRend-Image-Segmentation-as-Rendering">PointRend - Image Segmentation as Rendering</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[20]Transformer-Attention-is-all-you-need">Transformer - Attention is all you need</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[21]RefineMask-Towards-High-Quality-Instance-Segmentationwith-Fine-Grained_Features">RefineMask - Towards High-Quality Instance Segmentationwith Fine-Grained Features</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[22]GLADNet-Low-Light-Enhancement-Network-with-Global-Awareness">GLADNet - Low-Light Enhancement Network with Global Awareness</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[23]Squeeze-and-Excitation-Networks">Squeeze-and-Excitation Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation">BiSeNet - Bilateral Segmentation Network for Real-time Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[25]Rethinking-BiSeNet-For-Real-time-Semantic-Segmentation">Rethinking BiSeNet For Real-time Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[26]CBAM-Convolutional-Block-Attention-Module">CBAM - Convolutional Block Attention Module</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[27]Non-local-Neural-Networks">Non-local Neural Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[28]GCNet-Non-local-Networks-Meet-Squeeze-Excitation-Networks-and-Beyond">Non-local Networks Meet Squeeze-Excitation Networks and Beyond</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[29]Disentangled-Non-Local-Neural-Networks">Disentangled Non-Local Neural Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[30]RetinexNet-for-Low-Light-Enhancement">Deep Retinex Decomposition for Low-Light Enhancement</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[31]MSR-netLow-light-Image-Enhancement-Using-Deep-Convolutional-Network">MSR-net - Low-light Image Enhancement Using Deep Convolutional Network</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[32]LLCNN-A-Convolutional-Neural-Network-for-Low-light-Image-Enhancement">LLCNN - A convolutional neural network for low-light image enhancement</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[33]VOLO-Vision-Outlooker-for-Visual-Recognition">VOLO - Vision Outlooker for Visual Recognition</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[34]Polarized-Self-Attention-Towards-High-quality-Pixel-wise-Regression">Polarized Self-Attention - Towards High-quality Pixel-wise Regression</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[35]SimAM-A-Simple-Parameter-Free-Attention-Module-for-Convolutional-Neural-Networks">SimAM - A Simple, Parameter-Free Attention Module for Convolutional Neural Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[36]SOLO-Segmenting-Objects-by-Locations">SOLO - Segmenting Objects by Locations</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[37]YOLACT-Real-time-Instance-Segmentation">YOLACT - Real-time Instance Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[38]You-Only-Look-One-level-Feature">You Only Look One-level Feature</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[39]Instance-sensitive-Fully-Convolutional-Networks">Instance-sensitive Fully Convolutional Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[40]Learning-in-the-Frequency-Domain">Learning in the Frequency Domain</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><header class="margin-bottom--xl"><h1>One post tagged with &quot;transformer&quot;</h1><a href="/blog/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[45]Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows">Swin Transformer - Hierarchical Vision Transformer using Shifted Windows</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.664Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/AsTheStarsFalll.png" alt="AsTheStarsFall"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">AsTheStarsFall</span></a></div><small class="avatar__subtitle" itemprop="description">None</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>åˆ†å±‚Local Vision Transformerï¼Œé€šç”¨ä¸»å¹²ç½‘ç»œï¼Œå„ç±»ä¸‹æ¸¸ä»»åŠ¡å®ç°SOTAã€‚Best Paper Award!</p><blockquote><p>è®ºæ–‡åç§°ï¼š<a href="https://arxiv.org/abs/2103.14030" target="_blank" rel="noopener noreferrer">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</a></p><p>ä½œè€…ï¼šZe Liu ï¼ŒYutong Linï¼ŒYue Caoï¼ŒHan Huï¼ŒYixuan Weiï¼ŒZheng Zhangï¼ŒStephen Linï¼ŒBaining Guo</p><p>Codeï¼š<a href="https://github.com/microsoft/Swin-Transformer" target="_blank" rel="noopener noreferrer">https://github.com/microsoft/Swin-Transformer</a></p></blockquote><h2 class="anchor anchorWithStickyNavbar_y2LR" id="ä»‹ç»">ä»‹ç»<a aria-hidden="true" class="hash-link" href="#ä»‹ç»" title="Direct link to heading">â€‹</a></h2><p>è‡ªAlexNetä»¥æ¥ï¼ŒCNNä½œä¸ºéª¨å¹²ï¼ˆbackboneï¼‰åœ¨è®¡ç®—æœºè§†è§‰ä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ï¼›å¦ä¸€æ–¹é¢ï¼Œè‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ç½‘ç»œç»“æ„çš„æ¼”å˜åˆ™èµ°äº†ä¸€æ¡ä¸åŒçš„é“è·¯ï¼Œç°åœ¨çš„ä¸»æµç»“æ„æ˜¯Transformerã€‚</p><p>Transformeræ˜¯ä¸ºåºåˆ—å»ºæ¨¡å’Œè½¬æ¢ä»»åŠ¡è€Œè®¾è®¡çš„ï¼Œå®ƒä»¥å…³æ³¨æ•°æ®ä¸­çš„é•¿æœŸä¾èµ–å…³ç³»è€Œè‘—ç§°ã€‚å…¶åœ¨NLPé¢†åŸŸçš„å·¨å¤§æˆåŠŸå¸å¼•äº†äººä»¬ç ”ç©¶å®ƒå¯¹CVçš„é€‚åº”æ€§ï¼Œæœ€è¿‘çš„å®éªŒæ˜¾ç¤ºå…¶åœ¨å›¾åƒåˆ†ç±»å’Œè”åˆè§†è§‰è¯­è¨€å»ºæ¨¡æ–¹é¢æœ‰æ‰€æˆæ•ˆã€‚</p><p>æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®æœ‰ï¼š</p><ol><li>æå‡ºäº†ä¸€ç§åˆ†å±‚Transformerï¼Œå…¶å¯ä»¥ä½œä¸ºè®¡ç®—æœºè§†è§‰çš„é€šç”¨ä¸»å¹²ç½‘ç»œï¼Œå¹¶ä¸”åœ¨å„ç±»ä¸‹æ¸¸ä»»åŠ¡ä¸Šå–å¾—SOTAï¼›</li><li>é€šè¿‡Shift Windowså®ç°äº†å¯¹è¾“å…¥å›¾åƒå°ºå¯¸çš„çº¿æ€§æ—¶é—´å¤æ‚åº¦ã€‚</li></ol><img src="https://gitee.com/Thedeadleaf/images/raw/master/image-20211020204110669.png" alt="image-20211020204110669"></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/transformer">transformer</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/inductive-bias">inductive-bias</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Swin Transformer - Hierarchical Vision Transformer using Shifted Windows" href="/blog/[45]Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[46]Demystifying-Local-Vision-Transformer">Demystifying Local Vision Transformer</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.664Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/AsTheStarsFalll.png" alt="AsTheStarsFall"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">AsTheStarsFall</span></a></div><small class="avatar__subtitle" itemprop="description">None</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>ä»ç¨€ç–è¿æ¥æ€§ã€æƒé‡å…±äº«ã€åŠ¨æ€æƒé‡è¿›ä¸€æ­¥æ¢ç©¶Local Attentionã€‚</p><blockquote><p>è®ºæ–‡åç§°ï¼šDemystifying Local Vision Transformer: Sparse Connectivity, Weight Sharing, and Dynamic Weight</p><p>ä½œè€…ï¼šQi Han1ï¼ŒZejia Fanï¼ŒQi Daiï¼ŒLei Sunï¼ŒMing-Ming Chengï¼ŒJiaying Liuï¼ŒJingdong Wang</p><p>Codeï¼š<a href="https://github.com/Atten4Vis/DemystifyLocalViT/" target="_blank" rel="noopener noreferrer">https://github.com/Atten4Vis/DemystifyLocalViT/</a></p></blockquote><h2 class="anchor anchorWithStickyNavbar_y2LR" id="ä»‹ç»">ä»‹ç»<a aria-hidden="true" class="hash-link" href="#ä»‹ç»" title="Direct link to heading">â€‹</a></h2><p>æœ¬æ–‡çš„ä¸»è¦æˆæœå‘ç°ï¼ˆfindingï¼‰å¦‚ä¸‹ï¼š</p><ol><li><p>Local Transformeré‡‡ç”¨çš„Local Attentionåˆ©ç”¨äº†ç°æœ‰çš„æ­£åˆ™åŒ–æ–¹æ¡ˆï¼ˆregularization schemesï¼‰ã€ç¨€ç–è¿æ¥ï¼ˆsparse connectivity ï¼‰ã€æƒé‡å…±äº«ï¼ˆweight sharingï¼‰ä»¥åŠåŠ¨æ€æƒé‡é¢„æµ‹ï¼ˆdynamic weight predictionï¼‰ï¼Œåœ¨ä¸éœ€è¦é¢å¤–å¢åŠ æ¨¡å‹å¤æ‚åº¦å’Œè®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹å¢åŠ æ€§èƒ½ï¼›</p></li><li><p>å±€éƒ¨æ³¨æ„åŠ›ï¼ˆLocal Attentionï¼‰ä¸ï¼ˆåŠ¨æ€ï¼‰æ·±åº¦å·ç§¯ï¼ˆ(dynamic )depth-wise convolutionï¼‰åœ¨ç¨€ç–è¿æ¥æ€§ä¸Š<strong>ç›¸ä¼¼</strong>ï¼Œåœ¨æƒé‡å…±äº«å’ŒåŠ¨æ€æƒé‡é¢„æµ‹ä¸Šä¸åŒã€‚</p><p>å®éªŒç»“æœè¡¨æ˜ï¼Œå±€éƒ¨æ³¨æ„åŠ›å’Œï¼ˆåŠ¨æ€ï¼‰æ·±åº¦å·ç§¯æ‰€é‡‡ç”¨çš„æ­£åˆ™åŒ–å½¢å¼å’ŒåŠ¨æ€æƒé‡é¢„æµ‹æ–¹æ¡ˆå…·æœ‰<strong>ç›¸ä¼¼</strong>çš„æ€§èƒ½ã€‚</p></li><li><p>æ­¤å¤–ï¼Œæå‡ºäº†ä¸€ä¸ªå…³ç³»å›¾æ¥è”ç³»å·ç§¯å’Œæ³¨æ„åŠ›ï¼ŒåŒæ—¶å¼€å‘äº†åŸºäºMLPçš„æ–¹æ³•ã€‚</p><p>å…³ç³»å›¾è¡¨æ˜ï¼Œè¿™äº›æ–¹æ³•æœ¬è´¨ä¸Šåˆ©ç”¨äº†ä¸åŒçš„ç¨€ç–è¿æ¥å’Œæƒé‡å…±äº«æ¨¡å¼ï¼Œå¯ä»¥é€‰æ‹©ä½¿ç”¨åŠ¨æ€æƒé‡é¢„æµ‹è¿›è¡Œæ¨¡å‹æ­£åˆ™åŒ–ã€‚</p></li></ol></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/transformer">transformer</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/dynamic-neural-network">dynamic-neural-network</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Demystifying Local Vision Transformer" href="/blog/[46]Demystifying-Local-Vision-Transformer"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[20]Transformer-Attention-is-all-you-need">Transformer - Attention is all you need</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/AsTheStarsFalll.png" alt="AsTheStarsFall"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">AsTheStarsFall</span></a></div><small class="avatar__subtitle" itemprop="description">None</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><blockquote><p>è®ºæ–‡åç§°ï¼š<a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="noopener noreferrer">Attention Is All you Need</a></p><p>ä½œè€…ï¼šAshish Vaswaniï¼ŒNoam Shazeerï¼ŒNiki Parmarï¼ŒJakob Uszkoreitï¼ŒLlion Jonesï¼ŒAidan N. Gomezï¼ŒÅukasz Kaiserï¼ŒIllia Polosukhin</p><p>codeï¼š<a href="https://github.com/jadore801120/attention-is-all-you-need-pytorch/blob/master/transformer/Models.py" target="_blank" rel="noopener noreferrer">https://github.com/jadore801120/attention-is-all-you-need-pytorch/blob/master/transformer/Models.py</a></p></blockquote><h2 class="anchor anchorWithStickyNavbar_y2LR" id="å‰è¨€">å‰è¨€<a aria-hidden="true" class="hash-link" href="#å‰è¨€" title="Direct link to heading">â€‹</a></h2><p>åŸºäºRNNæˆ–CNNçš„Encoder-Decoderæ¨¡å‹åœ¨NLPé¢†åŸŸå æ®å¤§å£æ±Ÿå±±ï¼Œç„¶è€Œå¥¹ä»¬ä¹Ÿå¹¶éæ˜¯å®Œç¾æ— ç¼ºçš„ï¼š</p><ul><li>LSTMï¼ŒGRUç­‰RNNæ¨¡å‹å—é™äºå›ºæœ‰çš„å¾ªç¯é¡ºåºç»“æ„ï¼Œæ— æ³•å®ç°<strong>å¹¶è¡Œè®¡ç®—</strong>ï¼Œåœ¨åºåˆ—è¾ƒé•¿æ—¶ï¼Œè®¡ç®—æ•ˆç‡å°¤å…¶ä½ä¸‹ï¼Œè™½ç„¶æœ€è¿‘çš„å·¥ä½œå¦‚<a href="http://arxiv.org/abs/1703.10722" target="_blank" rel="noopener noreferrer">å› å­åˆ†è§£æŠ€å·§</a><sup id="fnref-1"><a href="#fn-1" class="footnote-ref">1</a></sup>ï¼Œ<a href="https://arxiv.org/abs/1701.06538" target="_blank" rel="noopener noreferrer">æ¡ä»¶è®¡ç®—</a><sup id="fnref-2"><a href="#fn-2" class="footnote-ref">2</a></sup>åœ¨ä¸€å®šç¨‹åº¦ä¸Šæé«˜äº†è®¡ç®—æ•ˆç‡å’Œæ€§èƒ½ï¼Œä½†æ˜¯é¡ºåºè®¡ç®—çš„é™åˆ¶ä¾ç„¶å­˜åœ¨ï¼›</li><li>Extended Neural GPU<sup id="fnref-3"><a href="#fn-3" class="footnote-ref">3</a></sup>,<a href="https://arxiv.org/abs/1610.10099" target="_blank" rel="noopener noreferrer">ByteNet</a><sup id="fnref-4"><a href="#fn-4" class="footnote-ref">4</a></sup>,å’Œ<a href="https://arxiv.org/abs/1705.03122" target="_blank" rel="noopener noreferrer">ConvS2S</a><sup id="fnref-5"><a href="#fn-5" class="footnote-ref">5</a></sup> ç­‰CNNæ¨¡å‹è™½ç„¶å¯ä»¥è¿›è¡Œå¹¶è¡Œè®¡ç®—ï¼Œä½†æ˜¯å­¦ä¹ ä»»æ„ä¸¤ä¸ªä½ç½®çš„ä¿¡å·çš„é•¿è·ç¦»å…³ç³»ä¾æ—§æ¯”è¾ƒå›°éš¾ï¼Œå…¶è®¡ç®—å¤æ‚åº¦éšè·ç¦»çº¿æ€§æˆ–å¯¹æ•°å¢é•¿ã€‚</li></ul><p>è€Œè°·æ­Œé€‰æ‹©æŠ›å¼ƒäº†ä¸»æµæ¨¡å‹å›ºæœ‰çš„ç»“æ„ï¼Œæå‡ºäº†<strong>å®Œå…¨</strong>åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„Transformerï¼Œæ‹¥æœ‰å…¶ä»–æ¨¡å‹æ— æ³•æ¯”æ‹Ÿçš„ä¼˜åŠ¿ï¼š</p><ul><li>Transformerå¯ä»¥é«˜æ•ˆçš„å¹¶è¡Œè®­ç»ƒï¼Œå› æ­¤é€Ÿåº¦ååˆ†å¿«ï¼Œåœ¨8ä¸ªGPUä¸Šè®­ç»ƒäº†3.5å¤©ï¼›</li><li>å¯¹äºé•¿è·ç¦»å…³ç³»çš„å­¦ä¹ ï¼ŒTransformerå°†æ—¶é—´å¤æ‚åº¦é™ä½åˆ°äº†å¸¸æ•°ï¼Œå¹¶ä¸”ä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æ¥æŠµæ¶ˆä½ç½®ä¿¡æ¯çš„å¹³å‡åŠ æƒé€ æˆçš„æœ‰æ•ˆåˆ†è¾¨ç‡é™ä½</li><li>Transformæ˜¯ä¸€ç§è‡ªç¼–ç ï¼ˆAuto-Encodingï¼‰æ¨¡å‹ï¼Œèƒ½å¤ŸåŒæ—¶åˆ©ç”¨ä¸Šä¸‹æ–‡</li></ul><h2 class="anchor anchorWithStickyNavbar_y2LR" id="æ•´ä½“ç»“æ„">æ•´ä½“ç»“æ„<a aria-hidden="true" class="hash-link" href="#æ•´ä½“ç»“æ„" title="Direct link to heading">â€‹</a></h2><p>Transfromerçš„æ•´ä½“ç»“æ„æ˜¯ä¸€ä¸ªEncoder-Decoderï¼Œè‡ªç¼–ç æ¨¡å‹ä¸»è¦åº”ç”¨äºè¯­æ„ç†è§£ï¼Œå¯¹äºç”Ÿæˆä»»åŠ¡è¿˜æ˜¯è‡ªå›å½’æ¨¡å‹æ›´æœ‰ä¼˜åŠ¿</p><p><img src="https://gitee.com/Thedeadleaf/images/raw/master/image-20210605151335569.png" alt="image-20210605151335569"></p><p>æˆ‘ä»¬å¯ä»¥å°†å…¶åˆ†ä¸ºå››ä¸ªéƒ¨åˆ†ï¼šè¾“å…¥ï¼Œç¼–ç å—ï¼Œè§£ç å—ä¸è¾“å‡º</p><p><img src="https://gitee.com/Thedeadleaf/images/raw/master/photo_2021-06-05_15-27-55.jpg"></p><p>æ¥ä¸‹æ¥è®©æˆ‘ä»¬æŒ‰ç…§é¡ºåºæ¥äº†è§£æ•´ä¸ªç»“æ„ï¼Œå¸Œæœ›åœ¨é˜…è¯»ä¸‹æ–‡å‰ä½ å¯ä»¥ä»”ç»†è§‚å¯Ÿè¿™å¹…å›¾ï¼Œé˜…è¯»æ—¶ä¹Ÿè¯·å‚è€ƒè¯¥å›¾</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/transformer">transformer</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Transformer - Attention is all you need" href="/blog/[20]Transformer-Attention-is-all-you-need"><b>Read More</b></a></div></footer></article></main></div></div></div><footer class="footer footer--dark"><div class="container"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2022 neet-cv. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.70701027.js"></script>
<script src="/assets/js/main.e4cdc564.js"></script>
</body>
</html>