<!doctype html>
<html lang="zh-cn" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.9">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿ RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿ Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.css" crossorigin="anonymous"><title data-react-helmet="true">One post tagged with &quot;fcn&quot; | å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿</title><meta data-react-helmet="true" property="og:title" content="One post tagged with &quot;fcn&quot; | å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://ml.akasaki.space//blog/tags/fcn"><meta data-react-helmet="true" name="docusaurus_locale" content="zh-cn"><meta data-react-helmet="true" name="docusaurus_tag" content="blog_tags_posts"><link data-react-helmet="true" rel="shortcut icon" href="/img/logo.svg"><link data-react-helmet="true" rel="canonical" href="https://ml.akasaki.space//blog/tags/fcn"><link data-react-helmet="true" rel="alternate" href="https://ml.akasaki.space//blog/tags/fcn" hreflang="zh-cn"><link data-react-helmet="true" rel="alternate" href="https://ml.akasaki.space//blog/tags/fcn" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.2aa28e4b.css">
<link rel="preload" href="/assets/js/runtime~main.70701027.js" as="script">
<link rel="preload" href="/assets/js/main.e4cdc564.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Logo" class="themedImage_TMUO themedImage--light_4Vu1"><img src="/img/logo.svg" alt="Logo" class="themedImage_TMUO themedImage--dark_uzRr"></div><b class="navbar__title">å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">é­”æ³•éƒ¨æ—¥å¿—</a><a href="https://github.com/neet-cv/ml.akasaki.space" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/about">Authors &amp; About</a><a href="https://gong.host" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>YetAnotherAkasaki<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_iYfV toggle_2i4l toggleDisabled_xj38"><div class="toggleTrack_t-f2" role="button" tabindex="-1"><div class="toggleTrackCheck_mk7D"><span class="toggleIcon_pHJ9">ğŸŒœ</span></div><div class="toggleTrackX_dm8H"><span class="toggleIcon_pHJ9">ğŸŒ</span></div><div class="toggleTrackThumb_W6To"></div></div><input type="checkbox" class="toggleScreenReader_h9qa" aria-label="Switch between dark and light mode"></div><div class="navbar__search searchBarContainer_I7kZ"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_Zg7X searchBarLoadingRing_J5Ez"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_CDc6"><kbd class="searchHint_2RRg">ctrl</kbd><kbd class="searchHint_2RRg">K</kbd></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-tags-post-list-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_q+wC thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_9G5K margin-bottom--md">All posts</div><ul class="sidebarItemList_6T4b"><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[42]CCNet-Criss-Cross-Attention-for-Semantic-Segmentation">CCNet - Criss-Cross Attention for Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[43]RepVGG-Making-VGG-style-ConvNets-Great-Again">RepVGG - Making VGG-style ConvNets Great Again</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[44]PP-LCNet-A-Lightweight-CPU-Convolutional-Neural-Network">PP-LCNet - A Lightweight CPU Convolutional Neural Network</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[45]Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows">Swin Transformer - Hierarchical Vision Transformer using Shifted Windows</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[46]Demystifying-Local-Vision-Transformer">Demystifying Local Vision Transformer</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[47]Discrete-Cosine-Transform-Mask-Representation-for-Instance-Segmentation">DCT-Mask - Discrete Cosine Transform Mask Representation for Instance Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[48]Deep-Retinex-Decomposition-for-Low-Light-Enhancement">Deep Retinex Decomposition for Low-Light Enhancement</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[49]GhostNet-More-Features-from-Cheap-Operations">GhostNet - More Features from Cheap Operations</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[50]Kindling-the-Darkness-A-Practical-Low-light-Image-Enhancer">Kindling the Darkness - A Practical Low-light Image Enhancer</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[51]How-much-Position-Information-Do-Convolutional-Neural-Networks-Encode">How much Position Information Do Convolutional Neural Networks Encode?</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[52]Axiomatic-Attribution-for-Deep-Networks">Axiomatic Attribution for Deep Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[00]unlimited-paper-works">æ¬¢è¿æ¥åˆ°é­”æ³•éƒ¨æ—¥å¿—</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[01]The-Devil-is-in-the-Decoder-Classification-Regression-and-GANs">The Devil is in the Decoder - Classification, Regression and GANs</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[02]Threat-of-Adversarial-Attacks-on-Deep-Learning-in-Computer-Vision-A-Survey">Threat of Adversarial Attacks on Deep Learning in Computer Vision - A Survey</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[03]Progressive-Semantic-Segmentation">Progressive Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[04]Decoders-Matter-for-Semantic-Segmentation-Data-Dependent-Decoding-Enables-Flexible-Feature-Aggregation">Decoders Matter for Semantic Segmentation - Data-Dependent Decoding Enables Flexible Feature Aggregation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[05]HLA-Face-Joint-High-Low-Adaptation-for-Low-Light-Face-Detection">HLA-Face Joint High-Low Adaptation for Low Light Face Detection</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[06]DeepLab-Series">DeepLab Series</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[07]Cross-Dataset-Collaborative-Learning-for-Semantic-Segmentation">Cross-Dataset Collaborative Learning for Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[08]Dynamic-Neural-Networks-A-Survey">Dynamic Neural Networks - A Survey</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[09]Feature-Pyramid-Networks-for-Object-Detection">Feature Pyramid Networks for Object Detection</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[10]Overview-Of-Semantic-Segmentation">A Review on Deep Learning Techniques Applied to Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[12]MobileNetV2-Inverted-Residuals-and-Linear-bottleneck">MobileNetV2 - Inverted Residuals and Linear Bottlenecks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[13]Fast-SCNN-Fast-Semantic-Segmentation-Network">Fast-SCNN - Fast Semantic Segmentation Network</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[14]MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications">MobileNets - Efficient Convolutional Neural Networks for Mobile Vision Applications</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[15]Gated-Channel-Transformation-for-Visual-Recognition">Gated Channel Transformation for Visual Recognition</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[16]Convolutional-Block-Attention-Module">Convolutional Block Attention Module</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[17]Boundary-IoU-Improving-Object-Centri-Image-Segmentation-Evaluation">Boundary IoU - Improving Object-Centric Image Segmentation Evaluation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[18]Involution-Inverting-the-Inherence-of-Convolution-for-Visual-Recognition">Involution - Inverting the Inherence of Convolution for Visual Recognition</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[19]PointRend-Image-Segmentation-as-Rendering">PointRend - Image Segmentation as Rendering</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[20]Transformer-Attention-is-all-you-need">Transformer - Attention is all you need</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[21]RefineMask-Towards-High-Quality-Instance-Segmentationwith-Fine-Grained_Features">RefineMask - Towards High-Quality Instance Segmentationwith Fine-Grained Features</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[22]GLADNet-Low-Light-Enhancement-Network-with-Global-Awareness">GLADNet - Low-Light Enhancement Network with Global Awareness</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[23]Squeeze-and-Excitation-Networks">Squeeze-and-Excitation Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation">BiSeNet - Bilateral Segmentation Network for Real-time Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[25]Rethinking-BiSeNet-For-Real-time-Semantic-Segmentation">Rethinking BiSeNet For Real-time Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[26]CBAM-Convolutional-Block-Attention-Module">CBAM - Convolutional Block Attention Module</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[27]Non-local-Neural-Networks">Non-local Neural Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[28]GCNet-Non-local-Networks-Meet-Squeeze-Excitation-Networks-and-Beyond">Non-local Networks Meet Squeeze-Excitation Networks and Beyond</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[29]Disentangled-Non-Local-Neural-Networks">Disentangled Non-Local Neural Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[30]RetinexNet-for-Low-Light-Enhancement">Deep Retinex Decomposition for Low-Light Enhancement</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[31]MSR-netLow-light-Image-Enhancement-Using-Deep-Convolutional-Network">MSR-net - Low-light Image Enhancement Using Deep Convolutional Network</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[32]LLCNN-A-Convolutional-Neural-Network-for-Low-light-Image-Enhancement">LLCNN - A convolutional neural network for low-light image enhancement</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[33]VOLO-Vision-Outlooker-for-Visual-Recognition">VOLO - Vision Outlooker for Visual Recognition</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[34]Polarized-Self-Attention-Towards-High-quality-Pixel-wise-Regression">Polarized Self-Attention - Towards High-quality Pixel-wise Regression</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[35]SimAM-A-Simple-Parameter-Free-Attention-Module-for-Convolutional-Neural-Networks">SimAM - A Simple, Parameter-Free Attention Module for Convolutional Neural Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[36]SOLO-Segmenting-Objects-by-Locations">SOLO - Segmenting Objects by Locations</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[37]YOLACT-Real-time-Instance-Segmentation">YOLACT - Real-time Instance Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[38]You-Only-Look-One-level-Feature">You Only Look One-level Feature</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[39]Instance-sensitive-Fully-Convolutional-Networks">Instance-sensitive Fully Convolutional Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[40]Learning-in-the-Frequency-Domain">Learning in the Frequency Domain</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><header class="margin-bottom--xl"><h1>One post tagged with &quot;fcn&quot;</h1><a href="/blog/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[39]Instance-sensitive-Fully-Convolutional-Networks">Instance-sensitive Fully Convolutional Networks</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/visualDust.png" alt="Gavin Gong"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Gavin Gong</span></a></div><small class="avatar__subtitle" itemprop="description">Rubbish CVer | Poor LaTex speaker | Half stack developer | é”®åœˆèººå°¸ç –å®¶</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+J" target="_blank" rel="noopener noreferrer">Jifeng Dai</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+K" target="_blank" rel="noopener noreferrer">Kaiming He</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y" target="_blank" rel="noopener noreferrer">Yi Li</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+S" target="_blank" rel="noopener noreferrer">Shaoqing Ren</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+J" target="_blank" rel="noopener noreferrer">Jian Sun</a></p><blockquote><p>Fully convolutional networks (FCNs) have been proven very successful for semantic segmentation, but the FCN outputs are unaware of object instances. In this paper, we develop FCNs that are capable of proposing instance-level segment candidates. In contrast to the previous FCN that generates one score map, our FCN is designed to compute a small set of instance-sensitive score maps, each of which is the outcome of a pixel-wise classifier of a relative position to instances. On top of these instance-sensitive score maps, a simple assembling module is able to output instance candidate at each position. In contrast to the recent DeepMask method for segmenting instances, our method does not have any high-dimensional layer related to the mask resolution, but instead exploits image local coherence for estimating instances. We present competitive results of instance segment proposal on both PASCAL VOC and MS COCO.</p></blockquote><p>è¿™ç¯‡å·¥ä½œåˆåInstanceFCNã€‚å®ä¾‹åˆ†å‰²æ–¹é¢ï¼Œç”±äºç½‘ç»œéš¾ä»¥åŒæ—¶è¿›è¡Œåˆ†ç±»å’Œåˆ†å‰²ä»»åŠ¡ï¼Œå› æ­¤é¦–å…ˆæµè¡Œçš„æ˜¯äºŒé˜¶æ®µå®ä¾‹åˆ†å‰²ç½‘ç»œï¼Œé¦–å…ˆå¯¹è¾“å…¥æ‰¾åˆ°å®ä¾‹çš„proposalï¼Œç„¶ååœ¨å…¶ä¸­è¿›è¡Œå¯†é›†é¢„æµ‹ï¼ˆä¹Ÿå°±æ˜¯å…ˆæ¡†æ¡†å†åˆ†å‰²ï¼‰ã€‚æœ¬æ–‡ä»åç§°ä¸Šçœ‹ä¸æ˜¯ä¸€ç¯‡è®²å®ä¾‹åˆ†å‰²çš„æ–‡ç« ï¼Œæ˜¯è®²å¦‚ä½•é€šè¿‡FCNè·å¾—å®ä¾‹çº§åˆ«çš„åˆ†å‰²maskçš„çš„ã€‚</p><p>åœ¨é˜…è¯»ä¹‹å‰æˆ‘æƒ³æé†’ä¸€ä¸‹ï¼Œè¿™ç¯‡å·¥ä½œçš„æ•ˆæœæ˜¯æ¯”è¾ƒå·®çš„ï¼Œæ¯•ç«Ÿæ˜¯æ—©æœŸå·¥ä½œã€‚ä¸è¿‡è¿™ç¯‡å·¥ä½œå…·æœ‰ä¸é”™çš„å¯å‘æ„ä¹‰ï¼Œå€¼å¾—è¯»ä¸€è¯»ã€‚åé¢çš„ä¸€ç¯‡å·¥ä½œFCISï¼ˆFully Convolutional Instance-aware Semantic Segmentationï¼‰ä¸­å°±å€Ÿé‰´äº†æœ¬æ–‡ä¸­æå‡ºçš„instance-sensitive score mapsï¼ˆè¯·ä¸è¦å¼„æ··æœ¬ç¯‡å·¥ä½œå’ŒFCISï¼‰ã€‚æœ¬æ–‡çš„ä¸€å¤§è´¡çŒ®å°±æ˜¯æå‡ºä½¿ç”¨instance-sensitive score mapsåŒºåˆ†ä¸åŒä¸ªä½“ã€‚</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/fcn">fcn</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/segmentation">segmentation</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/instance-segmentation">instance-segmentation</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/backbone">backbone</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Instance-sensitive Fully Convolutional Networks" href="/blog/[39]Instance-sensitive-Fully-Convolutional-Networks"><b>Read More</b></a></div></footer></article></main></div></div></div><footer class="footer footer--dark"><div class="container"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2022 neet-cv. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.70701027.js"></script>
<script src="/assets/js/main.e4cdc564.js"></script>
</body>
</html>