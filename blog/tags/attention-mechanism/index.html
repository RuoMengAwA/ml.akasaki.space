<!doctype html>
<html lang="zh-cn" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.9">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿ RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿ Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.css" crossorigin="anonymous"><title data-react-helmet="true">One post tagged with &quot;attention-mechanism&quot; | å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿</title><meta data-react-helmet="true" property="og:title" content="One post tagged with &quot;attention-mechanism&quot; | å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://ml.akasaki.space//blog/tags/attention-mechanism"><meta data-react-helmet="true" name="docusaurus_locale" content="zh-cn"><meta data-react-helmet="true" name="docusaurus_tag" content="blog_tags_posts"><link data-react-helmet="true" rel="shortcut icon" href="/img/logo.svg"><link data-react-helmet="true" rel="canonical" href="https://ml.akasaki.space//blog/tags/attention-mechanism"><link data-react-helmet="true" rel="alternate" href="https://ml.akasaki.space//blog/tags/attention-mechanism" hreflang="zh-cn"><link data-react-helmet="true" rel="alternate" href="https://ml.akasaki.space//blog/tags/attention-mechanism" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.2aa28e4b.css">
<link rel="preload" href="/assets/js/runtime~main.70701027.js" as="script">
<link rel="preload" href="/assets/js/main.e4cdc564.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Logo" class="themedImage_TMUO themedImage--light_4Vu1"><img src="/img/logo.svg" alt="Logo" class="themedImage_TMUO themedImage--dark_uzRr"></div><b class="navbar__title">å·¥å…·ç®±çš„æ·±åº¦å­¦ä¹ è®°äº‹ç°¿</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">é­”æ³•éƒ¨æ—¥å¿—</a><a href="https://github.com/neet-cv/ml.akasaki.space" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/about">Authors &amp; About</a><a href="https://gong.host" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>YetAnotherAkasaki<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_iYfV toggle_2i4l toggleDisabled_xj38"><div class="toggleTrack_t-f2" role="button" tabindex="-1"><div class="toggleTrackCheck_mk7D"><span class="toggleIcon_pHJ9">ğŸŒœ</span></div><div class="toggleTrackX_dm8H"><span class="toggleIcon_pHJ9">ğŸŒ</span></div><div class="toggleTrackThumb_W6To"></div></div><input type="checkbox" class="toggleScreenReader_h9qa" aria-label="Switch between dark and light mode"></div><div class="navbar__search searchBarContainer_I7kZ"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_Zg7X searchBarLoadingRing_J5Ez"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_CDc6"><kbd class="searchHint_2RRg">ctrl</kbd><kbd class="searchHint_2RRg">K</kbd></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-tags-post-list-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_q+wC thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_9G5K margin-bottom--md">All posts</div><ul class="sidebarItemList_6T4b"><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[42]CCNet-Criss-Cross-Attention-for-Semantic-Segmentation">CCNet - Criss-Cross Attention for Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[43]RepVGG-Making-VGG-style-ConvNets-Great-Again">RepVGG - Making VGG-style ConvNets Great Again</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[44]PP-LCNet-A-Lightweight-CPU-Convolutional-Neural-Network">PP-LCNet - A Lightweight CPU Convolutional Neural Network</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[45]Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows">Swin Transformer - Hierarchical Vision Transformer using Shifted Windows</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[46]Demystifying-Local-Vision-Transformer">Demystifying Local Vision Transformer</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[47]Discrete-Cosine-Transform-Mask-Representation-for-Instance-Segmentation">DCT-Mask - Discrete Cosine Transform Mask Representation for Instance Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[48]Deep-Retinex-Decomposition-for-Low-Light-Enhancement">Deep Retinex Decomposition for Low-Light Enhancement</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[49]GhostNet-More-Features-from-Cheap-Operations">GhostNet - More Features from Cheap Operations</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[50]Kindling-the-Darkness-A-Practical-Low-light-Image-Enhancer">Kindling the Darkness - A Practical Low-light Image Enhancer</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[51]How-much-Position-Information-Do-Convolutional-Neural-Networks-Encode">How much Position Information Do Convolutional Neural Networks Encode?</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[52]Axiomatic-Attribution-for-Deep-Networks">Axiomatic Attribution for Deep Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[00]unlimited-paper-works">æ¬¢è¿æ¥åˆ°é­”æ³•éƒ¨æ—¥å¿—</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[01]The-Devil-is-in-the-Decoder-Classification-Regression-and-GANs">The Devil is in the Decoder - Classification, Regression and GANs</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[02]Threat-of-Adversarial-Attacks-on-Deep-Learning-in-Computer-Vision-A-Survey">Threat of Adversarial Attacks on Deep Learning in Computer Vision - A Survey</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[03]Progressive-Semantic-Segmentation">Progressive Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[04]Decoders-Matter-for-Semantic-Segmentation-Data-Dependent-Decoding-Enables-Flexible-Feature-Aggregation">Decoders Matter for Semantic Segmentation - Data-Dependent Decoding Enables Flexible Feature Aggregation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[05]HLA-Face-Joint-High-Low-Adaptation-for-Low-Light-Face-Detection">HLA-Face Joint High-Low Adaptation for Low Light Face Detection</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[06]DeepLab-Series">DeepLab Series</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[07]Cross-Dataset-Collaborative-Learning-for-Semantic-Segmentation">Cross-Dataset Collaborative Learning for Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[08]Dynamic-Neural-Networks-A-Survey">Dynamic Neural Networks - A Survey</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[09]Feature-Pyramid-Networks-for-Object-Detection">Feature Pyramid Networks for Object Detection</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[10]Overview-Of-Semantic-Segmentation">A Review on Deep Learning Techniques Applied to Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[12]MobileNetV2-Inverted-Residuals-and-Linear-bottleneck">MobileNetV2 - Inverted Residuals and Linear Bottlenecks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[13]Fast-SCNN-Fast-Semantic-Segmentation-Network">Fast-SCNN - Fast Semantic Segmentation Network</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[14]MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications">MobileNets - Efficient Convolutional Neural Networks for Mobile Vision Applications</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[15]Gated-Channel-Transformation-for-Visual-Recognition">Gated Channel Transformation for Visual Recognition</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[16]Convolutional-Block-Attention-Module">Convolutional Block Attention Module</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[17]Boundary-IoU-Improving-Object-Centri-Image-Segmentation-Evaluation">Boundary IoU - Improving Object-Centric Image Segmentation Evaluation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[18]Involution-Inverting-the-Inherence-of-Convolution-for-Visual-Recognition">Involution - Inverting the Inherence of Convolution for Visual Recognition</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[19]PointRend-Image-Segmentation-as-Rendering">PointRend - Image Segmentation as Rendering</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[20]Transformer-Attention-is-all-you-need">Transformer - Attention is all you need</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[21]RefineMask-Towards-High-Quality-Instance-Segmentationwith-Fine-Grained_Features">RefineMask - Towards High-Quality Instance Segmentationwith Fine-Grained Features</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[22]GLADNet-Low-Light-Enhancement-Network-with-Global-Awareness">GLADNet - Low-Light Enhancement Network with Global Awareness</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[23]Squeeze-and-Excitation-Networks">Squeeze-and-Excitation Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation">BiSeNet - Bilateral Segmentation Network for Real-time Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[25]Rethinking-BiSeNet-For-Real-time-Semantic-Segmentation">Rethinking BiSeNet For Real-time Semantic Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[26]CBAM-Convolutional-Block-Attention-Module">CBAM - Convolutional Block Attention Module</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[27]Non-local-Neural-Networks">Non-local Neural Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[28]GCNet-Non-local-Networks-Meet-Squeeze-Excitation-Networks-and-Beyond">Non-local Networks Meet Squeeze-Excitation Networks and Beyond</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[29]Disentangled-Non-Local-Neural-Networks">Disentangled Non-Local Neural Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[30]RetinexNet-for-Low-Light-Enhancement">Deep Retinex Decomposition for Low-Light Enhancement</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[31]MSR-netLow-light-Image-Enhancement-Using-Deep-Convolutional-Network">MSR-net - Low-light Image Enhancement Using Deep Convolutional Network</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[32]LLCNN-A-Convolutional-Neural-Network-for-Low-light-Image-Enhancement">LLCNN - A convolutional neural network for low-light image enhancement</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[33]VOLO-Vision-Outlooker-for-Visual-Recognition">VOLO - Vision Outlooker for Visual Recognition</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[34]Polarized-Self-Attention-Towards-High-quality-Pixel-wise-Regression">Polarized Self-Attention - Towards High-quality Pixel-wise Regression</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[35]SimAM-A-Simple-Parameter-Free-Attention-Module-for-Convolutional-Neural-Networks">SimAM - A Simple, Parameter-Free Attention Module for Convolutional Neural Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[36]SOLO-Segmenting-Objects-by-Locations">SOLO - Segmenting Objects by Locations</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[37]YOLACT-Real-time-Instance-Segmentation">YOLACT - Real-time Instance Segmentation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[38]You-Only-Look-One-level-Feature">You Only Look One-level Feature</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[39]Instance-sensitive-Fully-Convolutional-Networks">Instance-sensitive Fully Convolutional Networks</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/[40]Learning-in-the-Frequency-Domain">Learning in the Frequency Domain</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><header class="margin-bottom--xl"><h1>One post tagged with &quot;attention-mechanism&quot;</h1><a href="/blog/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[42]CCNet-Criss-Cross-Attention-for-Semantic-Segmentation">CCNet - Criss-Cross Attention for Semantic Segmentation</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.664Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/AsTheStarsFalll.png" alt="AsTheStarsFall"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">AsTheStarsFall</span></a></div><small class="avatar__subtitle" itemprop="description">None</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>æå‡ºåå­—äº¤å‰æ³¨æ„åŠ›æ¨¡å—ï¼Œä½¿ç”¨å¾ªç¯ç¨€ç–è¿æ¥ä»£æ›¿å¯†é›†è¿æ¥ï¼Œå®ç°æ€§èƒ½SOTA</p><blockquote><p>è®ºæ–‡åç§°ï¼š<a href="https://arxiv.org/pdf/1811.11721.pdf" target="_blank" rel="noopener noreferrer">CCNet: Criss-Cross Attention for Semantic Segmentation</a></p><p>ä½œè€…ï¼šZilong Huangï¼ŒXinggang Wang Yunï¼Œchao Weiï¼ŒLichao Huangï¼ŒWenyu Liuï¼ŒThomas S. Huang</p><p>Codeï¼š<a href="https://github.com/speedinghzl/CCNet" target="_blank" rel="noopener noreferrer">https://github.com/speedinghzl/CCNet</a></p></blockquote><h2 class="anchor anchorWithStickyNavbar_y2LR" id="æ‘˜è¦">æ‘˜è¦<a aria-hidden="true" class="hash-link" href="#æ‘˜è¦" title="Direct link to heading">â€‹</a></h2><p>ä¸Šä¸‹æ–‡ä¿¡æ¯åœ¨è§†è§‰ç†è§£é—®é¢˜ä¸­è‡³å…³é‡è¦ï¼Œè­¬å¦‚è¯­ä¹‰åˆ†å‰²å’Œç›®æ ‡æ£€æµ‹ï¼›</p><p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åå­—äº¤å‰çš„ç½‘ç»œï¼ˆCriss-Cross Netï¼‰ä»¥éå¸¸é«˜æ•ˆçš„æ–¹å¼è·å–å®Œæ•´çš„å›¾åƒä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š</p><ol><li>å¯¹æ¯ä¸ªåƒç´ ä½¿ç”¨ä¸€ä¸ªåå­—æ³¨æ„åŠ›æ¨¡å—èšé›†å…¶è·¯å¾„ä¸Šæ‰€æœ‰åƒç´ çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼›</li><li>é€šè¿‡å¾ªç¯æ“ä½œï¼Œæ¯ä¸ªåƒç´ æœ€ç»ˆéƒ½å¯ä»¥æ•è·å®Œæ•´çš„å›¾åƒç›¸å…³æ€§ï¼›</li><li>æå‡ºäº†ä¸€ç§ç±»åˆ«ä¸€è‡´æ€§æŸå¤±æ¥å¢å¼ºæ¨¡å—çš„è¡¨ç°ã€‚</li></ol><p>CCNetå…·æœ‰ä¸€ä¸‹ä¼˜åŠ¿ï¼š</p><ol><li>æ˜¾å­˜å‹å¥½ï¼šç›¸è¾ƒäºNon-Localå‡å°‘æ˜¾å­˜å ç”¨11å€</li><li>è®¡ç®—é«˜æ•ˆï¼šå¾ªç¯åå­—æ³¨æ„åŠ›å‡å°‘Non-Localçº¦85%çš„è®¡ç®—é‡</li><li>SOTA</li><li>Achieve the <strong>mIoU</strong> scores of 81.9%, 45.76% and 55.47% on the <strong>Cityscapes test set</strong>, the <strong>ADE20K validation set</strong> and the <strong>LIP validation set</strong> respectively</li></ol></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/segmentation">segmentation</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about CCNet - Criss-Cross Attention for Semantic Segmentation" href="/blog/[42]CCNet-Criss-Cross-Attention-for-Semantic-Segmentation"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[45]Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows">Swin Transformer - Hierarchical Vision Transformer using Shifted Windows</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.664Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/AsTheStarsFalll.png" alt="AsTheStarsFall"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">AsTheStarsFall</span></a></div><small class="avatar__subtitle" itemprop="description">None</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>åˆ†å±‚Local Vision Transformerï¼Œé€šç”¨ä¸»å¹²ç½‘ç»œï¼Œå„ç±»ä¸‹æ¸¸ä»»åŠ¡å®ç°SOTAã€‚Best Paper Award!</p><blockquote><p>è®ºæ–‡åç§°ï¼š<a href="https://arxiv.org/abs/2103.14030" target="_blank" rel="noopener noreferrer">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</a></p><p>ä½œè€…ï¼šZe Liu ï¼ŒYutong Linï¼ŒYue Caoï¼ŒHan Huï¼ŒYixuan Weiï¼ŒZheng Zhangï¼ŒStephen Linï¼ŒBaining Guo</p><p>Codeï¼š<a href="https://github.com/microsoft/Swin-Transformer" target="_blank" rel="noopener noreferrer">https://github.com/microsoft/Swin-Transformer</a></p></blockquote><h2 class="anchor anchorWithStickyNavbar_y2LR" id="ä»‹ç»">ä»‹ç»<a aria-hidden="true" class="hash-link" href="#ä»‹ç»" title="Direct link to heading">â€‹</a></h2><p>è‡ªAlexNetä»¥æ¥ï¼ŒCNNä½œä¸ºéª¨å¹²ï¼ˆbackboneï¼‰åœ¨è®¡ç®—æœºè§†è§‰ä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ï¼›å¦ä¸€æ–¹é¢ï¼Œè‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ç½‘ç»œç»“æ„çš„æ¼”å˜åˆ™èµ°äº†ä¸€æ¡ä¸åŒçš„é“è·¯ï¼Œç°åœ¨çš„ä¸»æµç»“æ„æ˜¯Transformerã€‚</p><p>Transformeræ˜¯ä¸ºåºåˆ—å»ºæ¨¡å’Œè½¬æ¢ä»»åŠ¡è€Œè®¾è®¡çš„ï¼Œå®ƒä»¥å…³æ³¨æ•°æ®ä¸­çš„é•¿æœŸä¾èµ–å…³ç³»è€Œè‘—ç§°ã€‚å…¶åœ¨NLPé¢†åŸŸçš„å·¨å¤§æˆåŠŸå¸å¼•äº†äººä»¬ç ”ç©¶å®ƒå¯¹CVçš„é€‚åº”æ€§ï¼Œæœ€è¿‘çš„å®éªŒæ˜¾ç¤ºå…¶åœ¨å›¾åƒåˆ†ç±»å’Œè”åˆè§†è§‰è¯­è¨€å»ºæ¨¡æ–¹é¢æœ‰æ‰€æˆæ•ˆã€‚</p><p>æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®æœ‰ï¼š</p><ol><li>æå‡ºäº†ä¸€ç§åˆ†å±‚Transformerï¼Œå…¶å¯ä»¥ä½œä¸ºè®¡ç®—æœºè§†è§‰çš„é€šç”¨ä¸»å¹²ç½‘ç»œï¼Œå¹¶ä¸”åœ¨å„ç±»ä¸‹æ¸¸ä»»åŠ¡ä¸Šå–å¾—SOTAï¼›</li><li>é€šè¿‡Shift Windowså®ç°äº†å¯¹è¾“å…¥å›¾åƒå°ºå¯¸çš„çº¿æ€§æ—¶é—´å¤æ‚åº¦ã€‚</li></ol><img src="https://gitee.com/Thedeadleaf/images/raw/master/image-20211020204110669.png" alt="image-20211020204110669"></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/transformer">transformer</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/inductive-bias">inductive-bias</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Swin Transformer - Hierarchical Vision Transformer using Shifted Windows" href="/blog/[45]Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[46]Demystifying-Local-Vision-Transformer">Demystifying Local Vision Transformer</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.664Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/AsTheStarsFalll.png" alt="AsTheStarsFall"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">AsTheStarsFall</span></a></div><small class="avatar__subtitle" itemprop="description">None</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>ä»ç¨€ç–è¿æ¥æ€§ã€æƒé‡å…±äº«ã€åŠ¨æ€æƒé‡è¿›ä¸€æ­¥æ¢ç©¶Local Attentionã€‚</p><blockquote><p>è®ºæ–‡åç§°ï¼šDemystifying Local Vision Transformer: Sparse Connectivity, Weight Sharing, and Dynamic Weight</p><p>ä½œè€…ï¼šQi Han1ï¼ŒZejia Fanï¼ŒQi Daiï¼ŒLei Sunï¼ŒMing-Ming Chengï¼ŒJiaying Liuï¼ŒJingdong Wang</p><p>Codeï¼š<a href="https://github.com/Atten4Vis/DemystifyLocalViT/" target="_blank" rel="noopener noreferrer">https://github.com/Atten4Vis/DemystifyLocalViT/</a></p></blockquote><h2 class="anchor anchorWithStickyNavbar_y2LR" id="ä»‹ç»">ä»‹ç»<a aria-hidden="true" class="hash-link" href="#ä»‹ç»" title="Direct link to heading">â€‹</a></h2><p>æœ¬æ–‡çš„ä¸»è¦æˆæœå‘ç°ï¼ˆfindingï¼‰å¦‚ä¸‹ï¼š</p><ol><li><p>Local Transformeré‡‡ç”¨çš„Local Attentionåˆ©ç”¨äº†ç°æœ‰çš„æ­£åˆ™åŒ–æ–¹æ¡ˆï¼ˆregularization schemesï¼‰ã€ç¨€ç–è¿æ¥ï¼ˆsparse connectivity ï¼‰ã€æƒé‡å…±äº«ï¼ˆweight sharingï¼‰ä»¥åŠåŠ¨æ€æƒé‡é¢„æµ‹ï¼ˆdynamic weight predictionï¼‰ï¼Œåœ¨ä¸éœ€è¦é¢å¤–å¢åŠ æ¨¡å‹å¤æ‚åº¦å’Œè®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹å¢åŠ æ€§èƒ½ï¼›</p></li><li><p>å±€éƒ¨æ³¨æ„åŠ›ï¼ˆLocal Attentionï¼‰ä¸ï¼ˆåŠ¨æ€ï¼‰æ·±åº¦å·ç§¯ï¼ˆ(dynamic )depth-wise convolutionï¼‰åœ¨ç¨€ç–è¿æ¥æ€§ä¸Š<strong>ç›¸ä¼¼</strong>ï¼Œåœ¨æƒé‡å…±äº«å’ŒåŠ¨æ€æƒé‡é¢„æµ‹ä¸Šä¸åŒã€‚</p><p>å®éªŒç»“æœè¡¨æ˜ï¼Œå±€éƒ¨æ³¨æ„åŠ›å’Œï¼ˆåŠ¨æ€ï¼‰æ·±åº¦å·ç§¯æ‰€é‡‡ç”¨çš„æ­£åˆ™åŒ–å½¢å¼å’ŒåŠ¨æ€æƒé‡é¢„æµ‹æ–¹æ¡ˆå…·æœ‰<strong>ç›¸ä¼¼</strong>çš„æ€§èƒ½ã€‚</p></li><li><p>æ­¤å¤–ï¼Œæå‡ºäº†ä¸€ä¸ªå…³ç³»å›¾æ¥è”ç³»å·ç§¯å’Œæ³¨æ„åŠ›ï¼ŒåŒæ—¶å¼€å‘äº†åŸºäºMLPçš„æ–¹æ³•ã€‚</p><p>å…³ç³»å›¾è¡¨æ˜ï¼Œè¿™äº›æ–¹æ³•æœ¬è´¨ä¸Šåˆ©ç”¨äº†ä¸åŒçš„ç¨€ç–è¿æ¥å’Œæƒé‡å…±äº«æ¨¡å¼ï¼Œå¯ä»¥é€‰æ‹©ä½¿ç”¨åŠ¨æ€æƒé‡é¢„æµ‹è¿›è¡Œæ¨¡å‹æ­£åˆ™åŒ–ã€‚</p></li></ol></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/transformer">transformer</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/dynamic-neural-network">dynamic-neural-network</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Demystifying Local Vision Transformer" href="/blog/[46]Demystifying-Local-Vision-Transformer"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[15]Gated-Channel-Transformation-for-Visual-Recognition">Gated Channel Transformation for Visual Recognition</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/AsTheStarsFalll.png" alt="AsTheStarsFall"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">AsTheStarsFall</span></a></div><small class="avatar__subtitle" itemprop="description">None</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><blockquote><p>è®ºæ–‡åç§°ï¼š<a href="https://arxiv.org/abs/1909.11519" target="_blank" rel="noopener noreferrer">Gated Channel Transformation for Visual Recognition</a></p><p>ä½œè€…ï¼šZongxin Yang, Linchao Zhu, Y u Wu, and Yi Yang</p><p>Codeï¼š<a href="https://github.com/z-x-yang/GCT" target="_blank" rel="noopener noreferrer">https://github.com/z-x-yang/GCT</a></p></blockquote><h2 class="anchor anchorWithStickyNavbar_y2LR" id="æ‘˜è¦">æ‘˜è¦<a aria-hidden="true" class="hash-link" href="#æ‘˜è¦" title="Direct link to heading">â€‹</a></h2><ul><li>GCTæ¨¡å—æ˜¯ä¸€ä¸ªæ™®éé€‚ç”¨çš„é—¨æ§è½¬æ¢å•å…ƒï¼Œå¯ä¸ç½‘ç»œæƒé‡ä¸€èµ·ä¼˜åŒ–ã€‚</li><li>ä¸åŒäºSEneté€šè¿‡å…¨è¿æ¥çš„éšå¼å­¦ä¹ ï¼Œå…¶ä½¿ç”¨å¯è§£é‡Šçš„å˜é‡æ˜¾å¼åœ°å»ºæ¨¡é€šé“é—´çš„å…³ç³»ï¼Œå†³å®šæ˜¯ç«äº‰æˆ–æ˜¯åˆä½œã€‚</li></ul><p><strong>å…³é”®è¯ï¼šå¯è§£é‡Šæ€§ã€æ˜¾å¼å…³ç³»ã€é—¨æ§</strong></p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="ä»‹ç»">ä»‹ç»<a aria-hidden="true" class="hash-link" href="#ä»‹ç»" title="Direct link to heading">â€‹</a></h2><ul><li>å•ä¸ªå·ç§¯å±‚åªå¯¹Feature Mapä¸­æ¯ä¸ªç©ºé—´ä½ç½®çš„ä¸´è¿‘å±€éƒ¨ä¸Šä¸‹æ–‡è¿›è¡Œæ“ä½œï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´å±€éƒ¨æ­§ä¹‰ã€‚é€šå¸¸æœ‰ä¸¤ç§æ–¹æ³•è§£å†³è¿™ç§é—®é¢˜ï¼šä¸€æ˜¯å¢åŠ ç½‘ç»œçš„æ·±åº¦ï¼Œå¦‚VGGï¼ŒResnetï¼ŒäºŒæ˜¯å¢åŠ ç½‘ç»œçš„å®½åº¦æ¥è·å¾—æ›´å¤šçš„å…¨å±€ä¿¡æ¯ï¼Œå¦‚GEnetå¤§é‡ä½¿ç”¨é¢†åŸŸåµŒå…¥ï¼ŒSEneté€šè¿‡å…¨å±€åµŒå…¥ä¿¡æ¯æ¥å»ºæ¨¡é€šé“å…³ç³»ã€‚</li><li>ç„¶è€ŒSEnetä¸­ä½¿ç”¨fcå±‚ä¼šå‡ºç°ä¸¤ä¸ªé—®é¢˜ï¼š<ol><li>ç”±äºä½¿ç”¨äº†fcå±‚ï¼Œå‡ºäºèŠ‚çœå‚æ•°çš„è€ƒè™‘ï¼Œæ— æ³•åœ¨æ‰€æœ‰å±‚ä¸Šä½¿ç”¨</li><li>fcå±‚çš„å‚æ•°è¾ƒä¸ºå¤æ‚ï¼Œéš¾ä»¥åˆ†æä¸åŒé€šé“é—´çš„å…³è”æ€§ï¼Œè¿™å®é™…ä¸Šæ˜¯ä¸€ç§<strong>éšå¼</strong>å­¦ä¹ </li><li>æ”¾åœ¨æŸäº›å±‚ä¹‹åä¼šå‡ºç°é—®é¢˜</li></ol></li></ul></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Gated Channel Transformation for Visual Recognition" href="/blog/[15]Gated-Channel-Transformation-for-Visual-Recognition"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[16]Convolutional-Block-Attention-Module">Convolutional Block Attention Module</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/AsTheStarsFalll.png" alt="AsTheStarsFall"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">AsTheStarsFall</span></a></div><small class="avatar__subtitle" itemprop="description">None</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><blockquote><p>è®ºæ–‡åç§°ï¼š<a href="https://arxiv.org/abs/1807.06521" target="_blank" rel="noopener noreferrer">CBAM: Convolutional Block Attention Module</a></p><p>ä½œè€…ï¼šSanghyun Woo, Jongchan Park, Joon-Young Lee, and In So Kweonï¼ŒKorea Advanced Institute of Science and Technology, Daejeon, Korea</p></blockquote><h2 class="anchor anchorWithStickyNavbar_y2LR" id="æ‘˜è¦">æ‘˜è¦<a aria-hidden="true" class="hash-link" href="#æ‘˜è¦" title="Direct link to heading">â€‹</a></h2><ul><li>CBAMï¼ˆConvolutional Block Attention Moudule)æ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„<a href="https://www.cnblogs.com/samshare/p/11801806.html" target="_blank" rel="noopener noreferrer">å‰é¦ˆ</a>å·ç§¯ç¥ç»ç½‘ç»œæ³¨æ„åŠ›æ¨¡å—ã€‚ </li><li>è¯¥æ¨¡å—ä¸ºæ··åˆåŸŸæ³¨æ„åŠ›æœºåˆ¶ï¼ˆï¼‰ä»é€šé“å’Œç©ºé—´ä¸¤ä¸ªæ–¹é¢ä¾æ¬¡æ¨æ–­attention mapã€‚</li><li>CBAMæ˜¯ä¸€ä¸ªè½»é‡çº§çš„é€šç”¨æ¨¡å—ï¼Œå¯ä»¥æ— ç¼é›†æˆåˆ°ä»»ä½•CNNä¸­ã€‚</li></ul><p><strong>å…³é”®è¯:ç‰©ä½“è¯†åˆ«ï¼Œæ³¨æ„æœºåˆ¶ï¼Œé—¨æ§å·ç§¯</strong></p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="ä»‹ç»">ä»‹ç»<a aria-hidden="true" class="hash-link" href="#ä»‹ç»" title="Direct link to heading">â€‹</a></h2><ul><li>å·ç§¯ç¥ç»ç½‘ç»œ(CNNs)åŸºäºå…¶ä¸°å¯Œçš„è¡¨è¾¾èƒ½åŠ›æ˜¾è‘—æé«˜äº†è§†è§‰ä»»åŠ¡çš„æ€§èƒ½ï¼Œç›®å‰çš„ä¸»è¦å…³æ³¨ç½‘ç»œçš„ä¸‰ä¸ªé‡è¦å› ç´ ï¼š<strong>æ·±åº¦ï¼Œå®½åº¦å’ŒåŸºæ•°</strong>ï¼ˆCardinalityï¼‰ã€‚</li><li>ä»LeNetåˆ°æ®‹å·®ç½‘ç»œï¼Œç½‘ç»œå˜çš„æ›´åŠ æ·±å…¥ï¼Œè¡¨è¾¾å½¢å¼æ›´åŠ ä¸°å¯Œï¼›GoogLeNetè¡¨æ˜å®½åº¦æ˜¯æé«˜æ¨¡å‹æ€§èƒ½çš„å¦ä¸€ä¸ªé‡è¦å› ç´ ï¼›Xceptionå’ŒResNextåˆ™é€šè¿‡å¢åŠ ç½‘ç»œçš„<strong>åŸºæ•°</strong>ï¼Œåœ¨èŠ‚çœå‚æ•°çš„åŒæ—¶ï¼Œæ¥è·å¾—æ¯”æ·±åº¦ã€å®½åº¦æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›ï¼ˆå¼•ç”¨äºResNextè®ºæ–‡ï¼‰ã€‚</li><li>é™¤äº†è¿™äº›å› ç´ ä¹‹å¤–ï¼Œæœ¬æ–‡è€ƒå¯Ÿäº†ä¸ç½‘ç»œç»“æ„è®¾è®¡ä¸åŒçš„æ–¹é¢â€”â€”æ³¨æ„åŠ›ã€‚</li></ul></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Convolutional Block Attention Module" href="/blog/[16]Convolutional-Block-Attention-Module"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[18]Involution-Inverting-the-Inherence-of-Convolution-for-Visual-Recognition">Involution - Inverting the Inherence of Convolution for Visual Recognition</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/AsTheStarsFalll.png" alt="AsTheStarsFall"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">AsTheStarsFall</span></a></div><small class="avatar__subtitle" itemprop="description">None</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><blockquote><p>è®ºæ–‡åç§°ï¼š<a href="https://arxiv.org/abs/2103.06255" target="_blank" rel="noopener noreferrer"><em>Involution: Inverting the Inherence of Convolution for Visual Recognition</em></a></p><p>ä½œè€…ï¼šDuo Liï¼Œ Jie Huï¼Œ Changhu Wangï¼Œ Xiangtai Liï¼Œ Qi Sheï¼Œ Lei Zhuï¼Œ Tong Zhangï¼Œ Qifeng Chenï¼Œ The Hong Kong University of Science and Technologyï¼Œ ByteDance AI Labï¼Œ Peking Universityï¼Œ Beijing University of Posts and Telecommunications</p></blockquote><header><h1>Convolution</h1></header><ol><li><a href="https://arxiv.org/abs/1805.12177" target="_blank" rel="noopener noreferrer">ç©ºé—´æ— å…³æ€§(spatial agnostic)</a>ï¼šsame kernel for different position<ul><li>ä¼˜ç‚¹ï¼šå‚æ•°å…±äº«ï¼Œå¹³ç§»ç­‰å˜</li><li>ç¼ºç‚¹ï¼šä¸èƒ½çµæ´»æ”¹å˜å‚æ•°ï¼Œå·ç§¯æ ¸å°ºå¯¸ä¸èƒ½è¿‡å¤§ï¼Œåªèƒ½é€šè¿‡å †å æ¥æ‰©å¤§æ„Ÿå—é‡ã€æ•æ‰é•¿è·ç¦»å…³ç³»</li></ul></li><li>é€šé“ç‰¹å¼‚æ€§(channel specific)ï¼šdifferent kernels for different channels<ul><li>ä¼˜ç‚¹ï¼šå……åˆ†æå–ä¸åŒé€šé“ä¸Šçš„ä¿¡æ¯</li><li>ç¼ºç‚¹ï¼šæœ‰å†—ä½™</li></ul></li></ol><p>Convolution kernel å°ºå¯¸ä¸º B,C_out,C_in,K,K</p><header><h1>Involution</h1></header><p>ä¸convolutionä¸åŒï¼Œinvolutionæ‹¥æœ‰<strong>å®Œå…¨ç›¸å</strong>çš„æ€§è´¨ï¼š</p><ol><li>ç©ºé—´ç‰¹å¼‚æ€§ï¼škernel privatized for different position</li><li>é€šé“ä¸å˜æ€§ï¼škernel shared across different channels</li></ol><p>involution kernel çš„å°ºå¯¸ä¸ºB,G,KK,H,W.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/non-convolution">non-convolution</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Involution - Inverting the Inherence of Convolution for Visual Recognition" href="/blog/[18]Involution-Inverting-the-Inherence-of-Convolution-for-Visual-Recognition"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[20]Transformer-Attention-is-all-you-need">Transformer - Attention is all you need</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/AsTheStarsFalll.png" alt="AsTheStarsFall"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">AsTheStarsFall</span></a></div><small class="avatar__subtitle" itemprop="description">None</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><blockquote><p>è®ºæ–‡åç§°ï¼š<a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="noopener noreferrer">Attention Is All you Need</a></p><p>ä½œè€…ï¼šAshish Vaswaniï¼ŒNoam Shazeerï¼ŒNiki Parmarï¼ŒJakob Uszkoreitï¼ŒLlion Jonesï¼ŒAidan N. Gomezï¼ŒÅukasz Kaiserï¼ŒIllia Polosukhin</p><p>codeï¼š<a href="https://github.com/jadore801120/attention-is-all-you-need-pytorch/blob/master/transformer/Models.py" target="_blank" rel="noopener noreferrer">https://github.com/jadore801120/attention-is-all-you-need-pytorch/blob/master/transformer/Models.py</a></p></blockquote><h2 class="anchor anchorWithStickyNavbar_y2LR" id="å‰è¨€">å‰è¨€<a aria-hidden="true" class="hash-link" href="#å‰è¨€" title="Direct link to heading">â€‹</a></h2><p>åŸºäºRNNæˆ–CNNçš„Encoder-Decoderæ¨¡å‹åœ¨NLPé¢†åŸŸå æ®å¤§å£æ±Ÿå±±ï¼Œç„¶è€Œå¥¹ä»¬ä¹Ÿå¹¶éæ˜¯å®Œç¾æ— ç¼ºçš„ï¼š</p><ul><li>LSTMï¼ŒGRUç­‰RNNæ¨¡å‹å—é™äºå›ºæœ‰çš„å¾ªç¯é¡ºåºç»“æ„ï¼Œæ— æ³•å®ç°<strong>å¹¶è¡Œè®¡ç®—</strong>ï¼Œåœ¨åºåˆ—è¾ƒé•¿æ—¶ï¼Œè®¡ç®—æ•ˆç‡å°¤å…¶ä½ä¸‹ï¼Œè™½ç„¶æœ€è¿‘çš„å·¥ä½œå¦‚<a href="http://arxiv.org/abs/1703.10722" target="_blank" rel="noopener noreferrer">å› å­åˆ†è§£æŠ€å·§</a><sup id="fnref-1"><a href="#fn-1" class="footnote-ref">1</a></sup>ï¼Œ<a href="https://arxiv.org/abs/1701.06538" target="_blank" rel="noopener noreferrer">æ¡ä»¶è®¡ç®—</a><sup id="fnref-2"><a href="#fn-2" class="footnote-ref">2</a></sup>åœ¨ä¸€å®šç¨‹åº¦ä¸Šæé«˜äº†è®¡ç®—æ•ˆç‡å’Œæ€§èƒ½ï¼Œä½†æ˜¯é¡ºåºè®¡ç®—çš„é™åˆ¶ä¾ç„¶å­˜åœ¨ï¼›</li><li>Extended Neural GPU<sup id="fnref-3"><a href="#fn-3" class="footnote-ref">3</a></sup>,<a href="https://arxiv.org/abs/1610.10099" target="_blank" rel="noopener noreferrer">ByteNet</a><sup id="fnref-4"><a href="#fn-4" class="footnote-ref">4</a></sup>,å’Œ<a href="https://arxiv.org/abs/1705.03122" target="_blank" rel="noopener noreferrer">ConvS2S</a><sup id="fnref-5"><a href="#fn-5" class="footnote-ref">5</a></sup> ç­‰CNNæ¨¡å‹è™½ç„¶å¯ä»¥è¿›è¡Œå¹¶è¡Œè®¡ç®—ï¼Œä½†æ˜¯å­¦ä¹ ä»»æ„ä¸¤ä¸ªä½ç½®çš„ä¿¡å·çš„é•¿è·ç¦»å…³ç³»ä¾æ—§æ¯”è¾ƒå›°éš¾ï¼Œå…¶è®¡ç®—å¤æ‚åº¦éšè·ç¦»çº¿æ€§æˆ–å¯¹æ•°å¢é•¿ã€‚</li></ul><p>è€Œè°·æ­Œé€‰æ‹©æŠ›å¼ƒäº†ä¸»æµæ¨¡å‹å›ºæœ‰çš„ç»“æ„ï¼Œæå‡ºäº†<strong>å®Œå…¨</strong>åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„Transformerï¼Œæ‹¥æœ‰å…¶ä»–æ¨¡å‹æ— æ³•æ¯”æ‹Ÿçš„ä¼˜åŠ¿ï¼š</p><ul><li>Transformerå¯ä»¥é«˜æ•ˆçš„å¹¶è¡Œè®­ç»ƒï¼Œå› æ­¤é€Ÿåº¦ååˆ†å¿«ï¼Œåœ¨8ä¸ªGPUä¸Šè®­ç»ƒäº†3.5å¤©ï¼›</li><li>å¯¹äºé•¿è·ç¦»å…³ç³»çš„å­¦ä¹ ï¼ŒTransformerå°†æ—¶é—´å¤æ‚åº¦é™ä½åˆ°äº†å¸¸æ•°ï¼Œå¹¶ä¸”ä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æ¥æŠµæ¶ˆä½ç½®ä¿¡æ¯çš„å¹³å‡åŠ æƒé€ æˆçš„æœ‰æ•ˆåˆ†è¾¨ç‡é™ä½</li><li>Transformæ˜¯ä¸€ç§è‡ªç¼–ç ï¼ˆAuto-Encodingï¼‰æ¨¡å‹ï¼Œèƒ½å¤ŸåŒæ—¶åˆ©ç”¨ä¸Šä¸‹æ–‡</li></ul><h2 class="anchor anchorWithStickyNavbar_y2LR" id="æ•´ä½“ç»“æ„">æ•´ä½“ç»“æ„<a aria-hidden="true" class="hash-link" href="#æ•´ä½“ç»“æ„" title="Direct link to heading">â€‹</a></h2><p>Transfromerçš„æ•´ä½“ç»“æ„æ˜¯ä¸€ä¸ªEncoder-Decoderï¼Œè‡ªç¼–ç æ¨¡å‹ä¸»è¦åº”ç”¨äºè¯­æ„ç†è§£ï¼Œå¯¹äºç”Ÿæˆä»»åŠ¡è¿˜æ˜¯è‡ªå›å½’æ¨¡å‹æ›´æœ‰ä¼˜åŠ¿</p><p><img src="https://gitee.com/Thedeadleaf/images/raw/master/image-20210605151335569.png" alt="image-20210605151335569"></p><p>æˆ‘ä»¬å¯ä»¥å°†å…¶åˆ†ä¸ºå››ä¸ªéƒ¨åˆ†ï¼šè¾“å…¥ï¼Œç¼–ç å—ï¼Œè§£ç å—ä¸è¾“å‡º</p><p><img src="https://gitee.com/Thedeadleaf/images/raw/master/photo_2021-06-05_15-27-55.jpg"></p><p>æ¥ä¸‹æ¥è®©æˆ‘ä»¬æŒ‰ç…§é¡ºåºæ¥äº†è§£æ•´ä¸ªç»“æ„ï¼Œå¸Œæœ›åœ¨é˜…è¯»ä¸‹æ–‡å‰ä½ å¯ä»¥ä»”ç»†è§‚å¯Ÿè¿™å¹…å›¾ï¼Œé˜…è¯»æ—¶ä¹Ÿè¯·å‚è€ƒè¯¥å›¾</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/transformer">transformer</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Transformer - Attention is all you need" href="/blog/[20]Transformer-Attention-is-all-you-need"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[23]Squeeze-and-Excitation-Networks">Squeeze-and-Excitation Networks</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/visualDust.png" alt="Gavin Gong"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Gavin Gong</span></a></div><small class="avatar__subtitle" itemprop="description">Rubbish CVer | Poor LaTex speaker | Half stack developer | é”®åœˆèººå°¸ç –å®¶</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>Squeeze-and-Excitation Networksï¼ˆSENetï¼‰æ˜¯ç”±è‡ªåŠ¨é©¾é©¶å…¬å¸Momentaåœ¨2017å¹´å…¬å¸ƒçš„ä¸€ç§å…¨æ–°çš„å›¾åƒè¯†åˆ«ç»“æ„ï¼Œå®ƒé€šè¿‡å¯¹ç‰¹å¾é€šé“é—´çš„ç›¸å…³æ€§è¿›è¡Œå»ºæ¨¡ï¼ŒæŠŠé‡è¦çš„ç‰¹å¾è¿›è¡Œå¼ºåŒ–æ¥æå‡å‡†ç¡®ç‡ã€‚è¿™ä¸ªç»“æ„æ˜¯2017 ILSVRç«èµ›çš„å† å†›ï¼Œtop5çš„é”™è¯¯ç‡è¾¾åˆ°äº†2.251%ï¼Œæ¯”2016å¹´çš„ç¬¬ä¸€åè¿˜è¦ä½25%ã€‚</p><blockquote><p>The central building block of convolutional neural networks (CNNs) is the convolution operator, which enables networks to construct informative features by fusing both spatial and channel-wise information within local receptive fields at each layer. A broad range of prior research has investigated the spatial component of this relationship, seeking to strengthen the representational power of a CNN by enhancing the quality of spatial encodings throughout its feature hierarchy. In this work, we focus instead on the channel relationship and propose a novel architectural unit, which we term the &quot;Squeeze-and-Excitation&quot; (SE) block, that adaptively recalibrates channel-wise feature responses by explicitly modelling interdependencies between channels. We show that these blocks can be stacked together to form SENet architectures that generalise extremely effectively across different datasets. We further demonstrate that SE blocks bring significant improvements in performance for existing state-of-the-art CNNs at slight additional computational cost. Squeeze-and-Excitation Networks formed the foundation of our ILSVRC 2017 classification submission which won first place and reduced the top-5 error to 2.251%, surpassing the winning entry of 2016 by a relative improvement of ~25%. Models and code are available at <a href="https://github.com/hujie-frank/SENet" target="_blank" rel="noopener noreferrer">this https URL</a>.</p></blockquote><p><img alt="image-20210703161305168" src="/assets/images/image-20210703161305168-6ca7af5b712c6a190e7910f82bb43b20.png"></p><p>SENetçš„ä¸»è¦åˆ›æ–°æ˜¯ä¸€ä¸ªæ¨¡å—ã€‚å¦‚ä¸Šå›¾ï¼ŒFtræ˜¯ä¼ ç»Ÿå·ç§¯ç»“æ„ï¼Œå…¶è¾“å…¥<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span></span></span></span></span>(<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>C</mi><mo mathvariant="normal" lspace="0em" rspace="0em">â€²</mo></msup><mo>Ã—</mo><msup><mi>W</mi><mo mathvariant="normal" lspace="0em" rspace="0em">â€²</mo></msup><mo>Ã—</mo><msup><mi>H</mi><mo mathvariant="normal" lspace="0em" rspace="0em">â€²</mo></msup></mrow><annotation encoding="application/x-tex">C&#x27;\times W&#x27; \times H&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8352em;vertical-align:-0.0833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">â€²</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">Ã—</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8352em;vertical-align:-0.0833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">â€²</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">Ã—</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">â€²</span></span></span></span></span></span></span></span></span></span></span></span></span>)å’Œè¾“å‡º<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">U</span></span></span></span></span>(<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>Ã—</mo><mi>W</mi><mo>Ã—</mo><mi>H</mi></mrow><annotation encoding="application/x-tex">C\times W \times H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">Ã—</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">Ã—</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.08125em">H</span></span></span></span></span>)ä¹Ÿéƒ½æ˜¯ä¼ ç»Ÿç»“æ„ä¸­å·²ç»å­˜åœ¨çš„ã€‚SeNetçš„æ¨¡å—æ˜¯<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">U</span></span></span></span></span>ä¹‹åçš„éƒ¨åˆ†ã€‚SENeté€šè¿‡è¿™ç§è®¾åœ¨æŸç§ç¨‹åº¦ä¸Šå¼•å…¥äº†æ³¨æ„åŠ›ã€‚</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Squeeze-and-Excitation Networks" href="/blog/[23]Squeeze-and-Excitation-Networks"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[26]CBAM-Convolutional-Block-Attention-Module">CBAM - Convolutional Block Attention Module</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/visualDust.png" alt="Gavin Gong"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Gavin Gong</span></a></div><small class="avatar__subtitle" itemprop="description">Rubbish CVer | Poor LaTex speaker | Half stack developer | é”®åœˆèººå°¸ç –å®¶</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img alt="image-20210723203210974" src="/assets/images/image-20210723203210974-2dc470230899435d972cfec3588e4ffc.png"></p><p><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Woo%2C+S" target="_blank" rel="noopener noreferrer">Sanghyun Woo</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+J" target="_blank" rel="noopener noreferrer">Jongchan Park</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+J" target="_blank" rel="noopener noreferrer">Joon-Young Lee</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kweon%2C+I+S" target="_blank" rel="noopener noreferrer">In So Kweon</a></p><blockquote><p>We propose Convolutional Block Attention Module (CBAM), a simple yet effective attention module for feed-forward convolutional neural networks. Given an intermediate feature map, our module sequentially infers attention maps along two separate dimensions, channel and spatial, then the attention maps are multiplied to the input feature map for adaptive feature refinement. Because CBAM is a lightweight and general module, it can be integrated into any CNN architectures seamlessly with negligible overheads and is end-to-end trainable along with base CNNs. We validate our CBAM through extensive experiments on ImageNet-1K, MS~COCO detection, and VOC~2007 detection datasets. Our experiments show consistent improvements in classification and detection performances with various models, demonstrating the wide applicability of CBAM. The code and models will be publicly available.</p></blockquote><p>CBAMæ˜¯ä¸€ç¯‡ç»“åˆäº†é€šé“æ³¨æ„åŠ›å’Œç©ºé—´æ³¨æ„åŠ›çš„è®ºæ–‡ã€‚å®ƒé€šè¿‡åœ¨åŒä¸ªæ¨¡å—ä¸­å åŠ é€šé“æ³¨æ„åŠ›å’Œç©ºé—´æ³¨æ„åŠ›è¾¾åˆ°äº†è‰¯å¥½çš„æ•ˆæœã€‚ä¸ºäº†æå‡ CNN æ¨¡å‹çš„è¡¨ç°ï¼Œé™¤äº†å¯¹ç½‘ç»œçš„æ·±åº¦ã€å®½åº¦ä¸‹æ‰‹ï¼Œè¿˜æœ‰ä¸€ä¸ªæ–¹å‘æ˜¯æ³¨æ„åŠ›ã€‚æ³¨æ„åŠ›ä¸ä»…è¦å‘Šè¯‰æˆ‘ä»¬é‡ç‚¹å…³æ³¨å“ªé‡Œï¼Œæé«˜å…³æ³¨ç‚¹çš„è¡¨è¾¾ã€‚ æˆ‘ä»¬çš„ç›®æ ‡æ˜¯é€šè¿‡ä½¿ç”¨æ³¨æ„æœºåˆ¶æ¥å¢åŠ è¡¨ç°åŠ›ï¼Œå…³æ³¨é‡è¦ç‰¹å¾å¹¶æŠ‘åˆ¶ä¸å¿…è¦çš„ç‰¹å¾ã€‚</p><p>ä¸ºäº†å¼ºè°ƒç©ºé—´å’Œé€šé“è¿™ä¸¤ä¸ªç»´åº¦ä¸Šçš„æœ‰æ„ä¹‰ç‰¹å¾ï¼Œä½œè€…ä¾æ¬¡åº”ç”¨é€šé“å’Œç©ºé—´æ³¨æ„æ¨¡å—ï¼Œæ¥åˆ†åˆ«ä¼˜åŒ–å·ç§¯ç¥ç»ç½‘ç»œåœ¨é€šé“å’Œç©ºé—´ç»´åº¦ä¸Šå­¦ä¹ èƒ½åŠ›ã€‚ä½œè€…å°†æ³¨æ„åŠ›è¿‡ç¨‹åˆ†ä¸ºé€šé“å’Œç©ºé—´ä¸¤ä¸ªç‹¬ç«‹çš„éƒ¨åˆ†ï¼Œè¿™æ ·åšä¸ä»…å¯ä»¥èŠ‚çº¦å‚æ•°å’Œè®¡ç®—åŠ›ï¼Œè€Œä¸”ä¿è¯äº†å…¶å¯ä»¥ä½œä¸ºå³æ’å³ç”¨çš„æ¨¡å—é›†æˆåˆ°ç°æœ‰çš„ç½‘ç»œæ¶æ„ä¸­å»ã€‚</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about CBAM - Convolutional Block Attention Module" href="/blog/[26]CBAM-Convolutional-Block-Attention-Module"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[27]Non-local-Neural-Networks">Non-local Neural Networks</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/visualDust.png" alt="Gavin Gong"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Gavin Gong</span></a></div><small class="avatar__subtitle" itemprop="description">Rubbish CVer | Poor LaTex speaker | Half stack developer | é”®åœˆèººå°¸ç –å®¶</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><blockquote><p>The non-local block is a popular module for strengthening the context modeling ability of a regular convolutional neural network.</p></blockquote><p>Non-localæ—¨åœ¨ä½¿ç”¨å•ä¸ªLayerå®ç°é•¿è·ç¦»çš„åƒç´ å…³ç³»æ„å»ºï¼Œå±äºè‡ªæ³¨æ„åŠ›ï¼ˆself-attentionï¼‰çš„ä¸€ç§ã€‚å¸¸è§çš„CNNæˆ–æ˜¯RNNç»“æ„åŸºäºå±€éƒ¨åŒºåŸŸè¿›è¡Œæ“ä½œã€‚ä¾‹å¦‚ï¼Œå·ç§¯ç¥ç»ç½‘ç»œä¸­ï¼Œæ¯æ¬¡å·ç§¯è¯•å›¾å»ºç«‹ä¸€å®šåŒºåŸŸå†…åƒç´ çš„å…³ç³»ã€‚ä½†è¿™ç§å…³ç³»çš„èŒƒå›´å¾€å¾€è¾ƒå°ï¼ˆç”±äºå·ç§¯æ ¸ä¸å¤§ï¼‰ã€‚</p><p>ä¸ºäº†å»ºç«‹åƒç´ ä¹‹é—´çš„é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œä¹Ÿå°±æ˜¯å›¾åƒä¸­éç›¸é‚»åƒç´ ç‚¹ä¹‹é—´çš„å…³ç³»ï¼Œæœ¬æ–‡å¦è¾Ÿè¹Šå¾„ï¼Œæå‡ºåˆ©ç”¨non-local operationsæ„å»ºnon-localç¥ç»ç½‘ç»œã€‚è¿™ç¯‡è®ºæ–‡é€šè¿‡éå±€éƒ¨æ“ä½œè§£å†³æ·±åº¦ç¥ç»ç½‘ç»œæ ¸å¿ƒé—®é¢˜ï¼šæ•æ‰é•¿è·ç¦»ä¾èµ–å…³ç³»ã€‚</p><blockquote><p>Both convolutional and recurrent operations are building blocks that process one local neighborhood at a time. In this paper, we present non-local operations as a generic family of building blocks for capturing long-range dependencies. Inspired by the classical non-local means method in computer vision, our non-local operation computes the response at a position as a weighted sum of the features at all positions. This building block can be plugged into many computer vision architectures. On the task of video classification, even without any bells and whistles, our non-local models can compete or outperform current competition winners on both Kinetics and Charades datasets. In static image recognition, our non-local models improve object detection/segmentation and pose estimation on the COCO suite of tasks. Code is available at <a href="https://github.com/facebookresearch/video-nonlocal-net" target="_blank" rel="noopener noreferrer">this https URL</a> .</p></blockquote><p>æœ¬æ–‡å¦è¾Ÿè¹Šå¾„ï¼Œæå‡ºåˆ©ç”¨non-local operationsæ„å»ºnon-localç¥ç»ç½‘ç»œï¼Œè§£å†³äº†é•¿è·ç¦»åƒç´ ä¾èµ–å…³ç³»çš„é—®é¢˜ã€‚å¾ˆå€¼å¾—é˜…è¯»<a href="https://arxiv.org/abs/1711.07971" target="_blank" rel="noopener noreferrer">è®ºæ–‡åŸæ–‡</a>ã€‚å—è®¡ç®—æœºè§†è§‰ä¸­ç»å…¸çš„éå±€éƒ¨å‡å€¼æ–¹æ³•å¯å‘ï¼Œä½œè€…çš„éå±€éƒ¨æ“ä½œæ˜¯å°†æ‰€æœ‰ä½ç½®å¯¹ä¸€ä¸ªä½ç½®çš„ç‰¹å¾åŠ æƒå’Œä½œä¸ºè¯¥ä½ç½®çš„å“åº”å€¼ã€‚è¿™ç§éå±€éƒ¨æ“ä½œå¯ä»¥åº”ç”¨äºå¤šç§è®¡ç®—æœºè§†è§‰æ¡†æ¶ä¸­ï¼Œåœ¨è§†é¢‘åˆ†ç±»ã€ç›®æ ‡åˆ†ç±»ã€è¯†åˆ«ã€åˆ†å‰²ç­‰ç­‰ä»»åŠ¡ä¸Šï¼Œéƒ½æœ‰å¾ˆå¥½çš„è¡¨ç°ã€‚</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/non-convolution">non-convolution</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Non-local Neural Networks" href="/blog/[27]Non-local-Neural-Networks"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[28]GCNet-Non-local-Networks-Meet-Squeeze-Excitation-Networks-and-Beyond">Non-local Networks Meet Squeeze-Excitation Networks and Beyond</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/visualDust.png" alt="Gavin Gong"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Gavin Gong</span></a></div><small class="avatar__subtitle" itemprop="description">Rubbish CVer | Poor LaTex speaker | Half stack developer | é”®åœˆèººå°¸ç –å®¶</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+Y" target="_blank" rel="noopener noreferrer">Yue Cao</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+J" target="_blank" rel="noopener noreferrer">Jiarui Xu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+S" target="_blank" rel="noopener noreferrer">Stephen Lin</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+F" target="_blank" rel="noopener noreferrer">Fangyun Wei</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+H" target="_blank" rel="noopener noreferrer">Han Hu</a></p><p>GCNetï¼ˆåŸè®ºæ–‡ï¼š<a href="https://arxiv.org/abs/1904.11492" target="_blank" rel="noopener noreferrer">GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond</a>æˆ–<a href="https://arxiv.org/abs/2012.13375" target="_blank" rel="noopener noreferrer">Global Context Networks</a>ï¼‰è¿™ç¯‡è®ºæ–‡çš„ç ”ç©¶æ€è·¯ç±»ä¼¼äºDPNï¼Œæ·±å…¥æ¢è®¨äº†Non-localå’ŒSENetçš„ä¼˜ç¼ºç‚¹ï¼Œç„¶åç»“åˆNon-localå’ŒSENetçš„ä¼˜ç‚¹æå‡ºäº†GCNetã€‚</p><blockquote><p>The Non-Local Network (NLNet) presents a pioneering approach for capturing long-range dependencies, via aggregating query-specific global context to each query position. However, through a rigorous empirical analysis, we have found that the global contexts modeled by non-local network are almost the same for different query positions within an image. In this paper, we take advantage of this finding to create a simplified network based on a query-independent formulation, which maintains the accuracy of NLNet but with significantly less computation. We further observe that this simplified design shares similar structure with Squeeze-Excitation Network (SENet). Hence we unify them into a three-step general framework for global context modeling. Within the general framework, we design a better instantiation, called the global context (GC) block, which is lightweight and can effectively model the global context. The lightweight property allows us to apply it for multiple layers in a backbone network to construct a global context network (GCNet), which generally outperforms both simplified NLNet and SENet on major benchmarks for various recognition tasks. The code and configurations are released at <a href="https://github.com/xvjiarui/GCNet" target="_blank" rel="noopener noreferrer">this https URL</a>.</p></blockquote><p><img alt="image-20210713150550619" src="/assets/images/image-20210713150550619-77ccbe29a84029ee8123e066defbd049.png"></p><p>GCNetæå‡ºä¸€ç§æ¨¡å—æ¡†æ¶ç§°ä¸ºGlobal context modeling frameworkï¼ˆä¸Šå›¾ä¸­(a)ï¼‰ï¼Œå¹¶å°†å…¶åˆ†ä¸ºä¸‰æ­¥ï¼šContext modelingã€Transformã€Fusionã€‚</p><p>è¿™ç¯‡è®ºæ–‡é€‰ç”¨<a href="/blog/tags/[27]Non-local-Neural-Networks">Non-Local Neural Networks</a>ï¼ˆä¸Šå›¾ä¸­(b)æ˜¯å…¶ç®€åŒ–ç‰ˆï¼‰çš„Context modeling å’Œ <a href="/blog/tags/[23]Squeeze-and-Excitation-Networks">Squeeze and Excitation Networks </a>ï¼ˆä¸Šå›¾ä¸­(c)æ˜¯å…¶ä¸€ç§å½¢å¼ï¼‰çš„ Transformè¿‡ç¨‹ç»„æˆæ–°çš„æ¨¡å—Global Context (GC) blockï¼ŒåŒæ—¶è®­ç»ƒspacialå’Œchannel-wiseä¸Šçš„æ³¨æ„åŠ›ã€‚è¿™æ˜¯ä¸€ç¯‡å¾ˆå¥½çš„è®ºæ–‡ï¼Œæœ‰å…´è¶£è¯·é˜…è¯»<a href="https://arxiv.org/abs/1904.11492" target="_blank" rel="noopener noreferrer">åŸæ–‡</a>ã€‚</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Non-local Networks Meet Squeeze-Excitation Networks and Beyond" href="/blog/[28]GCNet-Non-local-Networks-Meet-Squeeze-Excitation-Networks-and-Beyond"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[29]Disentangled-Non-Local-Neural-Networks">Disentangled Non-Local Neural Networks</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/visualDust.png" alt="Gavin Gong"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Gavin Gong</span></a></div><small class="avatar__subtitle" itemprop="description">Rubbish CVer | Poor LaTex speaker | Half stack developer | é”®åœˆèººå°¸ç –å®¶</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yin%2C+M" target="_blank" rel="noopener noreferrer">Minghao Yin</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yao%2C+Z" target="_blank" rel="noopener noreferrer">Zhuliang Yao</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cao%2C+Y" target="_blank" rel="noopener noreferrer">Yue Cao</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+X" target="_blank" rel="noopener noreferrer">Xiu Li</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Z" target="_blank" rel="noopener noreferrer">Zheng Zhang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin%2C+S" target="_blank" rel="noopener noreferrer">Stephen Lin</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+H" target="_blank" rel="noopener noreferrer">Han Hu</a></p><blockquote><p>The non-local block is a popular module for strengthening the context modeling ability of a regular convolutional neural network. This paper first studies the non-local block in depth, where we find that its attention computation can be split into two terms, a whitened pairwise term accounting for the relationship between two pixels and a unary term representing the saliency of every pixel. We also observe that the two terms trained alone tend to model different visual clues, e.g. the whitened pairwise term learns within-region relationships while the unary term learns salient boundaries. However, the two terms are tightly coupled in the non-local block, which hinders the learning of each. Based on these findings, we present the disentangled non-local block, where the two terms are decoupled to facilitate learning for both terms. We demonstrate the effectiveness of the decoupled design on various tasks, such as semantic segmentation on Cityscapes, ADE20K and PASCAL Context, object detection on COCO, and action recognition on Kinetics.</p></blockquote><p>ä»è®ºæ–‡åç§°ä¸Šæ¥çœ‹ï¼Œè¿™ç¯‡è®ºæ–‡åˆ†æäº†<a href="/blog/tags/[27]Non-local-Neural-Networks">Non-Local Neural Networks</a>ä¸­çš„Non-Localæ¨¡å—ä¸­æ‰€å­˜åœ¨çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¹¶å¯¹å…¶è®¾è®¡è¿›è¡Œäº†è§£è€¦ã€‚è§£è€¦åè¯¥æ³¨æ„åŠ›åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼šæˆå¯¹é¡¹ï¼ˆpairwise termï¼‰ç”¨äºè¡¨ç¤ºåƒç´ ä¹‹é—´çš„å…³ç³»ï¼Œä¸€å…ƒé¡¹ï¼ˆunary termï¼‰ç”¨äºè¡¨ç¤ºåƒç´ è‡ªèº«çš„æŸç§æ˜¾è‘—æ€§ã€‚è¿™ä¸¤é¡¹åœ¨Non-Localå—ä¸­æ˜¯ç´§å¯†è€¦åˆçš„ã€‚è¿™ç¯‡è®ºæ–‡å‘ç°å½“ç€ä¸¤éƒ¨åˆ†è¢«åˆ†å¼€è®­ç»ƒåï¼Œä¼šåˆ†åˆ«å¯¹ä¸åŒçš„è§†è§‰çº¿ç´¢è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶è¾¾åˆ°ä¸é”™çš„æ•ˆæœã€‚</p><p>æ•´ç¯‡è®ºæ–‡ä»å¯¹Non-Localåˆ†æåˆ°æ–°çš„æ–¹æ³•æå‡ºéƒ½éå¸¸åœ°æœ‰è°ƒç†ã€‚æœ‰æ—¶é—´è¯·é˜…è¯»åŸè®ºæ–‡<a href="https://arxiv.org/abs/2006.06668" target="_blank" rel="noopener noreferrer">Disentangled Non-Local Neural Networks</a>ã€‚</p><blockquote><p>åœ¨é˜…è¯»æœ¬æ–‡ä¹‹å‰è¯·å…ˆé˜…è¯»<a href="/blog/tags/[27]Non-local-Neural-Networks">Non-Local Neural Networks</a>ã€‚</p></blockquote></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/non-convolution">non-convolution</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Disentangled Non-Local Neural Networks" href="/blog/[29]Disentangled-Non-Local-Neural-Networks"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[33]VOLO-Vision-Outlooker-for-Visual-Recognition">VOLO - Vision Outlooker for Visual Recognition</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/AsTheStarsFalll.png" alt="AsTheStarsFall"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">AsTheStarsFall</span></a></div><small class="avatar__subtitle" itemprop="description">None</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><blockquote><p>è®ºæ–‡åç§°ï¼šVOLO: Vision Outlooker for Visual Recognition</p><p>ä½œè€…ï¼šLi Yuan, Qibin Hou, Zihang Jiang, Jiashi Feng, Shuicheng Yan</p><p>Codeï¼š <a href="https://github.com/sail-sg/volo" target="_blank" rel="noopener noreferrer">https://github.com/sail-sg/volo</a></p></blockquote><h2 class="anchor anchorWithStickyNavbar_y2LR" id="æ‘˜è¦">æ‘˜è¦<a aria-hidden="true" class="hash-link" href="#æ‘˜è¦" title="Direct link to heading">â€‹</a></h2><ul><li>è§†è§‰è¯†åˆ«ä»»åŠ¡å·²è¢«<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi>N</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">CNN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">CNN</span></span></span></span></span>ä¸»å®°å¤šå¹´ã€‚åŸºäºè‡ªæ³¨æ„åŠ›çš„<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mi>i</mi><mi>T</mi></mrow><annotation encoding="application/x-tex">ViT</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">Vi</span><span class="mord mathnormal" style="margin-right:0.13889em">T</span></span></span></span></span>åœ¨<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi><mi>N</mi><mi>e</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">ImageNet</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mord mathnormal">ma</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10903em">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span></span></span></span></span>åˆ†ç±»æ–¹é¢è¡¨ç°å‡ºäº†æå¤§çš„æ½œåŠ›ï¼Œåœ¨æ²¡æœ‰é¢å¤–æ•°æ®å‰æä¸‹ï¼Œ<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>r</mi><mi>a</mi><mi>n</mi><mi>s</mi><mi>f</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>e</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">Transformer</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mord mathnormal">an</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mord mathnormal" style="margin-right:0.02778em">or</span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.02778em">er</span></span></span></span></span>çš„æ€§èƒ½ä¸æœ€å…ˆè¿›çš„<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi>N</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">CNN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">CNN</span></span></span></span></span>æ¨¡å‹ä»å…·æœ‰å·®è·ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ç¼©å°è¿™ä¸¤è€…ä¹‹é—´çš„æ€§èƒ½å·®è·ï¼Œå¹¶ä¸”è¯æ˜äº†åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹ç¡®å®èƒ½å¤Ÿæ¯”<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi>N</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">CNN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">CNN</span></span></span></span></span>è¡¨ç°æ›´å¥½ã€‚</li><li>ä¸æ­¤åŒæ—¶ï¼Œæˆ‘ä»¬å‘ç°é™åˆ¶<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mi>i</mi><mi>T</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">ViTs</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">Vi</span><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="mord mathnormal">s</span></span></span></span></span>åœ¨<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi><mi>N</mi><mi>e</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">ImageNet</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mord mathnormal">ma</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10903em">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span></span></span></span></span>åˆ†ç±»ä¸­çš„æ€§èƒ½çš„ä¸»è¦å› ç´ æ˜¯å…¶åœ¨å°†ç»†ç²’åº¦çº§åˆ«çš„ç‰¹å¾ç¼–ç ä¹˜<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>o</mi><mi>k</mi><mi>e</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">Token</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span></span></span></span></span>è¡¨ç¤ºè¿‡ç¨‹ä¸­æ¯”è¾ƒä½æ•ˆï¼Œä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>l</mi><mi>o</mi><mi>o</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">outlook</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.01968em">tl</span><span class="mord mathnormal">oo</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span>æ³¨æ„åŠ›ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç®€å•è€Œé€šç”¨çš„æ¶æ„ï¼Œç§°ä¸º<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">Vision</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">Vi</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span></span></span></span></span> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>l</mi><mi>o</mi><mi>o</mi><mi>k</mi><mi>e</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">outlooker</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.01968em">tl</span><span class="mord mathnormal">oo</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord mathnormal" style="margin-right:0.02778em">er</span></span></span></span></span> (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mi>O</mi><mi>L</mi><mi>O</mi></mrow><annotation encoding="application/x-tex">VOLO</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.02778em">O</span></span></span></span></span>)ã€‚<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi>l</mi><mi>o</mi><mi>o</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">outlook</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.01968em">tl</span><span class="mord mathnormal">oo</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span>æ³¨æ„åŠ›ä¸»è¦å°†<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mi>i</mi><mi>n</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">fine</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mord mathnormal">in</span><span class="mord mathnormal">e</span></span></span></span></span>â€‹-<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>e</mi><mi>v</mi><mi>e</mi><mi>l</mi></mrow><annotation encoding="application/x-tex">level</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span></span></span></span></span>çº§åˆ«çš„ç‰¹å¾å’Œä¸Šä¸‹æ–‡ä¿¡æ¯æ›´é«˜æ•ˆåœ°ç¼–ç åˆ°<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>o</mi><mi>k</mi><mi>e</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">token</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span></span></span></span></span>è¡¨ç¤ºä¸­ï¼Œè¿™äº›<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>o</mi><mi>k</mi><mi>e</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">token</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span></span></span></span></span>å¯¹è¯†åˆ«æ€§èƒ½è‡³å…³é‡è¦ï¼Œä½†å¾€å¾€è¢«è‡ªæ³¨æ„åŠ›æ‰€å¿½è§†ã€‚</li><li>å®éªŒè¡¨æ˜ï¼Œåœ¨ä¸ä½¿ç”¨ä»»ä½•é¢å¤–è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œ<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mi>O</mi><mi>L</mi><mi>O</mi></mrow><annotation encoding="application/x-tex">VOLO</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.02778em">O</span></span></span></span></span>åœ¨<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi><mi>N</mi><mi>e</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">ImageNet</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mord mathnormal">ma</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10903em">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span></span></span></span></span>-<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>K</mi></mrow><annotation encoding="application/x-tex">1K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord">1</span><span class="mord mathnormal" style="margin-right:0.07153em">K</span></span></span></span></span>åˆ†ç±»ä»»åŠ¡ä¸Šè¾¾åˆ°äº†87.1%çš„<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>o</mi><mi>p</mi></mrow><annotation encoding="application/x-tex">top</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8095em;vertical-align:-0.1944em"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal">p</span></span></span></span></span>-<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></span>å‡†ç¡®ç‡ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªè¶…è¿‡87%çš„æ¨¡å‹ã€‚æ­¤å¤–ï¼Œé¢„è®­ç»ƒå¥½çš„VOLOæ¨¡å‹è¿˜å¯ä»¥å¾ˆå¥½åœ°è¿ç§»åˆ°ä¸‹æ¸¸ä»»åŠ¡ï¼Œå¦‚è¯­ä¹‰åˆ†å‰²ã€‚æˆ‘ä»¬åœ¨<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi>i</mi><mi>t</mi><mi>y</mi><mi>s</mi><mi>c</mi><mi>a</mi><mi>p</mi><mi>e</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">Cityscapes</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ysc</span><span class="mord mathnormal">a</span><span class="mord mathnormal">p</span><span class="mord mathnormal">es</span></span></span></span></span>éªŒè¯é›†ä¸Šè·å¾—äº†84.3% <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>I</mi><mi>o</mi><mi>U</mi></mrow><annotation encoding="application/x-tex">mIoU</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10903em">U</span></span></span></span></span>ï¼Œåœ¨<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>D</mi><mi>E</mi><mn>20</mn><mi>K</mi></mrow><annotation encoding="application/x-tex">ADE20K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="mord">20</span><span class="mord mathnormal" style="margin-right:0.07153em">K</span></span></span></span></span>éªŒè¯é›†ä¸Šè·å¾—äº†54.3%çš„<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>I</mi><mi>o</mi><mi>U</mi></mrow><annotation encoding="application/x-tex">mIoU</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">m</span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10903em">U</span></span></span></span></span>ï¼Œå‡åˆ›ä¸‹äº†æœ€æ–°è®°å½•ã€‚</li></ul><img src="https://gitee.com/Thedeadleaf/images/raw/master/20210730004322.png"><p><strong>æ€»ç»“</strong>ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„æ³¨æ„åŠ›æœºåˆ¶â€”â€”<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mi>u</mi><mi>t</mi><mi>l</mi><mi>o</mi><mi>o</mi><mi>k</mi><mtext>Â </mtext><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">Outlook\ Attention</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.01968em">tl</span><span class="mord mathnormal">oo</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace">Â </span><span class="mord mathnormal">A</span><span class="mord mathnormal">tt</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span></span></span></span></span>ï¼Œä¸ç²—ç•¥å»ºæ¨¡å…¨å±€é•¿è·ç¦»å…³ç³»çš„<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>e</mi><mi>l</mi><mi>f</mi><mtext>Â </mtext><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">Self\ Attention</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mspace">Â </span><span class="mord mathnormal">A</span><span class="mord mathnormal">tt</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span></span></span></span></span>ä¸åŒï¼Œ<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mi>u</mi><mi>t</mi><mi>l</mi><mi>o</mi><mi>o</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">Outlook</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.01968em">tl</span><span class="mord mathnormal">oo</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span>èƒ½åœ¨é‚»åŸŸä¸Šæ›´ç²¾ç»†åœ°ç¼–ç é¢†åŸŸç‰¹å¾ï¼Œå¼¥è¡¥äº†<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>e</mi><mi>l</mi><mi>f</mi><mtext>Â </mtext><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">Self\ Attention</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mspace">Â </span><span class="mord mathnormal">A</span><span class="mord mathnormal">tt</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span></span></span></span></span>å¯¹æ›´ç²¾ç»†ç‰¹å¾ç¼–ç çš„ä¸è¶³ã€‚</p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="outlooker-attention">OutLooker Attention<a aria-hidden="true" class="hash-link" href="#outlooker-attention" title="Direct link to heading">â€‹</a></h2><p><strong>OutLooker</strong>æ¨¡å—å¯è§†ä½œæ‹¥æœ‰ä¸¤ä¸ªç‹¬ç«‹é˜¶æ®µçš„ç»“æ„ï¼Œç¬¬ä¸€ä¸ªéƒ¨åˆ†åŒ…å«ä¸€å †<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mi>u</mi><mi>t</mi><mi>L</mi><mi>o</mi><mi>o</mi><mi>k</mi><mi>e</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">OutLooker</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord mathnormal">L</span><span class="mord mathnormal">oo</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord mathnormal" style="margin-right:0.02778em">er</span></span></span></span></span>ç”¨äºç”Ÿæˆç²¾ç»†åŒ–çš„è¡¨ç¤ºï¼ˆ<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>o</mi><mi>k</mi><mi>e</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">Token</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span></span></span></span></span> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>e</mi><mi>p</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">representations</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em"></span><span class="mord mathnormal">re</span><span class="mord mathnormal">p</span><span class="mord mathnormal">rese</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">s</span></span></span></span></span>ï¼‰ï¼Œç¬¬äºŒä¸ªéƒ¨åˆ†éƒ¨ç½²ä¸€ç³»åˆ—çš„è½¬æ¢å™¨æ¥èšåˆå…¨å±€ä¿¡æ¯ã€‚åœ¨æ¯ä¸ªéƒ¨åˆ†ä¹‹å‰ï¼Œéƒ½æœ‰å—åµŒå…¥æ¨¡å—ï¼ˆ<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">patch</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span></span></span></span></span> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow><annotation encoding="application/x-tex">embedding</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">mb</span><span class="mord mathnormal">e</span><span class="mord mathnormal">dd</span><span class="mord mathnormal">in</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span></span></span></span></span> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>u</mi><mi>l</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">module</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">o</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">e</span></span></span></span></span>ï¼‰å°†è¾“å…¥æ˜ å°„åˆ°æŒ‡å®šå½¢çŠ¶ã€‚</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/non-convolution">non-convolution</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about VOLO - Vision Outlooker for Visual Recognition" href="/blog/[33]VOLO-Vision-Outlooker-for-Visual-Recognition"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[34]Polarized-Self-Attention-Towards-High-quality-Pixel-wise-Regression">Polarized Self-Attention - Towards High-quality Pixel-wise Regression</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/AsTheStarsFalll.png" alt="AsTheStarsFall"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">AsTheStarsFall</span></a></div><small class="avatar__subtitle" itemprop="description">None</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><blockquote><p>è®ºæ–‡åç§°ï¼š<a href="https://arxiv.org/pdf/2107.00782.pdf" target="_blank" rel="noopener noreferrer">Polarized Self-Attention: Towards High-quality Pixel-wise Regression</a></p><p>ä½œè€…ï¼šHuajun Liu,  Fuqiang Liu, Xinyi Fan</p><p>Codeï¼š<a href="https://github.com/DeLightCMU/PSA" target="_blank" rel="noopener noreferrer">https://github.com/DeLightCMU/PSA</a></p></blockquote><p>è¿™ç¯‡ç¬”è®°çš„å†™ä½œè€…æ˜¯<a href="https://github.com/asthestarsfalll" target="_blank" rel="noopener noreferrer">AsTheStarsFall</a>ã€‚</p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="æ‘˜è¦">æ‘˜è¦<a aria-hidden="true" class="hash-link" href="#æ‘˜è¦" title="Direct link to heading">â€‹</a></h2><p>ç»†ç²’åº¦çš„åƒç´ çº§ä»»åŠ¡ï¼ˆæ¯”å¦‚è¯­ä¹‰åˆ†å‰²ï¼‰ä¸€ç›´éƒ½æ˜¯è®¡ç®—æœºè§†è§‰ä¸­éå¸¸é‡è¦çš„ä»»åŠ¡ã€‚ä¸åŒäºåˆ†ç±»æˆ–è€…æ£€æµ‹ï¼Œç»†ç²’åº¦çš„åƒç´ çº§ä»»åŠ¡è¦æ±‚æ¨¡å‹åœ¨ä½è®¡ç®—å¼€é”€ä¸‹ï¼Œèƒ½å¤Ÿå»ºæ¨¡é«˜åˆ†è¾¨ç‡è¾“å…¥/è¾“å‡ºç‰¹å¾çš„é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œè¿›è€Œæ¥ä¼°è®¡é«˜åº¦éçº¿æ€§çš„åƒç´ è¯­ä¹‰ã€‚<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi>N</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">CNN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">CNN</span></span></span></span></span>â€‹â€‹â€‹ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶èƒ½å¤Ÿæ•è·é•¿è·ç¦»çš„ä¾èµ–å…³ç³»ï¼Œä½†æ˜¯è¿™ç§æ–¹å¼ååˆ†å¤æ‚ä¸”<strong>å¯¹å™ªå£°æ•æ„Ÿ</strong>ã€‚</p><p>æœ¬æ–‡æå‡ºäº†å³æ’å³ç”¨çš„æåŒ–è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œè¯¥æ¨¡å—åŒ…å«ä¸¤ä¸ªå…³é”®è®¾è®¡ï¼Œä»¥ä¿è¯é«˜è´¨é‡çš„åƒç´ å›å½’ï¼š</p><ol><li>æåŒ–æ»¤æ³¢ï¼ˆ<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>o</mi><mi>l</mi><mi>a</mi><mi>r</mi><mi>i</mi><mi>z</mi><mi>e</mi><mi>d</mi><mtext>Â </mtext><mi>f</mi><mi>i</mi><mi>l</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow><annotation encoding="application/x-tex">Polarized\ filtering</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">ze</span><span class="mord mathnormal">d</span><span class="mspace">Â </span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mord mathnormal">i</span><span class="mord mathnormal">lt</span><span class="mord mathnormal" style="margin-right:0.02778em">er</span><span class="mord mathnormal">in</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span></span></span></span></span>â€‹ï¼‰ï¼šåœ¨é€šé“å’Œç©ºé—´ç»´åº¦ä¿æŒæ¯”è¾ƒé«˜çš„åˆ†è¾¨ç‡ï¼ˆåœ¨é€šé“ä¸Šä¿æŒ<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">C/2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mord">/2</span></span></span></span></span>â€‹çš„ç»´åº¦ï¼Œåœ¨ç©ºé—´ä¸Šä¿æŒ<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>H</mi><mo separator="true">,</mo><mi>W</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[H,W]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="mclose">]</span></span></span></span></span>â€‹çš„ç»´åº¦ ï¼‰ï¼Œè¿›ä¸€æ­¥å‡å°‘ä½åˆ†è¾¨ç‡ã€ä½é€šé“æ•°å’Œä¸Šé‡‡æ ·é€ æˆçš„ä¿¡æ¯æŸå¤±ã€‚</li><li>å¢å¼ºï¼ˆ<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>n</mi><mi>h</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>e</mi><mi>m</mi><mi>e</mi><mi>n</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">Enhancement</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="mord mathnormal">nhan</span><span class="mord mathnormal">ce</span><span class="mord mathnormal">m</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span></span></span></span></span>â€‹ï¼‰ï¼šé‡‡ç”¨ç»†ç²’åº¦å›å½’è¾“å‡ºåˆ†å¸ƒçš„éçº¿æ€§å‡½æ•°ã€‚</li></ol></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/refinement">refinement</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Polarized Self-Attention - Towards High-quality Pixel-wise Regression" href="/blog/[34]Polarized-Self-Attention-Towards-High-quality-Pixel-wise-Regression"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[35]SimAM-A-Simple-Parameter-Free-Attention-Module-for-Convolutional-Neural-Networks">SimAM - A Simple, Parameter-Free Attention Module for Convolutional Neural Networks</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/AsTheStarsFalll.png" alt="AsTheStarsFall"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/AsTheStarsFalll" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">AsTheStarsFall</span></a></div><small class="avatar__subtitle" itemprop="description">None</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><blockquote><p>è®ºæ–‡åç§°ï¼š<a href="http://proceedings.mlr.press/v139/yang21o/yang21o.pdf" target="_blank" rel="noopener noreferrer">SimAM: A Simple, Parameter-Free Attention Module for Convolutional Neural Networks</a></p><p>ä½œè€…ï¼š<a href="https://zjjconan.github.io/" target="_blank" rel="noopener noreferrer"><strong>Lingxiao Yang</strong></a>, <a href="https://ruyuanzhang.github.io/" target="_blank" rel="noopener noreferrer">Ru-Yuan Zhang</a>, <a href="https://github.com/lld533" target="_blank" rel="noopener noreferrer">Lida Li</a>, <a href="http://sdcs.sysu.edu.cn/content/2478" target="_blank" rel="noopener noreferrer">Xiaohua Xie</a></p><p>Codeï¼š<a href="https://github.com/ZjjConan/SimAM" target="_blank" rel="noopener noreferrer">https://github.com/ZjjConan/SimAM</a></p></blockquote><h2 class="anchor anchorWithStickyNavbar_y2LR" id="ä»‹ç»">ä»‹ç»<a aria-hidden="true" class="hash-link" href="#ä»‹ç»" title="Direct link to heading">â€‹</a></h2><p>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„3Dæ³¨æ„åŠ›æ¨¡å—ï¼ŒåŸºäºè‘—åçš„ç¥ç»ç§‘å­¦ç†è®ºï¼Œæå‡ºäº†ä¸€ç§èƒ½é‡å‡½æ•°ï¼Œå¹¶ä¸”æ¨å¯¼å‡ºå…¶å¿«é€Ÿè§£æè§£ï¼Œèƒ½å¤Ÿä¸ºæ¯ä¸€ä¸ªç¥ç»å…ƒåˆ†é…æƒé‡ã€‚ä¸»è¦è´¡çŒ®å¦‚ä¸‹ï¼š</p><ul><li>å—äººè„‘æ³¨æ„æœºåˆ¶çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå…·æœ‰3Dæƒé‡çš„æ³¨æ„æ¨¡å—ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªèƒ½é‡å‡½æ•°æ¥è®¡ç®—æƒé‡ï¼›</li><li>æ¨å¯¼äº†èƒ½é‡å‡½æ•°çš„å°é—­å½¢å¼çš„è§£ï¼ŒåŠ é€Ÿäº†æƒé‡è®¡ç®—ï¼Œå¹¶ä¿æŒæ•´ä¸ªæ¨¡å—çš„è½»é‡ï¼›</li><li>å°†è¯¥æ¨¡å—åµŒå…¥åˆ°ç°æœ‰ConvNetä¸­åœ¨ä¸åŒä»»åŠ¡ä¸Šè¿›è¡Œäº†çµæ´»æ€§ä¸æœ‰æ•ˆæ€§çš„éªŒè¯ã€‚</li></ul></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/param-less">param-less</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/non-convolution">non-convolution</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about SimAM - A Simple, Parameter-Free Attention Module for Convolutional Neural Networks" href="/blog/[35]SimAM-A-Simple-Parameter-Free-Attention-Module-for-Convolutional-Neural-Networks"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/[40]Learning-in-the-Frequency-Domain">Learning in the Frequency Domain</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2022-11-05T07:47:19.660Z" itemprop="datePublished">2022å¹´11æœˆ5æ—¥</time> Â· <!-- -->One min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.yuuza.net/visualDust.png" alt="Gavin Gong"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Gavin Gong</span></a></div><small class="avatar__subtitle" itemprop="description">Rubbish CVer | Poor LaTex speaker | Half stack developer | é”®åœˆèººå°¸ç –å®¶</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+K" target="_blank" rel="noopener noreferrer">Kai Xu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Qin%2C+M" target="_blank" rel="noopener noreferrer">Minghai Qin</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+F" target="_blank" rel="noopener noreferrer">Fei Sun</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y" target="_blank" rel="noopener noreferrer">Yuhao Wang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+Y" target="_blank" rel="noopener noreferrer">Yen-Kuang Chen</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+F" target="_blank" rel="noopener noreferrer">Fengbo Ren</a></p><blockquote><p>  Deep neural networks have achieved remarkable success in computer vision tasks. Existing neural networks mainly operate in the spatial domain with fixed input sizes. For practical applications, images are usually large and have to be downsampled to the predetermined input size of neural networks. Even though the downsampling operations reduce computation and the required communication bandwidth, it removes both redundant and salient information obliviously, which results in accuracy degradation. Inspired by digital signal processing theories, we analyze the spectral bias from the frequency perspective and propose a learning-based frequency selection method to identify the trivial frequency components which can be removed without accuracy loss. The proposed method of learning in the frequency domain leverages identical structures of the well-known neural networks, such as ResNet-50, MobileNetV2, and Mask R-CNN, while accepting the frequency-domain information as the input. Experiment results show that learning in the frequency domain with static channel selection can achieve higher accuracy than the conventional spatial downsampling approach and meanwhile further reduce the input data size. Specifically for ImageNet classification with the same inpu t size, the proposed method achieves 1.41% and 0.66% top-1 accuracy improvements on ResNet-50 and MobileNetV2, respectively. Even with half input size, the proposed method still improves the top-1 accuracy on ResNet-50 by 1%. In addition, we observe a 0.8% average precision improvement on Mask R-CNN for instance segmentation on the COCO dataset.</p></blockquote><p><code>Comments</code>: Accepted to CVPR 2020</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/frequency-domain">frequency-domain</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/attention-mechanism">attention-mechanism</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/non-convolution">non-convolution</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Learning in the Frequency Domain" href="/blog/[40]Learning-in-the-Frequency-Domain"><b>Read More</b></a></div></footer></article></main></div></div></div><footer class="footer footer--dark"><div class="container"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2022 neet-cv. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.70701027.js"></script>
<script src="/assets/js/main.e4cdc564.js"></script>
</body>
</html>