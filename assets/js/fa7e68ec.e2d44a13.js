"use strict";(self.webpackChunkml_notebook=self.webpackChunkml_notebook||[]).push([[6131],{3905:function(e,t,r){r.d(t,{Zo:function(){return p},kt:function(){return d}});var n=r(67294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function s(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},o=Object.keys(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var l=n.createContext({}),c=function(e){var t=n.useContext(l),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},p=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},f=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,o=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),f=c(r),d=a,m=f["".concat(l,".").concat(d)]||f[d]||u[d]||o;return r?n.createElement(m,i(i({ref:t},p),{},{components:r})):n.createElement(m,i({ref:t},p))}));function d(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=r.length,i=new Array(o);i[0]=f;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:a,i[1]=s;for(var c=2;c<o;c++)i[c]=r[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,r)}f.displayName="MDXCreateElement"},3876:function(e,t,r){r.r(t),r.d(t,{frontMatter:function(){return f},contentTitle:function(){return d},metadata:function(){return m},assets:function(){return h},toc:function(){return b},default:function(){return g}});var n=r(3905),a=Object.defineProperty,o=Object.defineProperties,i=Object.getOwnPropertyDescriptors,s=Object.getOwnPropertySymbols,l=Object.prototype.hasOwnProperty,c=Object.prototype.propertyIsEnumerable,p=(e,t,r)=>t in e?a(e,t,{enumerable:!0,configurable:!0,writable:!0,value:r}):e[t]=r,u=(e,t)=>{for(var r in t||(t={}))l.call(t,r)&&p(e,r,t[r]);if(s)for(var r of s(t))c.call(t,r)&&p(e,r,t[r]);return e};const f={title:"Threat of Adversarial Attacks on Deep Learning in Computer Vision - A Survey",authors:["sonder"],tags:["adversarial attacks","survey","robustness"]},d=void 0,m={permalink:"/blog/[02]Threat-of-Adversarial-Attacks-on-Deep-Learning-in-Computer-Vision-A-Survey",editUrl:"https://github.dev/neet-cv/ml.akasaki.space/blob/master/blog/[02]Threat-of-Adversarial-Attacks-on-Deep-Learning-in-Computer-Vision-A-Survey.md",source:"@site/blog/[02]Threat-of-Adversarial-Attacks-on-Deep-Learning-in-Computer-Vision-A-Survey.md",title:"Threat of Adversarial Attacks on Deep Learning in Computer Vision - A Survey",description:"\u8fd9\u662f\u4e00\u7bc7\u795e\u7ecf\u5bf9\u6297\u7684\u7efc\u8ff0\u6587\u7ae0\uff0c\u975e\u5e38\u975e\u5e38\u975e\u5e38\u8be6\u7ec6\u7684\u4ecb\u7ecd\u4e86\u5f53\u524d\u795e\u7ecf\u5bf9\u6297\u653b\u51fb\u7684\u53d1\u5c55\u60c5\u51b5\u548c\u5df2\u6709\u7684\u653b\u51fb\u548c\u9632\u5fa1\u7b97\u6cd5\u3002\u539f\u8bba\u6587\uff1aThreat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey",date:"2022-11-05T07:47:19.660Z",formattedDate:"2022\u5e7411\u67085\u65e5",tags:[{label:"adversarial attacks",permalink:"/blog/tags/adversarial-attacks"},{label:"survey",permalink:"/blog/tags/survey"},{label:"robustness",permalink:"/blog/tags/robustness"}],readingTime:101.815,truncated:!0,authors:[{name:"Sonder",title:"life is but a span, I use python",url:"https://github.com/AndSonder",email:"me@keter.top",imageURL:"https://github.com/AndSonder.png",key:"sonder"}],prevItem:{title:"The Devil is in the Decoder - Classification, Regression and GANs",permalink:"/blog/[01]The-Devil-is-in-the-Decoder-Classification-Regression-and-GANs"},nextItem:{title:"Progressive Semantic Segmentation",permalink:"/blog/[03]Progressive-Semantic-Segmentation"}},h={authorsImageUrls:[void 0]},b=[],v={toc:b};function g(e){var t,r=e,{components:a}=r,p=((e,t)=>{var r={};for(var n in e)l.call(e,n)&&t.indexOf(n)<0&&(r[n]=e[n]);if(null!=e&&s)for(var n of s(e))t.indexOf(n)<0&&c.call(e,n)&&(r[n]=e[n]);return r})(r,["components"]);return(0,n.kt)("wrapper",(t=u(u({},v),p),o(t,i({components:a,mdxType:"MDXLayout"}))),(0,n.kt)("p",null,"\u8fd9\u662f\u4e00\u7bc7\u795e\u7ecf\u5bf9\u6297\u7684\u7efc\u8ff0\u6587\u7ae0\uff0c\u975e\u5e38\u975e\u5e38\u975e\u5e38\u8be6\u7ec6\u7684\u4ecb\u7ecd\u4e86\u5f53\u524d\u795e\u7ecf\u5bf9\u6297\u653b\u51fb\u7684\u53d1\u5c55\u60c5\u51b5\u548c\u5df2\u6709\u7684\u653b\u51fb\u548c\u9632\u5fa1\u7b97\u6cd5\u3002\u539f\u8bba\u6587\uff1a",(0,n.kt)("a",u({parentName:"p"},{href:"https://arxiv.org/pdf/1801.00553.pdf"}),"Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey")),(0,n.kt)("blockquote",null,(0,n.kt)("p",{parentName:"blockquote"},"Deep learning is at the heart of the current rise of machine learning and artificial intelligence. In the field of Computer Vision, it has become the workhorse for applications ranging from self-driving cars to surveillance and security. Whereas deep neural networks have demonstrated phenomenal success (often beyond human capabilities) in solving complex problems, recent studies show that they are vulnerable to adversarial attacks in the form of subtle perturbations to inputs that lead a model to predict incorrect outputs. For images, such perturbations are often too small to be perceptible, yet they completely fool the deep learning models. Adversarial attacks pose a serious threat to the success of deep learning in practice. This fact has lead to a large influx of contributions in this direction. This article presents the first comprehensive survey on adversarial attacks on deep learning in Computer Vision. We review the works that design adversarial attacks, analyze the existence of such attacks and propose defenses against them. To emphasize that adversarial attacks are possible in practical conditions, we separately review the contributions that evaluate adversarial attacks in the real-world scenarios. Finally, we draw on the literature to provide a broader outlook of the research direction.")),(0,n.kt)("p",null,"\u672c\u6587\u4e3b\u8981\u5bf9\u6587\u7ae0\u8fdb\u884c\u7ffb\u8bd1\uff0c\u8fd8\u52a0\u5165\u4e86\u4e2a\u4eba\u5bf9\u4e00\u4e9b\u7b97\u6cd5\u7684\u7406\u89e3\u4e0e\u89e3\u91ca\u3002\u8fd9\u7bc7\u6587\u7ae0\u6211\u5927\u6982\u770b\u4e86\u4e00\u4e2a\u661f\u671f\u3002\u771f\u7684\u662f\u4e00\u7bc7\u975e\u5e38\u4e0d\u9519\u7684\u7efc\u8ff0\u8bba\u6587\u3002"))}g.isMDXComponent=!0}}]);