"use strict";(self.webpackChunkml_notebook=self.webpackChunkml_notebook||[]).push([[562],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return d}});var r=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=r.createContext({}),c=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=c(e.components);return r.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),m=c(n),d=o,f=m["".concat(s,".").concat(d)]||m[d]||u[d]||a;return n?r.createElement(f,i(i({ref:t},p),{},{components:n})):r.createElement(f,i({ref:t},p))}));function d(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,i=new Array(a);i[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:o,i[1]=l;for(var c=2;c<a;c++)i[c]=n[c];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},8944:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return m},contentTitle:function(){return d},metadata:function(){return f},assets:function(){return b},toc:function(){return h},default:function(){return y}});var r=n(3905),o=Object.defineProperty,a=Object.defineProperties,i=Object.getOwnPropertyDescriptors,l=Object.getOwnPropertySymbols,s=Object.prototype.hasOwnProperty,c=Object.prototype.propertyIsEnumerable,p=(e,t,n)=>t in e?o(e,t,{enumerable:!0,configurable:!0,writable:!0,value:n}):e[t]=n,u=(e,t)=>{for(var n in t||(t={}))s.call(t,n)&&p(e,n,t[n]);if(l)for(var n of l(t))c.call(t,n)&&p(e,n,t[n]);return e};const m={title:"MobileNetV2 - Inverted Residuals and Linear Bottlenecks",authors:["pommespeter"],tags:["detection","backbone","light-weight"]},d=void 0,f={permalink:"/blog/[12]MobileNetV2-Inverted-Residuals-and-Linear-bottleneck",editUrl:"https://github.dev/neet-cv/ml.akasaki.space/blob/master/blog/[12]MobileNetV2-Inverted-Residuals-and-Linear-bottleneck.md",source:"@site/blog/[12]MobileNetV2-Inverted-Residuals-and-Linear-bottleneck.md",title:"MobileNetV2 - Inverted Residuals and Linear Bottlenecks",description:"\u8fd9\u662f\u4e00\u7bc7\u8bb2\u89e3\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4e3b\u5e72\u7f51\u7edc\u7684\u8bba\u6587\u3002\u539f\u8bba\u6587\uff08MobileNetV2: Inverted Residuals and Linear Bottlenecks\uff09\u3002",date:"2022-11-05T07:47:19.660Z",formattedDate:"2022\u5e7411\u67085\u65e5",tags:[{label:"detection",permalink:"/blog/tags/detection"},{label:"backbone",permalink:"/blog/tags/backbone"},{label:"light-weight",permalink:"/blog/tags/light-weight"}],readingTime:16.645,truncated:!0,authors:[{name:"PommesPeter",title:"I want to be strong. But it seems so hard.",url:"https://blog.pommespeter.com/",email:"me@pommespeter.com",imageURL:"https://github.com/PommesPeter.png",key:"pommespeter"}],prevItem:{title:"A Review on Deep Learning Techniques Applied to Semantic Segmentation",permalink:"/blog/[10]Overview-Of-Semantic-Segmentation"},nextItem:{title:"Fast-SCNN - Fast Semantic Segmentation Network",permalink:"/blog/[13]Fast-SCNN-Fast-Semantic-Segmentation-Network"}},b={authorsImageUrls:[void 0]},h=[],g={toc:h};function y(e){var t,n=e,{components:o}=n,p=((e,t)=>{var n={};for(var r in e)s.call(e,r)&&t.indexOf(r)<0&&(n[r]=e[r]);if(null!=e&&l)for(var r of l(e))t.indexOf(r)<0&&c.call(e,r)&&(n[r]=e[r]);return n})(n,["components"]);return(0,r.kt)("wrapper",(t=u(u({},g),p),a(t,i({components:o,mdxType:"MDXLayout"}))),(0,r.kt)("p",null,"\u8fd9\u662f\u4e00\u7bc7\u8bb2\u89e3\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4e3b\u5e72\u7f51\u7edc\u7684\u8bba\u6587\u3002",(0,r.kt)("a",u({parentName:"p"},{href:"https://arxiv.org/abs/1801.04381"}),"\u539f\u8bba\u6587\uff08MobileNetV2: Inverted Residuals and Linear Bottlenecks\uff09"),"\u3002"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\u672c\u6587\u4e3b\u8981\u9488\u5bf9\u8f7b\u91cf\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e2d\u7ed3\u6784\u4e0a\u7684\u4e09\u4e2a\u4fee\u6539\u63d0\u9ad8\u4e86\u7f51\u7edc\u6027\u80fd\u3002"),(0,r.kt)("li",{parentName:"ul"},"\u672c\u6587\u603b\u601d\u8def\uff1a\u4f7f\u7528\u4f4e\u7ef4\u5ea6\u7684\u5f20\u91cf\u5f97\u5230\u8db3\u591f\u591a\u7684\u7279\u5f81")),(0,r.kt)("p",null,"\u6458\u8981:"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and bench- marks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. is based on an inverted residual structure where the shortcut connections are between the thin bottle- neck layers. The intermediate expansion layer uses lightweight depthwise convolutions to filter features as a source of non-linearity. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demon- strate that this improves performance and provide an in- tuition that led to this design. Finally, our approach allows decoupling of the in- put/output domains from the expressiveness of the trans- formation, which provides a convenient framework for further analysis. We measure our performance on ImageNet classification, COCO object detection ","[2]",", VOC image segmentation ","[3]",". We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as actual latency, and the number of parameters.")))}y.isMDXComponent=!0}}]);